{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fontlearner\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Font Learner\n",
    "\n",
    "> Diffvg-based learner for font optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from __future__ import annotations\n",
    "from aifont.core import *\n",
    "from collections import OrderedDict\n",
    "from collections.abc import Iterable\n",
    "from contextlib import contextmanager\n",
    "from enum import Enum, auto\n",
    "from fastai.data.all import *\n",
    "from fastai.vision.all import *\n",
    "import ffmpeg\n",
    "from nbdev.showdoc import *\n",
    "from pandas import DataFrame\n",
    "import PIL\n",
    "from PIL.ImageOps import invert\n",
    "import pydiffvg\n",
    "from pydiffvg import Polygon, Rect, RenderFunction, save_svg, ShapeGroup\n",
    "from pydiffvg import Path as VectorPath\n",
    "from torch.distributions import Categorical\n",
    "from torch.nn import Parameter\n",
    "from typing import Callable, List, Protocol, Sequence, Tuple, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "COLOR_BLACK     = tensor(0., 0., 0., 1.)\n",
    "COLOR_WHITE     = tensor(1., 1., 1., 1.)\n",
    "DEFAULT_SAMPLES = 6 # See notebook 5§9 for an analysis\n",
    "EPS             = 1e-10 # Eps for, e.g. preventing div by 0\n",
    "RGBA_TO_GS      = tensor(0.2989, 0.5870, 0.1140) # Crude NTSC weights for RGB channels\n",
    "\n",
    "@contextmanager\n",
    "def debug(obj, set_to=True, silent=False) -> None:\n",
    "    \"\"\"A context manager for enabling the `debug` parameter for any object\n",
    "       that supports it. `no_debug` is a shorthand for `debug(False)`.\"\"\"\n",
    "    if not hasattr(obj, 'debug'):\n",
    "        if not silent: warn(f\"Object {obj} doesn't afford debug.\")\n",
    "        yield\n",
    "    else:\n",
    "        dbg = obj.debug\n",
    "        obj.debug = set_to\n",
    "        try: yield\n",
    "        finally: obj.debug = dbg\n",
    "\n",
    "no_debug = partial(debug, set_to=False)\n",
    "\n",
    "@contextmanager\n",
    "def eval_model(learner_or_model: Union[Learner, Module]) -> None:\n",
    "    \"\"\"A context manager for evaluating a `Learner` that restores the\n",
    "       previous `training` state.\"\"\"\n",
    "    m = learner_or_model.model if isinstance(learner_or_model, Learner) else learner_or_model\n",
    "    trn = m.training\n",
    "    m.eval()\n",
    "    try: yield\n",
    "    finally:\n",
    "        m.train(trn)\n",
    "\n",
    "def get_argmin(df: DataFrame, argmin_col = \"loss\", return_col = \"value\") -> float:\n",
    "    \"\"\"Get the `return_col` value for the row with the lowest `argmin_col`.\n",
    "       For use with `VectorLearner.calculate_losses`.\"\"\"\n",
    "    return df.iloc[df[argmin_col].argmin()][return_col]\n",
    "\n",
    "def get_vocab(dls_or_learn: Union[DataLoaders, Learner]) -> List[str]:\n",
    "    \"\"\"Utility for getting the vocab from a Learner or DataLoaders.\"\"\"\n",
    "    if isinstance(dls_or_learn, Learner): dls_or_learn = dls_or_learn.dls\n",
    "    vocab = dls_or_learn.vocab\n",
    "    if type(vocab) == L and type(vocab[0]) == list: \n",
    "        if vocab[0] != vocab[1]: warn(\"The two vocabs in dls do not match! Using the first one.\")\n",
    "        vocab = vocab[0]\n",
    "    return vocab\n",
    "\n",
    "class DebugCB(Callback):\n",
    "    \"\"\"A `Callback` for debugging a `VectorRenderLayer`.\"\"\"\n",
    "    def __init__(self, vocal=False):\n",
    "        super(DebugCB, self).__init__()\n",
    "        self.vals = []\n",
    "        self.grads = []\n",
    "        store_attr()\n",
    "    # def before_fit(self):\n",
    "    #     self.model[0].params.retain_grad()\n",
    "    def after_loss(self):\n",
    "        if self.vocal: print(f\"After loss: yb len = {len(self.yb)}\")\n",
    "    def before_backward(self):\n",
    "        if self.vocal: print(\"Before backward\")\n",
    "    def before_step(self):\n",
    "        m = self.model\n",
    "        self.vals.append([ x.clone() for x in m.params])\n",
    "        self.grads.append([x.grad.clone() if x.grad else tensor(0.) for x in m.params])\n",
    "    def plot(self) -> None:\n",
    "        # val = self.model[0].params[0].item()\n",
    "        # grad_df.iloc[(grad_df.Vals - val).abs().argmin()]\n",
    "        num = len(self.vals[0])\n",
    "        def _items(tensor_list, idx): return [x.item() for x in tensor_list[idx]]\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(num): plt.scatter(_items(self.vals, i), _items(self.grads, i), label=f\"Param {i}\")\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letter Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Letter groups\n",
    "# Crop the ends of strokes going beyond cap height or baseline\n",
    "LETTERS_CROP_BOTH        = \"AB DE FHI KLMN P R T VWXYZ\"\n",
    "LETTERS_CROP_TOP_ONLY    = \"         J          U     \"\n",
    "# Pad vertex points by half stroke width\n",
    "LETTERS_PAD_LEFT         = \"ABCDEFGHIJKLMNOPQRS UVWXYZ\"\n",
    "LETTERS_PAD_RIGHT        = \"ABCD  GHIJK MNOPQRS UVWXY \"\n",
    "LETTERS_PAD_TOP          = \" BCDEFG       OPQRST     Z\"\n",
    "LETTERS_PAD_BOTTOM       = \" BCDE G  J L  O Q S U    Z\"\n",
    "# The directions to apply overshoot to\n",
    "LETTERS_OVERSHOOT_TOP    = \"A C   G     MNO Q S       \"\n",
    "LETTERS_OVERSHOOT_BOTTOM = \"  C   G  J   NO Q S UVW   \"\n",
    "\n",
    "class BoundingBox(GetAttr):\n",
    "    \"\"\"A simple object to hold the coordinates for the bounding box of \n",
    "       letter vertices.\"\"\"\n",
    "    def __init__(self, \n",
    "        left: Tensor, \n",
    "        top: Tensor, \n",
    "        right: Tensor, \n",
    "        bottom: Tensor):\n",
    "        self.top_lft = self.top_left     = concat_tensors(left, top)\n",
    "        self.top_rgt = self.top_right    = concat_tensors(right, top)\n",
    "        self.btm_lft = self.bottom_left  = concat_tensors(left, bottom)\n",
    "        self.btm_rgt = self.bottom_right = concat_tensors(right, bottom)\n",
    "        self.width   = right - left\n",
    "        self.height  = bottom - top\n",
    "        store_attr()\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join([\"BoundingBox\"] + [f\"- {x}: {getattr(self, x).item()}\" for x in \"left,top,right,bottom\".split(\",\")])\n",
    "    @classmethod\n",
    "    def from_points(cls,\n",
    "        p1: Tensor,\n",
    "        p2: Tensor,\n",
    "        **kwargs\n",
    "        ):\n",
    "        \"\"\"Create a `BoundingBox` from top-left and bottom-right corner points.\"\"\"\n",
    "        return cls(left = p1[0], top = p1[1], right = p2[0], bottom = p2[1], **kwargs)\n",
    "\n",
    "def get_bounding_box(\n",
    "    p_height: Tensor, \n",
    "    p_width: Tensor, \n",
    "    p_stroke_w: Tensor, \n",
    "    letter: str, \n",
    "    p_overshoot: Tensor = None,\n",
    "    p_offset_x: Tensor = None,\n",
    "    p_offset_y: Tensor = None\n",
    "    ) -> BoundingBox:\n",
    "    \"\"\"Calculate the coordinates for the bounding box of vertices.\"\"\"\n",
    "    w = p_height * p_width if p_width is not None else p_stroke_w\n",
    "    x1 = (1 - w) / 2\n",
    "    x2 = x1 + w\n",
    "    y1 = (1 - p_height) / 2\n",
    "    y2 = y1 + p_height\n",
    "    dw = p_stroke_w / 2\n",
    "    if letter in LETTERS_PAD_LEFT:   x1 += dw\n",
    "    if letter in LETTERS_PAD_RIGHT:  x2 -= dw\n",
    "    if letter in LETTERS_PAD_TOP:    y1 += dw\n",
    "    if letter in LETTERS_PAD_BOTTOM: y2 -= dw\n",
    "    # Deal with situations where stroke_w > w\n",
    "    for t in (x1, y1): t.clamp_(0., 0.5 - EPS)\n",
    "    for t in (x2, y2): t.clamp_(0.5 - EPS, 1.)\n",
    "    if p_overshoot:\n",
    "        if letter in LETTERS_OVERSHOOT_TOP:    y1 -= p_overshoot\n",
    "        if letter in LETTERS_OVERSHOOT_BOTTOM: y2 += p_overshoot\n",
    "    if p_offset_x:\n",
    "        x1 += p_offset_x\n",
    "        x2 += p_offset_x\n",
    "    if p_offset_y:\n",
    "        y1 += p_offset_y\n",
    "        y2 += p_offset_y\n",
    "    bounds = [p_stroke_w, 1. - p_stroke_w]\n",
    "    for t in (x1, y1, x2, y2): t.clamp_(*bounds)\n",
    "    return BoundingBox(x1, y1, x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# The bezier curvature value for a circle\n",
    "CIRCLE_CURVATURE = 4 * (math.sqrt(2) - 1) / 3\n",
    "\n",
    "class Bezier(TensorBase):\n",
    "    \"\"\"A simple wrapper for tensors describing quadratic beziers.\"\"\"\n",
    "    def __init__(self, coords: Union[Tensor, list[Tensor], list[float]]):\n",
    "        assert type(coords) in (Tensor, list, tuple) and len(coords) == 8\n",
    "        self.__new__(Bezier, coords)\n",
    "    def at(self, t: Union[Tensor, float]) -> Tensor:\n",
    "        \"\"\"Evaluate the bézier at `t`.\"\"\"\n",
    "        assert t >= 0. and t <= 1.\n",
    "        return cast((1 - t) ** 3 * self.p0 + \\\n",
    "                    3 * (1 - t) ** 2 * t * self.p1 + \\\n",
    "                    3 * (1 - t) * t ** 2 * self.p2 + \\\n",
    "                    t ** 3 * self.p3,\n",
    "                    Tensor)\n",
    "    def cut(self, t: Union[Tensor, float]) -> Tensor:\n",
    "        \"\"\"Cut the bézier at `t`.\"\"\"\n",
    "        def _mix(a, b): return (1 - t) * a + t * b\n",
    "        pe = _mix(self.p0, self.p1)\n",
    "        pf = _mix(self.p1, self.p2)\n",
    "        pg = _mix(self.p2, self.p3)\n",
    "        ph = _mix(pe, pf)\n",
    "        pj = _mix(pf, pg)\n",
    "        pk = _mix(ph, pj)\n",
    "        # A,E,H,K and K,J,G,D\n",
    "        return Bezier(concat_tensors(self.p0, pe, ph, pk, flatten=True))\n",
    "    def plot(self, t: Union[Tensor, float] = None, x_lim = (0, 2), y_lim = (0, 2)) -> plt.Axes:\n",
    "        \"\"\"Plot the bézier with matplotlib.\"\"\"\n",
    "        Path = matplotlib.path.Path\n",
    "        fig, ax = plt.subplots()\n",
    "        pp1 = matplotlib.patches.PathPatch(\n",
    "            Path(self.reshape(-1, 2), [Path.MOVETO, Path.CURVE4, Path.CURVE4, Path.CURVE4]),\n",
    "            fc=\"none\", transform=ax.transData\n",
    "            )\n",
    "        ax.add_patch(pp1)\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "        if t is not None:\n",
    "            pt = self.at(t)\n",
    "            ax.plot(pt[0], pt[1], \"ro\")\n",
    "        plt.show()\n",
    "        return ax\n",
    "    @property\n",
    "    def p0(self) -> Tensor: return cast(self[0:2], Tensor)\n",
    "    @p0.setter\n",
    "    def p0(self, val: Union[Tensor, float]) -> Tensor: self[0:2] = tensor(val)\n",
    "    @property\n",
    "    def p1(self) -> Tensor: return cast(self[2:4], Tensor)\n",
    "    @p1.setter\n",
    "    def p1(self, val: Union[Tensor, float]) -> Tensor: self[2:4] = tensor(val)\n",
    "    @property\n",
    "    def p2(self) -> Tensor: return cast(self[4:6], Tensor)\n",
    "    @p2.setter\n",
    "    def p2(self, val: Union[Tensor, float]) -> Tensor: self[4:6] = tensor(val)\n",
    "    @property\n",
    "    def p3(self) -> Tensor: return cast(self[6:8], Tensor)\n",
    "    @p3.setter\n",
    "    def p3(self, val: Union[Tensor, float]) -> Tensor: self[6:8] = tensor(val)\n",
    "\n",
    "def pt(\n",
    "    x: Union[Tensor, float],\n",
    "    y: Union[Tensor, float]\n",
    "    ) -> Tensor:\n",
    "    \"\"\"A shorthand to create a 2-element point tensor from two tensors or floats.\"\"\"\n",
    "    assert len(x) == len(y) == 1\n",
    "    return concat_tensors(x, y, flatten=True)\n",
    "\n",
    "def curve(\n",
    "    rad_x: Union[Tensor, float],\n",
    "    rad_y: Union[Tensor, float] = None,\n",
    "    x: Union[Tensor, float] = 0.,\n",
    "    y: Union[Tensor, float] = 0.,\n",
    "    curvature: Union[Tensor, float] = CIRCLE_CURVATURE,\n",
    "    ) -> Tuple[Tensor, List[int]]:\n",
    "    \"\"\"Create the necessary coordinate tensor and list of numbers of control \n",
    "       points to form a truncated curve Path that consists of the point of\n",
    "       origin, one horisontal control point and the end point. For use with\n",
    "       C, G and S. `x` and `y` define the top-left coordinates, `curvature` \n",
    "       controls handle extension as a fraction curve width. `rad_x` and \n",
    "       `rad_y` may be negative.\"\"\"\n",
    "    if rad_y is None: rad_y = rad_x\n",
    "    pts = concat_tensors(x,                         y,\n",
    "                         x + rad_x * curvature,     y,\n",
    "                         x + rad_x,                 y + rad_y)\n",
    "    cpts = [1]\n",
    "    return pts, cpts\n",
    "\n",
    "class BowlType(Enum):\n",
    "    CIRCLE = auto()\n",
    "    SEMICIRCLE_LEFT = auto()\n",
    "    SEMICIRCLE_RIGHT = auto()\n",
    "    SEMICIRCLE_TOP = auto()\n",
    "    SEMICIRCLE_BOTTOM = auto()\n",
    "    DEMICIRCLE_TOP_LEFT = auto()\n",
    "    DEMICIRCLE_TOP_RIGHT = auto()\n",
    "    DEMICIRCLE_BOTTOM_LEFT = auto()\n",
    "    DEMICIRCLE_BOTTOM_RIGHT = auto()\n",
    "\n",
    "DISTORT_KEY_STEMS = \"top_rgt btm_rgt top_lft btm_lft\".split(\" \")\n",
    "DISTORT_KEYS_X = [x + \"_x\" for x in DISTORT_KEY_STEMS]\n",
    "DISTORT_KEYS_Y = [x + \"_y\" for x in DISTORT_KEY_STEMS]\n",
    "DISTORT_KEYS = DISTORT_KEYS_X + DISTORT_KEYS_Y\n",
    "\n",
    "def bowl(\n",
    "    rad_x: Union[Tensor, float],\n",
    "    rad_y: Union[Tensor, float] = None,\n",
    "    x: Union[Tensor, float] = 0.,\n",
    "    y: Union[Tensor, float] = 0.,\n",
    "    curvature: Union[Tensor, float] = 4 * (math.sqrt(2) - 1) / 3,\n",
    "    bowl_type: BowlType = BowlType.CIRCLE,\n",
    "    distort: dict[str, Union[Tensor, float]] = {}\n",
    "    ) -> Tuple[Tensor, List[int]]:\n",
    "    \"\"\"Create the necessary coordinate tensor and list of numbers of control \n",
    "       points to form a bowl Path. `x` and `y` define the top-left coordinates,\n",
    "       `curvature` controls handle extension as a fraction of the relevant\n",
    "       segment dimension, `dist_top_rgt_x` etc. are distortions as fractions of\n",
    "       the relevant radius for each control point on either on the x or y axis\n",
    "       and signed so that a negative distortion contracts the handle and a\n",
    "       positive one extends it. `bowl_type` defines whether a full or \n",
    "       semicircle is drawn.\"\"\"\n",
    "    if rad_y is None: rad_y = rad_x\n",
    "    cpt_x, cpt_y = rad_x * curvature, rad_y * curvature\n",
    "    lft, rgt, top, btm, ctx, cty = x.clone(), x + 2 * rad_x, y.clone(), y + 2 * rad_y, x + rad_x, y + rad_y\n",
    "    if bowl_type in (BowlType.SEMICIRCLE_RIGHT, BowlType.DEMICIRCLE_TOP_RIGHT, BowlType.DEMICIRCLE_BOTTOM_RIGHT): \n",
    "        lft -= rad_x\n",
    "        ctx -= rad_x\n",
    "        rgt -= rad_x\n",
    "    if bowl_type in (BowlType.SEMICIRCLE_BOTTOM, BowlType.DEMICIRCLE_BOTTOM_LEFT, BowlType.DEMICIRCLE_BOTTOM_RIGHT): \n",
    "        top -= rad_y\n",
    "        cty -= rad_y\n",
    "        btm -= rad_y\n",
    "    # Precalculate distortion and set missing to zero\n",
    "    distort_calc = {}\n",
    "    for k in DISTORT_KEYS:\n",
    "        if k not in distort: distort_calc[k] = tensor(0.)\n",
    "        else: distort_calc[k] = distort[k] * rad_x if k in DISTORT_KEYS_X else rad_y\n",
    "    pts = []\n",
    "    # Build the pts clockwise from the top\n",
    "    if bowl_type in (BowlType.CIRCLE, BowlType.SEMICIRCLE_RIGHT, BowlType.DEMICIRCLE_TOP_RIGHT):\n",
    "        # NB! If making changes here, also apply them to the last if segment\n",
    "        pts += [# Top vertex\n",
    "                ctx,                                        top,\n",
    "                ctx + cpt_x + distort_calc[\"top_rgt_x\"],    top,\n",
    "                rgt,                                        cty - cpt_y - distort_calc[\"top_rgt_y\"],\n",
    "                # Right vertex\n",
    "                rgt,                                        cty\n",
    "                ]\n",
    "    if bowl_type in (BowlType.CIRCLE, BowlType.SEMICIRCLE_RIGHT, BowlType.SEMICIRCLE_BOTTOM, BowlType.DEMICIRCLE_BOTTOM_RIGHT):\n",
    "        if len(pts) == 0: pts = [rgt, cty]\n",
    "        pts += [# Right vertex control points\n",
    "                rgt,                                        cty + cpt_y + distort_calc[\"btm_rgt_y\"],\n",
    "                ctx + cpt_x + distort_calc[\"btm_rgt_x\"],    btm,\n",
    "                # Bottom vertex\n",
    "                ctx,                                        btm\n",
    "                ]\n",
    "    if bowl_type in (BowlType.CIRCLE, BowlType.SEMICIRCLE_LEFT, BowlType.SEMICIRCLE_BOTTOM, BowlType.DEMICIRCLE_BOTTOM_LEFT):\n",
    "        if len(pts) == 0: pts = [ctx, btm]\n",
    "        pts += [# Bottom vertex control points\n",
    "                ctx - cpt_x - distort_calc[\"btm_lft_x\"],    btm,\n",
    "                lft,                                        cty + cpt_y + distort_calc[\"btm_lft_y\"],\n",
    "                # Left vertex\n",
    "                lft,                                        cty\n",
    "                ]\n",
    "    if bowl_type in (BowlType.CIRCLE, BowlType.SEMICIRCLE_LEFT, BowlType.SEMICIRCLE_TOP, BowlType.DEMICIRCLE_TOP_LEFT):\n",
    "        if len(pts) == 0: pts = [lft, cty]\n",
    "        pts += [# Left vertex control points\n",
    "                lft,                                        cty - cpt_y - distort_calc[\"top_lft_y\"],\n",
    "                ctx - cpt_x - distort_calc[\"top_lft_x\"],    top,\n",
    "                # Top vertex\n",
    "                ctx,                                        top\n",
    "                ]\n",
    "    if bowl_type == BowlType.SEMICIRCLE_TOP:\n",
    "        # Finally add the top-right segment\n",
    "        pts += [# Top vertex control points\n",
    "                ctx + cpt_x + distort_calc[\"top_rgt_x\"],    top,\n",
    "                rgt,                                        cty - cpt_y - distort_calc[\"top_rgt_y\"],\n",
    "                # Right vertex\n",
    "                rgt,                                        cty\n",
    "                ]\n",
    "    cpts = [2] * ((len(pts) - 1) // 6)\n",
    "    return concat_tensors(*pts), cpts\n",
    "\n",
    "class MaskDirection(Enum):\n",
    "    DOWN = auto()\n",
    "    UP = auto()\n",
    "\n",
    "ANGLE_EPS = 1e-4\n",
    "\n",
    "def terminal_mask(\n",
    "    curve: Union[Tensor, Bezier],\n",
    "    t: Union[Tensor, float] = None,\n",
    "    area_p1 = tensor(0., 0.), \n",
    "    area_p2 = tensor(1., 1.),\n",
    "    angle_deviation = tensor(0.),\n",
    "    direction = MaskDirection.DOWN,\n",
    "    fulcrum_pt = None\n",
    "    ) -> Tensor:\n",
    "    \"\"\"Create a mask for cutting the Bézier `curve` at fraction `t`\n",
    "       or at it's end point if None, at an angle defined matching a \n",
    "       line drawn from the fulcrum to the cut-off point rotated \n",
    "       towards vertical by `angle_deviation` radians. \n",
    "       The fulcrum defaults to bottom-left if `direction` is \n",
    "       down, top-right otherwise. The mask extends in `direction` to \n",
    "       cover the area defined by the corner point tensors `area_p1` \n",
    "       and `area_p2`.\"\"\"\n",
    "    if t is not None:\n",
    "        if not isinstance(curve, Bezier): curve = Bezier(curve)\n",
    "        term_pt = curve.at(t)\n",
    "    else: term_pt = curve[-2:]\n",
    "    area = BoundingBox.from_points(area_p1, area_p2)\n",
    "    if fulcrum_pt is None: fulcrum_pt = area.btm_lft if direction == MaskDirection.DOWN else area.top_rgt\n",
    "    term_dx = term_pt[0] - fulcrum_pt[0]\n",
    "    term_dy = fulcrum_pt[1] - term_pt[1]\n",
    "    angle = torch.atan(term_dy / term_dx) + angle_deviation\n",
    "    angle.clamp_(ANGLE_EPS, math.pi/2 - ANGLE_EPS)\n",
    "    # Extend the line to the edges of the area. The intersection may\n",
    "    # fall on a vertical or a horisontal edge. Note that the direction\n",
    "    # is clockwise, so with dir = DOWN pt 1 is on the left and with UP,\n",
    "    # on the right.\n",
    "    mask_dy_1 = torch.min(angle.tan() * term_dx, term_dy) if direction == MaskDirection.DOWN else \\\n",
    "                torch.max(angle.tan() * term_dx, term_dy)\n",
    "    mask_dx_1 = mask_dy_1 / angle.tan() * -1\n",
    "    mask_dy_2 = torch.min(angle.tan() * (area.right - term_pt[0]), term_pt[1] - area.top) * -1 \\\n",
    "                if direction == MaskDirection.DOWN else \\\n",
    "                torch.max(angle.tan() * (area.left  - term_pt[0]), term_pt[1] - area.bottom) * -1\n",
    "    mask_dx_2 = mask_dy_2 * -1 / angle.tan()\n",
    "    # Terminating line\n",
    "    term_line = [term_pt[0] + mask_dx_1,   term_pt[1] + mask_dy_1,\n",
    "                 term_pt[0] + mask_dx_2,   term_pt[1] + mask_dy_2]\n",
    "    # Clockwise. NB. We make a zero-height spike in the btm-left/\n",
    "    # top-right corner if the term line doesn't intersect with the\n",
    "    # vertical edge, but this should have no effect.\n",
    "    mask_pts = [area.btm_lft,\n",
    "                *term_line,\n",
    "                area.top_rgt,\n",
    "                area.btm_rgt] if direction == MaskDirection.DOWN else \\\n",
    "               [area.top_rgt,\n",
    "                *term_line,\n",
    "                area.btm_lft,\n",
    "                area.top_lft]\n",
    "    return concat_tensors(*mask_pts, flatten=True)\n",
    "\n",
    "def mirror(\n",
    "    pts: Tensor,\n",
    "    y: Union[Tensor, float]\n",
    "    ) -> Tensor:\n",
    "    \"\"\"Mirrors `pts` vertically around a line going through `y`.\"\"\"\n",
    "    assert pts.ndim == 1\n",
    "    res = pts.clone().reshape(-1, 2)\n",
    "    res *= tensor([1., -1.])\n",
    "    res[:, 1] = res[:, 1] + 2 * y\n",
    "    return res.flatten()\n",
    "\n",
    "def cut_semicircle(\n",
    "    semicircle: Tensor,\n",
    "    t: Union[Tensor, float]\n",
    "    ) -> Tensor:\n",
    "    \"\"\"Cut a semicircle tensor at `t` while maintaining\n",
    "        the number of points.\"\"\"\n",
    "    assert len(semicircle) == 14\n",
    "    assert t >= 0. and t <= 1.\n",
    "    # We split the semicircle into two demicircles and then cut accordingly\n",
    "    cut = 2 * t\n",
    "    cut_1 = torch.clamp(cut,     max=1.)\n",
    "    cut_2 = torch.clamp(cut - 1, min=0.)\n",
    "    dc_1 = Bezier(semicircle[:8]).cut(cut_1)\n",
    "    dc_2 = Bezier(semicircle[6:]).cut(cut_2)\n",
    "    # The second demicircle may be truncated at zero, which results in a point\n",
    "    # artefact, so we have to move all points init to the end point of\n",
    "    # the first demicircle. This is a GHASTLY hack...\n",
    "    blend_f = torch.where(cut_2.bool(), 1., 0.)\n",
    "    dc_2 = dc_2 * blend_f + (1 - blend_f) * dc_1[-2:].repeat(4)\n",
    "    # Rebuild the semicircle, noting that the end point of dc_1 is shared\n",
    "    return concat_tensors(dc_1, dc_2[2:], flatten=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "Shape = Union[Rect, Polygon, VectorPath]\n",
    "\n",
    "class Scene:\n",
    "    \"\"\"Just a utility to hold the different scene arguments together.\"\"\"\n",
    "    rf = RenderFunction\n",
    "    def __init__(self, \n",
    "        shapes: list[any], \n",
    "        shape_groups: list[ShapeGroup], \n",
    "        canvas_width = 256, \n",
    "        canvas_height = 256, \n",
    "        samples = None\n",
    "        ):\n",
    "        assert shapes is not None and len(shapes) != 0\n",
    "        assert shape_groups is not None and len(shape_groups) != 0\n",
    "        if samples is None: samples = DEFAULT_SAMPLES\n",
    "        self.last_seed: int = None\n",
    "        store_attr()\n",
    "\n",
    "    def get_scene_args(self) -> list:\n",
    "        \"\"\"Get the serialize scene for passing to `pydiffvg.RenderFunction`.\"\"\"\n",
    "        return self.rf.serialize_scene(self.canvas_width, self.canvas_height, self.shapes, self.shape_groups)\n",
    "\n",
    "    def render(self, \n",
    "        seed: int = None, \n",
    "        do_render_grad = False\n",
    "        ) -> Tensor:\n",
    "        \"\"\"Render the scene using pydffiv `RenderFunction` or its\n",
    "           gradient if `do_render_grad`.\"\"\"\n",
    "        if seed is None: seed = random.randint(0, 1e6)\n",
    "        self.last_seed = seed\n",
    "        scene_args = self.get_scene_args()\n",
    "        w,h = self.canvas_width,self.canvas_height\n",
    "        s = self.samples\n",
    "        args = [w, h, s, s, seed, None] + scene_args\n",
    "        return self.rf.render_grad(torch.ones(w, h, 4, device=pydiffvg.get_device()), *args) \\\n",
    "               if do_render_grad else self.rf.apply(*args)\n",
    "\n",
    "    def render_grad(self, \n",
    "        seed: int = None\n",
    "        ) -> Tensor:\n",
    "        \"\"\"Render the gradient as raster.\"\"\"\n",
    "        return self.render(seed=self.last_seed, do_render_grad=True)\n",
    "\n",
    "    def save_svg(self, \n",
    "        fn: Union[Path, str]\n",
    "        ) -> None:\n",
    "        \"\"\"Save the scene as svg.\"\"\"\n",
    "        save_svg(ensure_path(Path(fn).with_suffix(\".svg\")), \n",
    "                 self.canvas_width, self.canvas_height, self.shapes, self.shape_groups)\n",
    "\n",
    "add_docs(Scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageSaver:\n",
    "    \"\"\"Create a callback to pass to `VectorRenderLayer` as `rendered_callback`\n",
    "       to save rendered images and optionally grads.\"\"\"\n",
    "    def __init__(self, \n",
    "        folder: str, \n",
    "        save_grad = False,\n",
    "        save_svg  = False, \n",
    "        iter_name = \"iter\", \n",
    "        grad_name = \"grad\"\n",
    "        ):\n",
    "        assert folder is not None\n",
    "        assert \"_\" not in iter_name and \"_\" not in grad_name\n",
    "        if folder.endswith(\"/\"): folder = folder[:-1]\n",
    "        self.iter_files: List[str] = []\n",
    "        self.grad_files: List[str] = []\n",
    "        store_attr()\n",
    "\n",
    "    def __call__(self, \n",
    "        raster: Tensor, \n",
    "        batch_i: int, \n",
    "        item_i: int, \n",
    "        scene: Scene = None,\n",
    "        target = \"\",\n",
    "        **kwargs\n",
    "        ) -> None:\n",
    "        assert not ((self.save_grad or self.save_svg) and scene is None)\n",
    "        iter_sfx = f\"_{batch_i}_{target}_{item_i}\" # NB! This must match the template in render_grid\n",
    "        img_fn  = f\"{self.iter_name}{iter_sfx}\"\n",
    "        self.iter_files.append(self.save_image(raster, img_fn, **kwargs))\n",
    "        if self.save_grad: self.grad_files.append(self.save_image(scene.render_grad(), f\"{self.grad_name}{iter_sfx}\", **kwargs))\n",
    "        if self.save_svg: scene.save_svg(get_filepath(f\"{img_fn}.svg\"))\n",
    "\n",
    "    def save_image(self, \n",
    "        raster: Tensor, \n",
    "        filename: str\n",
    "        ) -> str:\n",
    "        \"\"\"Save the `raster` tensor as image file and return filename used.\"\"\"\n",
    "        r = raster.cpu()\n",
    "        fn = get_filepath(f\"{filename}.png\")\n",
    "        img = img_from_tensor(r)\n",
    "        img.save(fn)\n",
    "        return fn\n",
    "    \n",
    "    def render_result_video(self, \n",
    "        delete_imgs=False, \n",
    "        frame_rate=24, \n",
    "        grad=False\n",
    "        ) -> None:\n",
    "        \"\"\"Render intermediate images as a video.\"\"\"\n",
    "        files = self.grad_files if grad else self.iter_files\n",
    "        img = Image.open(files[0])\n",
    "        canvas_height,canvas_width = img.height,img.width\n",
    "        img.close()\n",
    "        out = os.path.join(self.folder, \"grads.mp4\" if grad else \"iters.mp4\")\n",
    "        frames = ffmpeg.input('pipe:', r=str(frame_rate))\n",
    "        process = ffmpeg.input(f\"color=c=white:s={canvas_width}x{canvas_height}\", f=\"lavfi\") \\\n",
    "                        .overlay(frames, eof_action=\"endall\") \\\n",
    "                        .output(out) \\\n",
    "                        .overwrite_output() \\\n",
    "                        .run_async(pipe_stdin=True, quiet=True)\n",
    "        for in_file in files:\n",
    "            with open(in_file, 'rb') as f: process.stdin.write(f.read())\n",
    "        # Close stdin pipe - FFmpeg fininsh encoding the output file.\n",
    "        process.stdin.close()\n",
    "        process.wait()\n",
    "        if delete_imgs: \n",
    "            for f in files: os.remove(f)\n",
    "        print(\"Rendering video done!\")\n",
    "\n",
    "    def render_grids(self,\n",
    "        grid_name = \"grid\",\n",
    "        grid_scale = 1.,\n",
    "        vocal = True\n",
    "        ) -> None:\n",
    "        \"\"\"Render grid versions of the individual rendered images.\"\"\"\n",
    "        def _render_grids(\n",
    "            imgs = self.iter_files,\n",
    "            name = self.iter_name\n",
    "            ) -> None:\n",
    "            batch_i = -1\n",
    "            buffer = []\n",
    "            for f in imgs:\n",
    "                i = int(Path(f).stem.split(\"_\")[1])\n",
    "                if i != batch_i:\n",
    "                    if len(buffer): image_grid(buffer, scale=grid_scale).convert('L').save(f\"{self.folder}/{grid_name}_{name}_{batch_i}.png\")\n",
    "                    if vocal: print(f\"Rendered batch {batch_i} of set {name}\")\n",
    "                    batch_i = i\n",
    "                    buffer = []\n",
    "                buffer.append(f)\n",
    "        _render_grids()\n",
    "        if self.save_grad: _render_grids(imgs=self.grad_files, name=self.grad_name)\n",
    "\n",
    "    def get_filepath(self, fn) -> str:\n",
    "        \"\"\"Add folder to `fn` and ensure necessary dirs exist.\"\"\"\n",
    "        fn = Path(self.folder)/filename\n",
    "        ensure_path(fn)\n",
    "        return str(fn)\n",
    "\n",
    "add_docs(ImageSaver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "Simple `DataLoader` for getting letter classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LetterDL(DataLoader):\n",
    "    \"\"\"A dummy data loader for use with font vector optimisation.\n",
    "       Pass the same `vocab` as in the OCR model. If `letters` is\n",
    "       defined, items are restricted to those. Batch size defaults\n",
    "       to the number of available items.\"\"\"\n",
    "    def __init__(self, \n",
    "        vocab: CategoryMap, \n",
    "        letters: Iterable[str] = None, \n",
    "        bs: int = None, \n",
    "        epoch_len = 10, \n",
    "        random = True,\n",
    "        **kwargs\n",
    "        ):\n",
    "        assert vocab is not None\n",
    "        if letters is None: letters = tuple(vocab)\n",
    "        if bs is None: bs = len(letters)\n",
    "        if not random and epoch_len * bs < len(letters): warn(f\"Some of the letters will never be produced \"\n",
    "            \"because random is False and epoch_len * bs is less than the number of letters.\")\n",
    "        super(LetterDL, self).__init__(bs=bs, n=epoch_len*bs, **kwargs)\n",
    "        self.categorizer = Categorize(vocab=vocab)\n",
    "        self.current_i: int\n",
    "        self._letters: Iterable[str]\n",
    "        store_attr(\"vocab,letters,epoch_len,random\")\n",
    "    @property\n",
    "    def letters(self) -> Iterable[str]: return self._letters\n",
    "    @letters.setter\n",
    "    def letters(self, v: Iterable[str]):\n",
    "        self._letters = v\n",
    "        self.reset_i()\n",
    "    def reset_i(self) -> None:\n",
    "        \"\"\"Call to reset `self.current_i` when `n` is reached. We randomise this if `self.n` isn't a\n",
    "           multiple of the number of letters so that all letters are produced evenly.\"\"\"\n",
    "        residue = self.n % len(self.letters)\n",
    "        self.current_i = 0 if residue == 0 else random.randint(0, residue)\n",
    "    def create_item(self, s\n",
    "        ) -> Tuple[TensorCategory, TensorCategory]:\n",
    "        \"\"\"Return the CategoryTensor for a random letter from `letters`.\"\"\"\n",
    "        if self.current_i == self.n: self.reset_i()\n",
    "        r = self.categorizer.encodes(random.choice(self.letters) if self.random else \\\n",
    "            self.letters[self.current_i % len(self.letters)])\n",
    "        self.current_i += 1\n",
    "        return r, r.clone() # Y is a copy of x\n",
    "    @classmethod\n",
    "    def from_vocab(cls, \n",
    "        vocab: CategoryMap, \n",
    "        random = False, \n",
    "        **kwargs\n",
    "        ):\n",
    "        \"\"\"Create a `LetterDL` using the whole `vocab`.\"\"\"\n",
    "        for x in (\"letters\", \"bs\"):\n",
    "            if x in kwargs and kwargs[x] is not None: warn(f\"Are you sure you want to define {x} when using from_vocab?\")\n",
    "            else: kwargs[x] = None\n",
    "        return cls(vocab=vocab, random=random, **kwargs)\n",
    "    \n",
    "add_docs(LetterDL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Model\n",
    "\n",
    "The vector model consists of a `FontParamLayer`, which holds the parameters to optimise, and a subclass of `VectorRenderLayer`, which handles the creation of the letter vectors.\n",
    "\n",
    "> Note that the utility of this bisection is tentative, and the params might as well be contained within the `VectorRenderLayer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Font Parameters\n",
    "\n",
    "Font parameters can be simple or specified to interpolate to certain ranges. \n",
    "\n",
    "The the order they are stored in the parameter layer. For each, a ParamRange tuple containing the min, max and optional mean values is passed, which are used to interpolate the value from the raw value, usually (–1, 1), passed by the parameter layer. Most values are treated as fractions, usually of cap height and, for Height, of canvas height. For standard ranges use the PRange enum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "ParamDict = dict[str, Parameter]\n",
    "\n",
    "PARAM_NAME_SEP = \", \"\n",
    "\n",
    "def compare_param_dicts(\n",
    "    a: ParamDict, \n",
    "    b: ParamDict,\n",
    "    vocal = False\n",
    ") -> Union[None, Tuple[list[str], list[str]]]:\n",
    "    \"\"\"Compare `ParamDict`s and report discrepancies if `vocal`.\"\"\"\n",
    "    new     = [o for o in b.keys() if o not in a]\n",
    "    missing = [o for o in a.keys() if o not in b]\n",
    "    if len(new) or len(missing):\n",
    "        if vocal: print(f\"Params in b but not in a: {'; '.join(new)} • Params in a but not in b: {'; '.join(missing)}\")\n",
    "        return (new, missing)\n",
    "    else: return None\n",
    "\n",
    "def split_param(param_name: str) -> list[str, Union[str, None]]:\n",
    "    \"\"\"Split `param_name` into base name and affected letters\"\"\"\n",
    "    parts = param_name.split(PARAM_NAME_SEP)\n",
    "    assert len(parts) < 3\n",
    "    return parts if len(parts) == 2 else parts + [None]\n",
    "\n",
    "def join_param(base_name: str, letters: str = None) -> str:\n",
    "    \"\"\"Create a param name from `base_name` and affected `letters`.\"\"\"\n",
    "    return base_name if letters in (None, \"\") else \\\n",
    "           \"\".join((base_name, PARAM_NAME_SEP, *sorted(letters)))\n",
    "\n",
    "def get_param_name(param_name: str) -> str:\n",
    "    \"\"\"Get the base name of `param_name`\"\"\"\n",
    "    return split_param(param_name)[0]\n",
    "\n",
    "def get_param_letters(param_name: str) -> Union[str, None]:\n",
    "    \"\"\"Get the letters `param_name` affects or `None` if not specified.\"\"\"\n",
    "    return split_param(param_name)[1]\n",
    "\n",
    "def param_affects(param_name: str,\n",
    "    letters: str,\n",
    "    incl_general = True,\n",
    "    strict = False,\n",
    "    ) -> bool:\n",
    "    \"\"\"Check if `param_name` affects any of the `letters`. If `incl_general` \n",
    "       also returns `True` for general params. If `strict`, only return \n",
    "       parameters that affect no other `letters`.\"\"\"\n",
    "    assert not strict or not incl_general\n",
    "    pl = get_param_letters(param_name)\n",
    "    if pl is None: return incl_general\n",
    "    for l in pl:\n",
    "        if strict and l not in letters: return False\n",
    "        if not strict and l in letters: return True\n",
    "    return strict\n",
    "\n",
    "def get_param_groups(param_names: list[str]\n",
    "    ) -> OrderedDict:\n",
    "    \"\"\"Divide `param_names` into groups of parameters based on the letters they affect.\"\"\"\n",
    "    groups = {}\n",
    "    for p in param_names:\n",
    "        l = get_param_letters(p)\n",
    "        l = '' if l is None else ''.join(sorted(l))\n",
    "        if l in groups: groups[l].append(p)\n",
    "        else:           groups[l] = [p]\n",
    "    names = sorted(groups.keys(), key=lambda x: (x != '', -len(x), x))\n",
    "    return OrderedDict({k: groups[k] for k in names})\n",
    "\n",
    "def get_effective_params(param_names: list[str],\n",
    "    letters: str,\n",
    "    incl_general = False\n",
    "    ) -> list[str]:\n",
    "    \"\"\"Get the parameters in `param_names` that affect `letters`.\"\"\"\n",
    "    return [o for o in param_names if param_affects(o, letters, incl_general=incl_general)]\n",
    "\n",
    "class InitType(Enum):\n",
    "    DEFAULT = auto()\n",
    "    NEAR_ZERO = auto()\n",
    "    ZERO = auto()\n",
    "\n",
    "INIT_RANGE_DEFAULT = 2.\n",
    "INIT_RANGE_NEAR_ZERO = .1\n",
    "\n",
    "class ParamInterpolator(GetAttr):\n",
    "    \"\"\"Create an interpolator for sigmoid-activated param values passed\n",
    "       by the `FontParamLayer`. Use `asymmetric` for values whose\n",
    "       distribution is highest at `min` and tapers towards `max`.\"\"\"\n",
    "    def __init__(self, \n",
    "        min: float = None, \n",
    "        max: float = None, \n",
    "        asymmetric = False,\n",
    "        init_type = InitType.DEFAULT\n",
    "        ):\n",
    "        if min is None: min = 0.\n",
    "        if max is None: max = 1.\n",
    "        if min == 0 and max == 0 and not asymmetric: self.noop = True\n",
    "        min, max = tensor(min), tensor(max)\n",
    "        self.v_range = max - min\n",
    "        self.noop = False\n",
    "        store_attr()\n",
    "    def __call__(self, \n",
    "        x: Tensor\n",
    "        ) -> Tensor:\n",
    "        return self.interpolate(x)\n",
    "    def interpolate(self, \n",
    "        x: Tensor\n",
    "        ) -> Tensor:\n",
    "        \"\"\"Interpolate `x`.\"\"\"\n",
    "        if self.noop: return x\n",
    "        if self.asymmetric:  x = x.pow(.333)\n",
    "        return self.min + self.v_range * x\n",
    "    def init_param(self, \n",
    "        x: Parameter,\n",
    "        init_range = INIT_RANGE_DEFAULT) -> None:\n",
    "        \"\"\"Randomly initialise `x`.\"\"\"\n",
    "        if   self.init_type == InitType.ZERO:            x.data.zero_()\n",
    "        elif self.init_type == InitType.NEAR_ZERO:       x.data.uniform_(-INIT_RANGE_NEAR_ZERO, INIT_RANGE_NEAR_ZERO)\n",
    "        elif self.init_type in (InitType.DEFAULT, None): x.data.uniform_(-init_range, init_range)\n",
    "        else: raise ValueError(f\"Unknown init_type: {self.init_type}\")\n",
    "\n",
    "# Parameter ranges\n",
    "NONZERO       = 0.05\n",
    "XXSMALL       = 0.05\n",
    "XSMALL        = 0.1\n",
    "SMALL         = 0.25\n",
    "NONFULL       = 0.9\n",
    "LARGE         = 1.5\n",
    "MAX_HEIGHT    = 0.8\n",
    "DEFAULT_ANGLE = 45/180 * math.pi\n",
    "ANGLE_90      = 90/180 * math.pi\n",
    "\n",
    "PRANGE_DEFAULT   = ParamInterpolator( 0.0,     1.0)\n",
    "PRANGE_DOUBLE    = ParamInterpolator( 0.0,     2.0)\n",
    "PRANGE_LARGE     = ParamInterpolator( 0.0,     LARGE)\n",
    "PRANGE_NONFULL   = ParamInterpolator( 0.0,     NONFULL)\n",
    "PRANGE_HALF      = ParamInterpolator( 0.0,     0.5)\n",
    "PRANGE_SMALL     = ParamInterpolator( 0.0,     SMALL)\n",
    "PRANGE_XSMALL    = ParamInterpolator( 0.0,     XSMALL)\n",
    "PRANGE_XXSMALL   = ParamInterpolator( 0.0,     XXSMALL)\n",
    "PRANGE_BIDIR     = ParamInterpolator(-1.0,     1.0)\n",
    "PRANGE_BIDIR_H   = ParamInterpolator(-0.5,     0.5)\n",
    "PRANGE_BIDIR_S   = ParamInterpolator(-SMALL,   SMALL)\n",
    "PRANGE_BIDIR_XS  = ParamInterpolator(-XSMALL,  XSMALL)\n",
    "PRANGE_ZEROIN_XS = ParamInterpolator(-XSMALL,  XSMALL, init_type=InitType.NEAR_ZERO)\n",
    "PRANGE_NONZERO   = ParamInterpolator( NONZERO, 1.0)\n",
    "PRANGE_HEIGHT    = ParamInterpolator( NONZERO, MAX_HEIGHT)\n",
    "PRANGE_NONZERO_H = ParamInterpolator( NONZERO, 0.5)\n",
    "PRANGE_ASYM      = ParamInterpolator( 0.0,     1.0,    asymmetric=True)\n",
    "PRANGE_ASYM_H    = ParamInterpolator( 0.0,     0.5,    asymmetric=True)\n",
    "PRANGE_ASYM_S    = ParamInterpolator( 0.0,     SMALL,  asymmetric=True)\n",
    "PRANGE_ASYM_XS   = ParamInterpolator( 0.0,     XSMALL, asymmetric=True)\n",
    "PRANGE_ANGLE     = ParamInterpolator( -DEFAULT_ANGLE, DEFAULT_ANGLE)\n",
    "PRANGE_ANGLE_90  = ParamInterpolator( 0.0,     ANGLE_90)\n",
    "PRANGE_STROKE    = ParamInterpolator( 0.01,    0.25)\n",
    "PRANGE_WIDTH     = ParamInterpolator( SMALL,   LARGE) # Force a min width to prevent unrecoverable collapse\n",
    "\n",
    "DEFAULT_FONT_PARAM_SPECS = OrderedDict({\n",
    "    \"Height\": PRANGE_HEIGHT,\n",
    "    # \"Slant\": PRANGE_BIDIR,\n",
    "    \"Midline\": PRANGE_DEFAULT,\n",
    "    \"Stroke width\": PRANGE_STROKE,\n",
    "    \"Bowl curvature\": PRANGE_DEFAULT, # Superness: 0: cross, 1: lozenge, 2: circle: Inf: square\n",
    "    \"Width, AV\": PRANGE_WIDTH,\n",
    "    \"Width, BPR\": PRANGE_WIDTH,\n",
    "    \"Width, D\": PRANGE_WIDTH,\n",
    "    \"Width, EF\": PRANGE_WIDTH,\n",
    "    \"Width, CGOQ\": PRANGE_WIDTH, # NB. This is the final width for only O\n",
    "    \"Width, HNU\": PRANGE_WIDTH,\n",
    "    \"Width, J\": PRANGE_WIDTH,\n",
    "    \"Width, K\": PRANGE_WIDTH,\n",
    "    \"Width, L\": PRANGE_WIDTH,\n",
    "    \"Width, M\": PRANGE_WIDTH,\n",
    "    \"Width, S\": PRANGE_WIDTH,\n",
    "    \"Width, TZ\": PRANGE_WIDTH,\n",
    "    \"Width, W\": PRANGE_WIDTH,\n",
    "    \"Width, XY\": PRANGE_WIDTH,\n",
    "    \"Width n difference from O, C\": PRANGE_ASYM_S,\n",
    "    \"Width n difference from E, F\": PRANGE_ASYM_S,\n",
    "    \"Width n difference from O, G\": PRANGE_ASYM_S,\n",
    "    \"Offset x from symmetry, AXZ\": PRANGE_BIDIR_S,\n",
    "    \"Overshoot, AMNVW\":  PRANGE_XSMALL,  # An option is to allow negative values for this\n",
    "    \"Overshoot, CGJOSQ\": PRANGE_XXSMALL, # See: https://en.wikipedia.org/wiki/Overshoot_(typography)\n",
    "    \"Crossbar y offset, A\": PRANGE_BIDIR_H,\n",
    "    \"Crossbar y offset, B\": PRANGE_BIDIR_H,\n",
    "    \"Crossbar y offset, G\": PRANGE_BIDIR_H,\n",
    "    \"Crossbar y offset, P\": PRANGE_BIDIR_H,\n",
    "    \"Crossbar y offset, R\": PRANGE_BIDIR_H,\n",
    "    \"Crotch y offset, Y\": PRANGE_BIDIR_H,\n",
    "    \"Crossbar length, G\": PRANGE_NONFULL,\n",
    "    \"Bar stem height, G\": PRANGE_DEFAULT,\n",
    "    \"Bowl aspect ratio, BPR\": PRANGE_DOUBLE,\n",
    "    \"Bowl aspect ratio, D\": PRANGE_DOUBLE,\n",
    "    \"Bowl aspect ratio, J\": PRANGE_DOUBLE,\n",
    "    \"Bowl aspect ratio, U\": PRANGE_DOUBLE,\n",
    "    \"Bowl distortion, BPR\": PRANGE_ASYM_S,\n",
    "    # \"Bowl distortion, G\": PRANGE_ASYM_S,\n",
    "    \"Bowl distortion, J\": PRANGE_ASYM_S,\n",
    "    \"Upper bowl xn offset, B\": PRANGE_ASYM_S,\n",
    "    \"Upper width n difference, E\": PRANGE_ASYM_S,\n",
    "    \"Upper bowl ratio to lower, S\": PRANGE_NONZERO,\n",
    "    \"Upper bowl xp offset, S\": PRANGE_ASYM_S,\n",
    "    \"Upper width n difference, X\": PRANGE_ASYM_S,\n",
    "    \"Upper width n difference, Z\": PRANGE_ASYM_S,\n",
    "    \"Middle width n difference, E\": PRANGE_ASYM_S,\n",
    "    \"Middle width n difference, F\": PRANGE_ASYM_S,\n",
    "    \"Aperture, CGS\": PRANGE_NONZERO,\n",
    "    \"Aperture, J\": PRANGE_NONZERO,\n",
    "    \"Arm xn offset, K\": PRANGE_ASYM_S,\n",
    "    \"Stem-arm connection height, K\": PRANGE_DEFAULT,\n",
    "    \"Arm-leg connection location, K\": PRANGE_DEFAULT,\n",
    "    \"Stem xp offset from vertical, M\": PRANGE_ASYM_S,\n",
    "    \"Tail angle, Q\": PRANGE_ANGLE_90,\n",
    "    \"Tail length, Q\": PRANGE_NONZERO_H,\n",
    "    \"Tail-bowl connection location, Q\": PRANGE_DEFAULT,\n",
    "    \"Tail inside fraction, Q\": PRANGE_DEFAULT,\n",
    "    \"Leg xp offset, R\": PRANGE_ASYM_S,\n",
    "    \"Leg-bowl connection location, R\": PRANGE_DEFAULT,\n",
    "    \"Leg distortion, R\": PRANGE_ASYM_H,\n",
    "    # Not implemented bc it would too much work to sharpen all corners to match the behaviour\n",
    "    # \"Termination angle deviation, CGJS\": PRANGE_ANGLE\n",
    "    })\n",
    "# These additional parameters are needed for font matching\n",
    "OFFSET_PARAM_SPECS = OrderedDict({\n",
    "    \"Offset y\": PRANGE_ZEROIN_XS\n",
    "    })\n",
    "for l in VOCAB_UC: OFFSET_PARAM_SPECS[f\"Offset x, {l}\"] = PRANGE_ZEROIN_XS\n",
    "FONT_MATCHING_PARAM_SPECS = OrderedDict(\n",
    "    **DEFAULT_FONT_PARAM_SPECS,\n",
    "    **OFFSET_PARAM_SPECS\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Rendering Layer Base\n",
    "\n",
    "> The base for font models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Normaliser(Protocol):\n",
    "    \"\"\"For normalising rasters for the OCR.\"\"\"\n",
    "    mean: float\n",
    "    std: float\n",
    "\n",
    "class VectorRenderLayerBase(Module):\n",
    "    \"\"\"Base for vector render layers. Get's input from a FontParamLayer\n",
    "       and returns the diffvg rendering. Override `create_scenes` in\n",
    "       subclasses and save the results in `self.scenes` of which there\n",
    "       should be `bs`. `forward` calls `render` which renders the\n",
    "       scenes and permutes to match the OCR model. Note that the workflow\n",
    "       is based on greyscale images and we're only using the alpha value\n",
    "       of the diffvg render output.\n",
    "\n",
    "       Params can be defined simply with `n_params` or an `OrderedDict` \n",
    "       `param_specs` that contains each parameter's name and a \n",
    "       `ParamInterpolator` to which the activated param values is passed.\n",
    "       All params have sigmoid activation and, thus, have an output range\n",
    "       of [0, 1] before possible interpolation.\n",
    "       \n",
    "       Init parameters:\n",
    "       `canvas_width`, `canvas_height`: rastered canvas dims\n",
    "       `raster_norm`: use the normaliser from the OCR `dls`\n",
    "       `clip_raster`: whether to clip color values to [0., 1.] as is done when\n",
    "            saving image (note that the values produced by the render\n",
    "            function value wildly up to more than 10. so setting this to\n",
    "            False is advised against)\n",
    "       `apply_gamma`: whether to apply `gamma` to the color values similarly\n",
    "            to clipping above\n",
    "       `n_params`: number of params (with sigmoid activation). Either this or\n",
    "            `param_specs` must be passed.\n",
    "       `param_specs`: `OrderedDict` that contains each parameter's name and a \n",
    "            `ParamInterpolator` to which the activated param values is passed\n",
    "            or a list of these if names are not used.\n",
    "       `vocab`: list of letter strings to which the inputs are matched\n",
    "       `init_range`: defines the range of the   pre-activation parameter \n",
    "            value space when initialised at random by `reset_parameters` \n",
    "            centered around the middle.\n",
    "       `eps`: amount of random jitter added to params, use with care!\n",
    "       `n_colors_out`: color channels out\n",
    "       `max_distance`: the maximum fraction [0., 1.] of canvas dims \n",
    "            `distance_params` can span\n",
    "       `fixed_seed`: fixed seed value to pass to `pydiffvg.RenderFunction`\n",
    "       `gamma`: set to override default gamma of 2.2 for colour images and 1.\n",
    "            for grayscale ones\n",
    "       `stroke_width`: stroke width for shape generator helpers\n",
    "            (note that this is defined as a fraction of `canvas_size`);\n",
    "            either a float or a tuple of min and max width and used by\n",
    "            `expand_stroke_width`\n",
    "       `stroke_color`: default stroke color for shape generator helpers\n",
    "       `samples`: passed to `diffvg.RenderFunction` when rendering scenes\n",
    "       `rendered_callback`: set to an ImageSaver to save interim renders\"\"\"\n",
    "    def __init__(self, canvas_width: int, canvas_height: int, vocab: CategoryMap, \n",
    "                 param_specs: Union[OrderedDict, List[ParamInterpolator]] = None, \n",
    "                 n_params: int = None, seed: int = None, \n",
    "                 init_range = 2., eps: float = None, raster_norm: Normaliser = None, clip_raster = True, \n",
    "                 apply_gamma = True, n_colors_out = 1, max_distance = 1., fixed_seed: int = None, \n",
    "                 gamma: float = None, stroke_width: Union[float, Tuple[float, float]] = 1./28, \n",
    "                 stroke_color = COLOR_BLACK,  samples: int = None,\n",
    "                 rendered_callback: ImageSaver = None):\n",
    "        if max_distance is None: max_distance = 1.\n",
    "        assert max_distance <= 1.\n",
    "        if param_specs is not None: n_params = len(param_specs)\n",
    "        assert n_params is not None and vocab is not None\n",
    "        if seed is not None: torch.random.manual_seed(seed)\n",
    "        super(VectorRenderLayerBase, self).__init__()\n",
    "        self.batch_i = -1\n",
    "        self.bs: int\n",
    "        self.debug = False\n",
    "        self.i: int # Current item index\n",
    "        self.eps_tensor: Tensor\n",
    "        self.param_interpolators: List[ParamInterpolator]\n",
    "        self.param_names: List[str]\n",
    "        self.scenes: List[Scene] = []\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.stored = []\n",
    "        self.weight: List[Parameter] = []\n",
    "        self.x: Tensor\n",
    "        if param_specs:\n",
    "            if isinstance(param_specs, OrderedDict):\n",
    "                self.param_names = list(param_specs.keys())\n",
    "                self.param_interpolators = list(param_specs.values())\n",
    "            elif isinstance(param_specs, list):\n",
    "                self.param_interpolators = param_specs\n",
    "            else: raise ValueError(\"param_specs must of the type Union[OrderedDict, List[ParamInterpolator]]\")\n",
    "        self.weight = []\n",
    "        for i in range(n_params):\n",
    "            p = Parameter(torch.rand([])) # Can't use zeros or empty as they do not create a new Parameter instance!\n",
    "            n = self.param_names[i] if self.param_names else str(i)\n",
    "            self.register_parameter(n, p) # We need to do this manually as we are not saving the params as attributes\n",
    "            self.weight.append(p)\n",
    "        stroke_width = tensor(stroke_width)\n",
    "        if canvas_width != canvas_height: \n",
    "            warn(f\"When canvas is not square ({canvas_width}x{canvas_height}), \"\n",
    "                  \"some dimensions may be expanded outside it.\")\n",
    "        if gamma is None: gamma = 1. if n_colors_out == 1 else 2.2\n",
    "        store_attr()\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def __repr__(self):\n",
    "        p_strings = []\n",
    "        i_pad = math.ceil(math.log(len(self.params), 10))\n",
    "        name_pad = max([len(x) for x in self.param_names])\n",
    "        for i, p in enumerate(self.params):\n",
    "            s = f\"  {i:{i_pad}}\"\n",
    "            if self.param_names: s += f\" {self.param_names[i]:{name_pad}} \"\n",
    "            s += f\"{p.item(): .2f} ({self.get_param_value(i, no_eps=True).item(): .2f})\"\n",
    "            if not p.requires_grad: s += \" <FROZEN>\"\n",
    "            p_strings.append(s)\n",
    "        return \"\\n\".join([f\"{self.__class__.__name__} with params:\"] + p_strings)\n",
    "\n",
    "    def show_params(self, letters: str = None, filter: str = None) -> None:\n",
    "        \"\"\"Show the model's parameters and their values, possibly limited to those\n",
    "           specifically affecting `letters` and matching regex `filter`.\"\"\"\n",
    "        out = self.__repr__()\n",
    "        if letters or filter:\n",
    "            out = \"\\n\".join([x for x in out.split(\"\\n\") if \n",
    "                            (not letters or re.search(f\", {letters}\", x)) and\n",
    "                            (not filter  or re.search(filter, x))])\n",
    "        print(out)\n",
    "\n",
    "    @property\n",
    "    def canvas_size(self) -> int:\n",
    "        \"\"\"The bigger of the canvas dimensions.\"\"\"\n",
    "        return max(self.canvas_width, self.canvas_height)\n",
    "\n",
    "    @property\n",
    "    def params(self) -> List[Tensor]:\n",
    "        \"\"\"A synomym for `weight`. Note that the result is list of parameter tensors.\"\"\"\n",
    "        return self.weight\n",
    "\n",
    "    def reset_parameters(self, init_range=None):\n",
    "        \"\"\"Randomly init the parameters around the middle of possible values.\"\"\"\n",
    "        for p in self.params: self.reset_param(p, init_range=init_range)\n",
    "\n",
    "    def reset_param(self, param: Union[str, int, Parameter], init_range=None) -> None:\n",
    "        \"\"\"Randomly init the parameter.\"\"\"\n",
    "        if init_range is None: init_range = self.init_range\n",
    "        p = self.get_param(param)\n",
    "        if pi := self.get_param_interpolator(p): pi.init_param(p, init_range)\n",
    "        else: p.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def get_param_value(self, param: Union[str, int, Parameter], no_eps = False) -> Tensor:\n",
    "        \"\"\"Get interpolated param value by `param`.\"\"\"\n",
    "        idx = self.get_param_index(param)\n",
    "        p = self.get_param(idx)\n",
    "        v = self.sigmoid(p if no_eps or not self.eps else p + self.eps_tensor[idx])\n",
    "        pi = self.get_param_interpolator(idx)\n",
    "        return pi(v) if pi else v\n",
    "\n",
    "    def get_param_value_for_letter(self, param_name: str, letter: str = None, default_val: Union[Tensor, float] = None, **kwargs) -> Union[Tensor, None]:\n",
    "        \"\"\"A utility method that uses either the `letter` argument of `self.i`\n",
    "           to construct the param name.\"\"\"\n",
    "        assert self.param_names\n",
    "        assert \",\" not in param_name\n",
    "        if letter is None: letter = self.get_letter()\n",
    "        for k in self.param_names:\n",
    "            if get_param_name(k) == param_name and param_affects(k, letter): return self.get_param_value(k, **kwargs)\n",
    "        # raise ValueError(f\"No matching parameter for {param_name} and {letter}.\")\n",
    "        return None if default_val is None else tensor(default_val)\n",
    "\n",
    "    def get_param(self, param: Union[str, int, Parameter]) -> Parameter:\n",
    "        \"\"\"Get the param object by `param`.\"\"\"\n",
    "        return param if isinstance(param, Parameter) else self.params[self.get_param_index(param)]\n",
    "\n",
    "    def get_param_dict(self) -> ParamDict:\n",
    "        \"\"\"Get a `dict` containing all parameters and their values.\"\"\"\n",
    "        return {n: self.get_param(n).item() for n in self.param_names}\n",
    "\n",
    "    def get_param_index(self, param: Union[str, int, Parameter]) -> int:\n",
    "        \"\"\"Get the index of the param.\"\"\"\n",
    "        if type(param) is int: return param\n",
    "        return self.params.index(param) if isinstance(param, Parameter) else self.param_names.index(param)\n",
    "\n",
    "    def get_param_name(self, param: Union[str, int, Parameter]) -> int:\n",
    "        \"\"\"Get the name of the param.\"\"\"\n",
    "        assert self.param_names\n",
    "        return param if type(param) is str else self.param_names[self.get_param_index(param)]\n",
    "\n",
    "    def get_param_interpolator(self, param: Union[str, int, Parameter]) -> Union[ParamInterpolator, None]:\n",
    "        \"\"\"Get the param interpolator for `param`.\"\"\"\n",
    "        if not self.param_interpolators: return None\n",
    "        return self.param_interpolators[self.get_param_index(param)]\n",
    "\n",
    "    def load_param_dict(self, param_dict: ParamDict, vocal = True, clip:float = None) -> None:\n",
    "        \"\"\"Set param values based on `param_dict` optionally clipping abs values at `clip`.\"\"\"\n",
    "        comp = compare_param_dicts(self.get_param_dict(), param_dict, vocal=vocal)\n",
    "        new  = comp[0] if comp is not None else []\n",
    "        for p,v in param_dict.items():\n",
    "            if p not in new:\n",
    "                if clip is not None: v = max(min(v, clip), -clip)\n",
    "                self.set_param(p, v)\n",
    "\n",
    "    def set_param(self, param: Union[str, int, Parameter], value: Union[float, Tensor]) -> None:\n",
    "        \"\"\"Set the value for the param by `param`. Mostly for debugging.\"\"\"\n",
    "        self.get_param(param).data = tensor(value)\n",
    "\n",
    "    def get_param_groups(self) -> OrderedDict:\n",
    "        \"\"\"Get param names grouped by the letters they affect.\"\"\"\n",
    "        return get_param_groups(self.param_names)\n",
    "\n",
    "    def get_effective_params(self, letters: str, **kwargs) -> list[str]:\n",
    "        \"\"\"Get param names that affect `letters`.\"\"\"\n",
    "        return get_effective_params(self.param_names, letters, **kwargs)\n",
    "\n",
    "    def freeze_params(self, params: list[Union[str, int, Parameter]], set_to = False) -> None:\n",
    "        \"\"\"Freeze the one or more params by `params` or all of them if no `params` are given.\"\"\"\n",
    "        pp = self.params if len(params) == 0 else [self.get_param(n) for n in params]\n",
    "        for p in pp: p.requires_grad = set_to\n",
    "\n",
    "    def unfreeze_params(self, params: list[Union[str, int, Parameter]]) -> None:\n",
    "        \"\"\"Unfreeze the one or more params by `params`.\"\"\"\n",
    "        self.freeze_params(params, set_to=True)\n",
    "\n",
    "    def get_letter(self, i: int = None) -> string:\n",
    "        \"\"\"Get letter as string for item `i`.\"\"\"\n",
    "        if i is None: i = self.i\n",
    "        return self.vocab[self.get_input(i).int().item()]\n",
    "\n",
    "    def get_input(self, i: int) -> Tensor:\n",
    "        \"\"\"Get the letter category for item `i` in `x`\"\"\"\n",
    "        return self.x[i]\n",
    "\n",
    "    def add_eps(self) -> None:\n",
    "        \"\"\"Apply random eps to params. \n",
    "           Cf. diffvg/apps/generative modeling/rendering.render_lines\"\"\"\n",
    "        if not self.eps: return\n",
    "        self.eps_tensor = self.eps * torch.randn(self.n_params)\n",
    "\n",
    "    def expand_distance(self, vals: Tensor) -> Tensor:\n",
    "        \"\"\"Expand values to a central `self.max_distance` fraction of the canvas.\n",
    "           Coordinates originate from NW.\"\"\"\n",
    "        return self.canvas_size * vals if self.max_distance == 1. else \\\n",
    "               self.canvas_size * ((1 - self.max_distance) / 2 + vals * self.max_distance)\n",
    "\n",
    "    def expand_stroke_width(self, vals: Tensor = None) -> Tensor:\n",
    "        \"\"\"Expand `vals`,  based on `[min_stroke_width, max_stroke_width] * canvas_height`.\n",
    "           Note that we divide by two so that result is in line with traditional usage in\n",
    "           vector software.\"\"\"\n",
    "        if vals is None: \n",
    "            warn(\"Using default stroke width in rendering.\")\n",
    "            vals = tensor(1.)\n",
    "        w = vals * self.stroke_width if self.stroke_width.ndim == 0 \\\n",
    "            else self.stroke_width[0] + vals * (self.stroke_width[1] - self.stroke_width[0])\n",
    "        return w * self.canvas_size / 2\n",
    "\n",
    "    def normalise_raster(self, raster: Tensor) -> Tensor:\n",
    "        \"\"\"Apply normalisation to `raster`. Not useful for grayscale letters.\"\"\"\n",
    "        if not self.raster_norm: return raster\n",
    "        return (raster - self.raster_norm.mean) / self.raster_norm.std \n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        \"\"\"Render letters defined in `x`.\"\"\"\n",
    "        self._forward(x)\n",
    "        return self.render()\n",
    "\n",
    "    def _forward(self, x) -> None:\n",
    "        \"\"\"Prepare for rendering\"\"\"\n",
    "        if x.ndim == 1: x = x.unsqueeze(1)\n",
    "        elif x.ndim != 2: raise ValueError(\"Input can only be 1- or 2-dimensional.\")\n",
    "        self.batch_i += 1\n",
    "        self.x = x\n",
    "        self.bs = x.size(0)\n",
    "        self.add_eps()\n",
    "        self.scenes = [None] * self.bs\n",
    "        self.create_scenes()\n",
    "\n",
    "    def save_svg(self,\n",
    "        fn_stem: Union[Path, str],\n",
    "        letter: str = \"A\", \n",
    "        ) -> None:\n",
    "        \"\"\"Save one or more letters as svg.\"\"\"\n",
    "        x = tensor([self.vocab.index(o) for o in letter])\n",
    "        with eval_model(self):\n",
    "            with torch.no_grad(): self._forward(x) # Create Scenes\n",
    "        for l,s in zip(letter, self.scenes): s.save_svg(f\"{fn_stem}_{l}\")\n",
    "\n",
    "    def create_scenes(self) -> None:\n",
    "        \"\"\"Override this in subclasses to create the vector scenes for the letters.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def create_line_scene(self, shapes: list[Shape]) -> Scene:\n",
    "        \"\"\"Create a simple line-drawing Scene with shapes.\"\"\"\n",
    "        shape_groups = [self.create_line_group(shapes)]\n",
    "        return self.create_scene_from_groups(shapes, shape_groups)\n",
    "\n",
    "    def create_line_group(self, shapes: list[Shape], stroke_color=None, id_offset=0) -> ShapeGroup:\n",
    "        \"\"\"Create a ShapeGroup from shapes for line drawing.\"\"\"\n",
    "        if stroke_color is None: stroke_color = self.stroke_color\n",
    "        return ShapeGroup(shape_ids=tensor([x + id_offset for x in range(len(shapes))]),\n",
    "                          fill_color=None,\n",
    "                          stroke_color=stroke_color,\n",
    "                          use_even_odd_rule=False)\n",
    "\n",
    "    def create_fill_group(self, shapes: list[Shape], fill_color=None, id_offset=0) -> ShapeGroup:\n",
    "        \"\"\"Create a ShapeGroup from shapes for filling.\"\"\"\n",
    "        if fill_color is None: fill_color = self.stroke_color\n",
    "        return ShapeGroup(shape_ids=tensor([x + id_offset for x in range(len(shapes))]),\n",
    "                          fill_color=fill_color,\n",
    "                          stroke_color=None,\n",
    "                          use_even_odd_rule=True)\n",
    "\n",
    "    def create_scene_from_groups(self, shapes: list[Shape], shape_groups: list[ShapeGroup]) -> list:\n",
    "        \"\"\"Create a scene from `shapes` and `shape_groups`.\"\"\"\n",
    "        # Check that there are no duplicate ids\n",
    "        all_ids = torch.concat([x.shape_ids for x in shape_groups])\n",
    "        assert all_ids.numel() == all_ids.unique().numel()\n",
    "        return Scene(shapes=shapes, shape_groups=shape_groups, \n",
    "                     canvas_width=self.canvas_width, canvas_height=self.canvas_height,\n",
    "                     samples=self.samples)\n",
    "    \n",
    "    def create_scene_from_shapes(self, shapes_and_types: list[Tuple[Shape, bool]], stroke_color=None, \n",
    "                                 fill_color=None, bg_color=None) -> list:\n",
    "        \"\"\"Create a scene from `shapes_and_types`, which are tuples of a `Shape` and a boolean \n",
    "           indicating whether the shape is a filled one (`True`) or a line shape. The scene can \n",
    "           optionally have a background.\"\"\"\n",
    "        shapes = []\n",
    "        shape_groups = []\n",
    "        id_offset = 0\n",
    "        if bg_color is not None:\n",
    "            bg = Rect(tensor(0., 0.), tensor(self.canvas_width, self.canvas_height), stroke_width=tensor(0.))\n",
    "            g = self.create_fill_group([bg], fill_color=bg_color, id_offset=id_offset)\n",
    "            shapes.append(bg)\n",
    "            shape_groups.append(g)\n",
    "            id_offset += 1\n",
    "        for s, f in shapes_and_types:\n",
    "            g = self.create_fill_group([s], fill_color=fill_color, id_offset=id_offset) if f else \\\n",
    "                self.create_line_group([s], stroke_color=stroke_color, id_offset=id_offset)\n",
    "            shapes.append(s)\n",
    "            shape_groups.append(g)\n",
    "            id_offset += 1\n",
    "        return self.create_scene_from_groups(shapes, shape_groups) \n",
    "    \n",
    "    def create_mixed_scene(self, line_shapes: list[Shape] = [], fill_shapes: list[Shape] = [], **kwargs) -> list:\n",
    "        \"\"\"Create a scene that has both `line_shapes` and `fill_shapes` and optionally a background.\n",
    "           A shortcut for `create_scene_from_shapes`.\"\"\"\n",
    "        shapes_and_types = [(s, False) for s in line_shapes] + [(s, True) for s in fill_shapes]\n",
    "        return self.create_scene_from_shapes(shapes_and_types, **kwargs)\n",
    "\n",
    "    def create_line_scene_from_points(self, point_tensors: list[Tensor], **kwargs) -> Scene:\n",
    "        \"\"\"Shorthand for `create_line_scene` by passing `point_tensors` that\n",
    "           are converted to polygons.\"\"\"\n",
    "        return self.create_line_scene(*self.points_to_polygons(point_tensors, **kwargs))\n",
    "\n",
    "    def points_to_beziers(self, point_tensors: list[Tensor], n_control_pts: Union[None, list] = None, \n",
    "                          force = False, **kwargs) -> list[Polygon]:\n",
    "        \"\"\"Convert `point_tensors` to a List of pydiffvg Paths. `n_control_pts` \n",
    "           sets the number of control points. It should be a list \n",
    "           If it's None, control points are set to zero, i.e., the path is\n",
    "           rendered as a polyline.\"\"\"\n",
    "        assert type(point_tensors) is list\n",
    "        if n_control_pts is None: n_control_pts = [None] * len(point_tensors)\n",
    "        assert type(n_control_pts) is list and len(point_tensors) == len(n_control_pts)\n",
    "        bezier_control_pts = []\n",
    "        for pt, cpt in zip(point_tensors, n_control_pts):\n",
    "            assert len(pt) >= 4, \"The Bézier must have at least two points\"\n",
    "            if cpt is None: bezier_control_pts.append(tensor([0] * (len(pt) // 2 - 1)))\n",
    "            elif type(cpt) is list: \n",
    "                if not force and pt.numel() / 2 != sum(cpt) + len(cpt) + 1:\n",
    "                    raise ValueError(f\"Number of control points {sum(cpt) + len(cpt) + 1} does not fit path with {pt.numel() / 2} points. \"\n",
    "                          \"Use force=True to override.\", pt, cpt)\n",
    "                bezier_control_pts.append(tensor(cpt))\n",
    "            else: raise ValueError(\"n_control_pts must be of type Union[None, list]\")\n",
    "        return self.points_to_shapes(VectorPath, point_tensors, bezier_control_pts=bezier_control_pts, **kwargs)\n",
    "\n",
    "    def points_to_polygons(self, point_tensors: list[Tensor], **kwargs) -> list[Polygon]:\n",
    "        \"\"\"Convert `point_tensors` to a List of pydiffvg Polygons.\"\"\"\n",
    "        return self.points_to_shapes(Polygon, point_tensors, **kwargs)\n",
    "\n",
    "    def points_to_shapes(self, shape_cls, point_tensors: list[Tensor], stroke_width: Tensor = None, \n",
    "                         is_closed = False, expand_distance = False,\n",
    "                         bezier_control_pts: list[Tensor] = None) -> list:\n",
    "        \"\"\"Convert `point_tensors` to a List of pydiffvg shapes of `shape_cls`.\"\"\"\n",
    "        assert type(point_tensors) is list\n",
    "        args = dict(stroke_width=self.expand_stroke_width() if stroke_width is None else stroke_width,\n",
    "                    is_closed=is_closed)\n",
    "        shapes = []\n",
    "        for i, pt in enumerate(self.reshape_points(point_tensors)):\n",
    "            if expand_distance: pt = self.expand_distance(pt)\n",
    "            if shape_cls is VectorPath: args[\"num_control_points\"] = bezier_control_pts[i]\n",
    "            shapes.append(shape_cls(points=pt, **args))\n",
    "        return shapes\n",
    "\n",
    "    def reshape_points(self, point_tensors: list[Tensor]) -> list[Tensor]:\n",
    "        \"\"\"Ensure that `point_tensor` has a shape of `(N, 2)`.\"\"\"\n",
    "        assert type(point_tensors) is list\n",
    "        return [t if t.ndim == 2 else t.reshape(-1, 2) for t in point_tensors]\n",
    "\n",
    "    def render(self) -> Tensor:\n",
    "        \"\"\"Render `self.scenes` as a raster tensor using pydiffvg.\"\"\"\n",
    "        assert self.scenes is not None and len(self.scenes) == self.bs\n",
    "        cols = self.n_colors_out\n",
    "        output = torch.zeros(self.bs, cols, self.canvas_width, self.canvas_height) # .requires_grad_()\n",
    "        for i, s in enumerate(self.scenes):\n",
    "            raster = s.render(seed=self.fixed_seed)\n",
    "            if self.rendered_callback: \n",
    "                self.rendered_callback(raster=raster, batch_i=self.batch_i, item_i=i, scene=s, target=self.get_letter(i))\n",
    "            if cols in (1, 3):\n",
    "                # Output is w,h,rgba, where with values in 0.-1. (and black thus 0., 0., 0., 1.)\n",
    "                # First, we apply alpha by mixing output with white in that proportion\n",
    "                if self.debug: self.stored.append(raster.clone())\n",
    "                alpha = raster[:, :, 3].unsqueeze(2).expand(-1, -1, 4)\n",
    "                white = torch.full_like(raster, 1.) * (1. - alpha)\n",
    "                raster = (white + raster * alpha)[:, :, :3] # Now raster is w,h,rgb\n",
    "                if cols == 1: # Convert to grayscale if needed\n",
    "                    raster *= RGBA_TO_GS # This is a crude NTSC sampling to grayscale\n",
    "                    raster = raster.sum(-1, keepdims=True)\n",
    "                raster = raster.permute(2, 0, 1) # Order channel-first\n",
    "            elif cols != 4: raise NotImplementedError(f\"n_colors_out '{cols}' can only be 1, 3 or 4.\")\n",
    "            raster = self.normalise_raster(raster)\n",
    "            if self.clip_raster: raster = raster.clip(0., 1.)\n",
    "            if self.apply_gamma: \n",
    "                if cols == 1: raster = raster.pow(1.0/self.gamma)\n",
    "                else: raster[:,:,:3] = raster[:,:,:3].pow(1.0/self.gamma)\n",
    "            # assert raster.requires_grad\n",
    "            output[i] = raster\n",
    "        return output\n",
    "\n",
    "add_docs(VectorRenderLayerBase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans Serif Font Model\n",
    "\n",
    "> The first sans-serif font rendering layer model with all 26 uppercase alphabets. Note that this model relies heavily the constant `DEFAULT_FONT_PARAM_SPECS`, above, although that can be overriden upon initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class SansSerifFontRL(VectorRenderLayerBase):\n",
    "    \"\"\"A model for rendering a whole sans serif font. Init takes `vocab`\n",
    "       to define which letters are allowed. `param_specs` defines the \n",
    "       value ranges for the parameters (see source).\"\"\"\n",
    "    \n",
    "    def __init__(self, param_specs: OrderedDict = DEFAULT_FONT_PARAM_SPECS, max_distance=1.0, **kwargs):\n",
    "        assert param_specs is not None\n",
    "        assert max_distance == 1.0, \"Do not use max_distance with SansSerifFontRL\"\n",
    "        # Note that we allow the full range for stroke_width as it's restrictions are\n",
    "        # done in param_specs \n",
    "        super(SansSerifFontRL, self).__init__(param_specs=param_specs, max_distance=max_distance,\n",
    "                                              stroke_width=(0., 1.), **kwargs)\n",
    "\n",
    "    def crop_box(self, p1=tensor(0., 0.), p2=tensor(1., 1.), expand_distance=True) -> pydiffvg.Rect:\n",
    "        \"\"\"Create a cropping box with corner points `p1` and `p2`.\"\"\"\n",
    "        return pydiffvg.Rect(self.expand_distance(p1) if expand_distance else p1, \n",
    "                             self.expand_distance(p2) if expand_distance else p2, \n",
    "                             stroke_width=tensor(0.))\n",
    "\n",
    "    def create_scenes(self) -> None:\n",
    "        \"\"\"Create scenes for rendering for the whole batch contained in `self.x`.\"\"\"\n",
    "\n",
    "        # Shortcuts\n",
    "        def P(param, default_val=0.): return self.get_param_value_for_letter(param, default_val=default_val)\n",
    "        def pt(x, y): return concat_tensors(x, y)\n",
    "\n",
    "        for i in range(self.bs):\n",
    "            # Create letter shapes for each letter in the batch\n",
    "            # NB. For curved shapes, we use a rough approximation of a \n",
    "            # superellipse with pure extension of bézier handles, which \n",
    "            # cannot yield as star shapes (n < 1) nor full squares (n ~ Inf).\n",
    "            # We thus limit the handle extension to [0, segment length].\n",
    "            # Curves are mostly governed by the parameters:\n",
    "            # - Bowl curvature\n",
    "            # - Bowl aspect ratio\n",
    "            # - Bowl distortion\n",
    "            # Current letter\n",
    "            self.i = i\n",
    "            letter = self.get_letter()\n",
    "            # General params\n",
    "            p_curvature = P(\"Bowl curvature\")\n",
    "            p_height    = P(\"Height\")\n",
    "            p_offset_y  = P(\"Offset y\")\n",
    "            # p_slant   = P(\"Slant\") # NOT USED\n",
    "            p_midline   = P(\"Midline\", default_val=.5)\n",
    "            p_stroke_w  = P(\"Stroke width\")\n",
    "            # Local params we will already use for calculating the bbox\n",
    "            p_width     = P(\"Width\")\n",
    "            p_overshoot = P(\"Overshoot\")\n",
    "            p_offset_x  = P(\"Offset x\")\n",
    "            # Precalculated properties\n",
    "            expanded_stroke_w = self.expand_stroke_width(p_stroke_w)\n",
    "            bbox = get_bounding_box(p_height=p_height, p_width=p_width, p_stroke_w=p_stroke_w, letter=letter, \n",
    "                                    p_overshoot=p_overshoot, p_offset_x=p_offset_x, p_offset_y=p_offset_y)\n",
    "            w, h = bbox.width, bbox.height\n",
    "            # Note that bbox.top and .bottom refer to vertex position taking into account overshoot \n",
    "            # and stroke width. Cap_height_y and baseline_y, below, are mostly used for cropping the \n",
    "            # stroked results so we have to do a bit of calculations to get them right.\n",
    "            dw = p_stroke_w / 2\n",
    "            cap_height_y = torch.clamp((1. - p_height) / 2 + (0 if p_offset_y is None else p_offset_y), min=0.)\n",
    "            baseline_y   = torch.clamp(cap_height_y + p_height,                                         max=1.)\n",
    "            midline_y    = cap_height_y + p_height * p_midline\n",
    "            # A utility to get the y for an offset from the midline as fraction of the available height\n",
    "            def midline_offset(p_offset):\n",
    "                return (midline_y - bbox.top) * (1 + p_offset) + bbox.top if p_offset < 0 else \\\n",
    "                       (bbox.bottom - midline_y) * p_offset + midline_y\n",
    "            # We fill this with the functions below\n",
    "            shapes_and_types: list[Tuple[Shape, bool]] = []\n",
    "            def add_paths(pts, n_control_pts=None, filled=False):\n",
    "                assert type(pts) is list\n",
    "                for pt in pts: assert isinstance(pt, Tensor)\n",
    "                assert n_control_pts is None or type(n_control_pts) is list\n",
    "                ss = self.points_to_beziers(pts, n_control_pts=n_control_pts, stroke_width=expanded_stroke_w, \n",
    "                                            expand_distance=True)\n",
    "                for s in ss: shapes_and_types.append((s, filled))\n",
    "            def add_masks(*a, **kwa): add_paths(*a, **kwa, filled=True)\n",
    "\n",
    "            if letter == \"A\":\n",
    "                # Shapes:\n",
    "                # inverted V shape (angles of the V can be asymmetrically slanted)\n",
    "                # crossbar\n",
    "                # Local params\n",
    "                p_asymmetry_offset = P(\"Offset x from symmetry\")\n",
    "                p_crossbar_offset  = P(\"Crossbar y offset\")\n",
    "                # Get iV relative center\n",
    "                center_dx = w / 2 * (1 + p_asymmetry_offset)\n",
    "                # Calc iV x/y ratios for placing the crossbar\n",
    "                ratio_l = center_dx / h\n",
    "                ratio_r = (w - center_dx) / h\n",
    "                # Not implemented bc of rounding: we need to extend the strokes beyond the baseline\n",
    "                # so that the rounded ends aren't shown. We extend them so that their\n",
    "                # y coordinates are half stroke_w below the baseline.\n",
    "                # iv_dy   = p_stroke_w / 2\n",
    "                # iv_dx_l = iv_dy * ratio_l * -1\n",
    "                # iv_dx_r = iv_dy * ratio_r\n",
    "                # Calc crossbar coordinates as offsets from the bottom corners\n",
    "                bar_y    = midline_offset(p_crossbar_offset)\n",
    "                bar_dy   = bar_y - bbox.bottom\n",
    "                bar_dx_l = bar_dy * ratio_l * -1\n",
    "                bar_dx_r = bar_dy * ratio_r\n",
    "                # Create points tensors\n",
    "                pts_iv = concat_tensors(\n",
    "                    bbox.btm_lft,\n",
    "                    bbox.left + center_dx, bbox.top,\n",
    "                    bbox.btm_rgt,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                pts_bar = concat_tensors(\n",
    "                    bbox.left + bar_dx_l,  bar_y, \n",
    "                    bbox.right + bar_dx_r, bar_y\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts_iv, pts_bar])\n",
    "\n",
    "            elif letter == \"B\":\n",
    "                # Shapes: \n",
    "                # vertical stem\n",
    "                # upper bowl with straight horisontal parts\n",
    "                # lower bowl\n",
    "                # Local params\n",
    "                p_bowl_ratio        = P(\"Bowl aspect ratio\")\n",
    "                p_bowl_distortion   = P(\"Bowl distortion\")\n",
    "                p_upper_bowl_offset = P(\"Upper bowl xn offset\")\n",
    "                p_crossbar_offset   = P(\"Crossbar y offset\")\n",
    "                # Upper bowl y and x radius\n",
    "                bar_y = midline_offset(p_crossbar_offset)\n",
    "                ub_rad_y = (bar_y - bbox.top) / 2 \n",
    "                ub_rad_x = torch.min(w, ub_rad_y * p_bowl_ratio)\n",
    "                # Upper bowl straight part length\n",
    "                ub_line_x = (w - ub_rad_x) * (1 - p_upper_bowl_offset)\n",
    "                # The same for the lower bowl\n",
    "                bb_rad_y = h / 2 - ub_rad_y\n",
    "                bb_rad_x = torch.min(w, bb_rad_y * p_bowl_ratio)\n",
    "                bb_line_x = w - bb_rad_x\n",
    "                bb_top = bbox.top + 2 * ub_rad_y\n",
    "                # Negative dx applied to junction of the bowls\n",
    "                jnct_dx = p_bowl_distortion\n",
    "                # Stem\n",
    "                pts_stem = concat_tensors(\n",
    "                    bbox.top_lft, \n",
    "                    bbox.btm_lft, \n",
    "                    flatten=True\n",
    "                    )\n",
    "                # Upper bowl\n",
    "                ub_crv, ub_crv_cpts = bowl(\n",
    "                    rad_x=ub_rad_x,\n",
    "                    rad_y=ub_rad_y,\n",
    "                    x=bbox.left + ub_line_x,\n",
    "                    y=bbox.top,\n",
    "                    curvature=p_curvature,\n",
    "                    bowl_type=BowlType.SEMICIRCLE_RIGHT,\n",
    "                    distort=dict(btm_rgt_x = -1 * jnct_dx)\n",
    "                    )\n",
    "                pts_upper_bowl = concat_tensors(\n",
    "                    bbox.left, bbox.top,                # Origin\n",
    "                    ub_crv,                             # Curve\n",
    "                    bbox.left, bbox.top + ub_rad_y * 2, # End of line to stem\n",
    "                    flatten=True\n",
    "                    )\n",
    "                cpts_upper_bowl = [0] + ub_crv_cpts + [0]\n",
    "                # Bottom bowl\n",
    "                bb_crv, bb_crv_cpts = bowl(\n",
    "                    rad_x=bb_rad_x,\n",
    "                    rad_y=bb_rad_y,\n",
    "                    x=bbox.left + bb_line_x,\n",
    "                    y=bb_top,\n",
    "                    curvature=p_curvature,\n",
    "                    bowl_type=BowlType.SEMICIRCLE_RIGHT,\n",
    "                    distort=dict(top_rgt_x = -1 * jnct_dx)\n",
    "                    )\n",
    "                pts_bottom_bowl = concat_tensors(\n",
    "                    bbox.left + ub_line_x, bb_top,      # Origin at end of upper curve\n",
    "                    bb_crv,                             # Curve\n",
    "                    bbox.left, bbox.bottom,             # End of line to stem\n",
    "                    flatten=True\n",
    "                    )\n",
    "                cpts_bottom_bowl = [0] + bb_crv_cpts + [0]\n",
    "                # Add shapes\n",
    "                add_paths([pts_stem, pts_upper_bowl, pts_bottom_bowl],\n",
    "                          [None, cpts_upper_bowl, cpts_bottom_bowl])\n",
    "\n",
    "            elif letter == \"C\":\n",
    "                # Shapes: \n",
    "                # left semicircle\n",
    "                # top-right curve\n",
    "                # bottom-right curve = top-right curve reflected\n",
    "                # NI: mask to create straight terminals\n",
    "                # Local params\n",
    "                p_width_diff        = P(\"Width n difference from O\")\n",
    "                p_aperture          = P(\"Aperture\")\n",
    "                # NI: p_term_angle_d      = P(\"Termination angle deviation\")\n",
    "                # Y and x radii, x is different for the left and right semicircles\n",
    "                rad_y = h / 2 \n",
    "                lft_rad_x = w / 2\n",
    "                rgt_rad_x = lft_rad_x * (1 - p_width_diff)\n",
    "                rgt_crv_x = bbox.left + lft_rad_x\n",
    "                # Semicircle\n",
    "                lft_sr, lft_sr_cpts = bowl(\n",
    "                    rad_x=lft_rad_x,\n",
    "                    rad_y=rad_y,\n",
    "                    x=bbox.left,\n",
    "                    y=bbox.top,\n",
    "                    curvature=p_curvature,\n",
    "                    bowl_type=BowlType.SEMICIRCLE_LEFT\n",
    "                    )\n",
    "                # Top arc\n",
    "                arc_rad = rad_y * (1 - p_aperture)\n",
    "                ctr_y = bbox.top + rad_y\n",
    "                top_arc, top_arc_cpts = curve(\n",
    "                    rad_x=rgt_rad_x,\n",
    "                    rad_y=arc_rad,\n",
    "                    x=rgt_crv_x,\n",
    "                    y=bbox.top,\n",
    "                    curvature=p_curvature\n",
    "                    )\n",
    "                # Just reflect the top arc for the bottom\n",
    "                btm_arc  = mirror(top_arc, ctr_y)\n",
    "                # NI: Create a mask to straighten the end point of the curve\n",
    "                # top_mask = terminal_mask(\n",
    "                #     curve=top_arc,\n",
    "                #     t=None,\n",
    "                #     area_p1=concat_tensors(rgt_crv_x, 0.),\n",
    "                #     area_p2=concat_tensors(1., ctr_y),\n",
    "                #     angle_deviation=p_term_angle_d\n",
    "                #     )\n",
    "                # NI: btm_mask = mirror(top_mask, ctr_y)\n",
    "                # Add shapes\n",
    "                add_paths([lft_sr, top_arc, btm_arc], \n",
    "                          [lft_sr_cpts, top_arc_cpts, top_arc_cpts])\n",
    "                # add_masks([top_mask, btm_mask])\n",
    "\n",
    "            elif letter == \"D\":\n",
    "                # Shapes: \n",
    "                # bowl with straight horisontal parts joined with stem\n",
    "                p_bowl_ratio = P(\"Bowl aspect ratio\")\n",
    "                # Bowl x radius\n",
    "                rad_x = torch.min(w, h / 2 / p_bowl_ratio)\n",
    "                # Horisontal line length\n",
    "                line_x = w - rad_x\n",
    "                # Bowl\n",
    "                crv, crv_cpts = bowl(\n",
    "                    rad_x=rad_x,\n",
    "                    rad_y=h / 2,\n",
    "                    x=bbox.left + line_x,\n",
    "                    y=bbox.top,\n",
    "                    curvature=p_curvature,\n",
    "                    bowl_type=BowlType.SEMICIRCLE_RIGHT\n",
    "                    )\n",
    "                pts = concat_tensors(\n",
    "                    bbox.top_lft,\n",
    "                    crv,\n",
    "                    bbox.btm_lft,\n",
    "                    bbox.top_lft\n",
    "                    )\n",
    "                cpts = [0] + crv_cpts + [0, 0]\n",
    "                # Add shapes\n",
    "                add_paths([pts], [cpts])\n",
    "\n",
    "            elif letter == \"E\":\n",
    "                # Shapes:\n",
    "                # square C-shape\n",
    "                # crossbar\n",
    "                # Local params\n",
    "                p_top_dx = P(\"Upper width n difference\")\n",
    "                p_bar_dx = P(\"Middle width n difference\")\n",
    "                top_dx = w * p_top_dx\n",
    "                bar_dx = w * p_bar_dx\n",
    "                bar_y = midline_y\n",
    "                # Create points tensors\n",
    "                pts_c = concat_tensors(\n",
    "                    bbox.btm_rgt,\n",
    "                    bbox.btm_lft,\n",
    "                    bbox.top_lft,\n",
    "                    bbox.right - top_dx,  bbox.top,       \n",
    "                    flatten=True\n",
    "                    )\n",
    "                pts_bar = concat_tensors(\n",
    "                    bbox.left,            bar_y, \n",
    "                    bbox.right - bar_dx,  bar_y\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts_c, pts_bar])\n",
    "\n",
    "            elif letter == \"F\":\n",
    "                # Shapes:\n",
    "                # inverted L shape\n",
    "                # crossbar\n",
    "                # Local params\n",
    "                p_width_diff = P(\"Width n difference from E\")\n",
    "                p_bar_dx     = P(\"Middle width n difference\")\n",
    "                top_dx = w * p_width_diff\n",
    "                bar_dx = w * torch.clamp(p_width_diff + p_bar_dx, max=1.)\n",
    "                bar_y = midline_y\n",
    "                # Create points tensors\n",
    "                pts_il = concat_tensors(\n",
    "                    bbox.btm_lft,\n",
    "                    bbox.top_lft,\n",
    "                    bbox.right - top_dx,  bbox.top,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                pts_bar = concat_tensors(\n",
    "                    bbox.left,            bar_y, \n",
    "                    bbox.right - bar_dx,  bar_y\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts_il, pts_bar])\n",
    "\n",
    "            elif letter == \"G\":\n",
    "                # Shapes: \n",
    "                # left semicircle\n",
    "                # top-right arc\n",
    "                # bottom-right arc\n",
    "                # crossbar with stem = inverted L\n",
    "                # NI: mask to create straight terminal at the top right\n",
    "                # NI: mask to create straight terminal for the crossbar\n",
    "                p_width_diff        = P(\"Width n difference from O\")\n",
    "                p_aperture          = P(\"Aperture\")\n",
    "                # p_term_angle_d      = P(\"Termination angle deviation\")\n",
    "                # p_bowl_distortion   = P(\"Bowl distortion\")\n",
    "                p_crossbar_offset   = P(\"Crossbar y offset\")\n",
    "                p_bar_length        = P(\"Crossbar length\")\n",
    "                p_stem_height       = P(\"Bar stem height\")\n",
    "                # We need to this to calculate both the right arcs' dimensions\n",
    "                bar_y     = midline_offset(p_crossbar_offset)\n",
    "                rad_y     = h / 2 \n",
    "                lft_rad_x = w / 2\n",
    "                rgt_rad_x = lft_rad_x * (1 - p_width_diff)\n",
    "                rgt_crv_x = bbox.left + lft_rad_x\n",
    "                # The true right bound of the letter\n",
    "                rgt = bbox.right - w / 2 + rgt_rad_x\n",
    "                # Left semicircle\n",
    "                lft_sr, lft_sr_cpts = bowl(\n",
    "                    rad_x=lft_rad_x,\n",
    "                    rad_y=rad_y,\n",
    "                    x=bbox.left,\n",
    "                    y=bbox.top,\n",
    "                    curvature=p_curvature,\n",
    "                    bowl_type=BowlType.SEMICIRCLE_LEFT\n",
    "                    )\n",
    "                # Top arc\n",
    "                arc_rad = (bar_y - bbox.top) * (1 - p_aperture)\n",
    "                top_arc, top_arc_cpts = curve(\n",
    "                    rad_x=rgt_rad_x,\n",
    "                    rad_y=arc_rad,\n",
    "                    x=rgt_crv_x,\n",
    "                    y=bbox.top,\n",
    "                    curvature=p_curvature\n",
    "                    )\n",
    "                # NI: Create a mask to straighten the end point of the curve\n",
    "                # ctr_y = bbox.top + rad_y\n",
    "                # top_mask = terminal_mask(\n",
    "                #     curve=top_arc,\n",
    "                #     t=None,\n",
    "                #     area_p1=concat_tensors(rgt_crv_x, 0.),\n",
    "                #     area_p2=concat_tensors(1., ctr_y),\n",
    "                #     angle_deviation=p_term_angle_d\n",
    "                #     )\n",
    "                # The bottom-right part is a tricky one\n",
    "                # We need a curve that starts with one control point before connecting\n",
    "                # to the inverted L shape that makes up the crossbar and its stem\n",
    "                # We don't want the bar to reach the left bow, so we deduct the width\n",
    "                # of the rounded stroke end\n",
    "                bar_lft  = rgt - w * torch.clamp(p_bar_length - p_stroke_w, min=0.)\n",
    "                stem_hgt = (bbox.bottom - bar_y) * p_stem_height\n",
    "                stem_btm = bar_y + stem_hgt\n",
    "                # Inverted L\n",
    "                il_pts = concat_tensors(\n",
    "                    bar_lft, bar_y,\n",
    "                    rgt,     bar_y,\n",
    "                    rgt,     stem_btm\n",
    "                    )\n",
    "                # Bottom arc\n",
    "                btm_arc_rad_y = bbox.bottom - bar_y - stem_hgt\n",
    "                btm_arc, btm_arc_cpts = curve(\n",
    "                    rad_x=rgt_rad_x,\n",
    "                    rad_y=btm_arc_rad_y * -1,\n",
    "                    x=rgt_crv_x,\n",
    "                    y=bbox.bottom,\n",
    "                    curvature=p_curvature\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([lft_sr, top_arc, btm_arc, il_pts],\n",
    "                          [lft_sr_cpts, top_arc_cpts, btm_arc_cpts, None])\n",
    "\n",
    "            elif letter == \"H\":\n",
    "                # Shapes:\n",
    "                # stems\n",
    "                # crossbar\n",
    "                bar_y = midline_y\n",
    "                # Create points tensors\n",
    "                pts_stem_l = concat_tensors(\n",
    "                    bbox.btm_rgt,\n",
    "                    bbox.top_rgt,    \n",
    "                    flatten=True\n",
    "                    )\n",
    "                pts_stem_r = concat_tensors(\n",
    "                    bbox.btm_lft,\n",
    "                    bbox.top_lft,    \n",
    "                    flatten=True\n",
    "                    )\n",
    "                pts_bar = concat_tensors(\n",
    "                    bbox.left,   bar_y, \n",
    "                    bbox.right,  bar_y\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts_stem_l, pts_stem_r, pts_bar])\n",
    "\n",
    "            elif letter == \"I\":\n",
    "                # Shapes:\n",
    "                # stem\n",
    "                pts_stem = concat_tensors(\n",
    "                    bbox.btm_rgt,\n",
    "                    bbox.top_rgt,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts_stem])\n",
    "\n",
    "            elif letter == \"J\":\n",
    "                # Shapes: \n",
    "                # stem\n",
    "                # bowl consisting of two demicircles\n",
    "                # (one of which is hidden if aperture is > .5)\n",
    "                p_bowl_ratio        = P(\"Bowl aspect ratio\")\n",
    "                p_bowl_distortion   = P(\"Bowl distortion\")\n",
    "                p_aperture          = P(\"Aperture\")\n",
    "                # Calculate the semicircle proportions, which we'll later\n",
    "                # truncate. NB. We draw them clockwise\n",
    "                rad_x  = w / 2\n",
    "                rad_y  = torch.min(h, rad_x / p_bowl_ratio)\n",
    "                bowl_y = bbox.bottom - rad_y\n",
    "                pts_bowl, cpts_bowl = bowl(\n",
    "                    rad_x=rad_x,\n",
    "                    rad_y=rad_y,\n",
    "                    x=bbox.left,\n",
    "                    y=bowl_y,\n",
    "                    curvature=p_curvature,\n",
    "                    distort=dict(btm_lft_x = -1 * p_bowl_distortion),\n",
    "                    bowl_type=BowlType.SEMICIRCLE_BOTTOM\n",
    "                    )\n",
    "                pts_bowl_cut = cut_semicircle(pts_bowl, 1 - p_aperture)\n",
    "                # Adjust position because of truncation to align to bottom centre\n",
    "                pts_bowl_cut_2 = pts_bowl_cut.reshape((-1, 2))\n",
    "                bowl_btm = pts_bowl_cut_2[:, 1].max()\n",
    "                dy = bbox.bottom - bowl_btm\n",
    "                bowl_w = pts_bowl_cut_2[:, 0].max() - pts_bowl_cut_2[:, 0].min()\n",
    "                dx = (bowl_w - w) / 2\n",
    "                pts_bowl_out = (pts_bowl_cut_2 + pt(dx, dy)).flatten()\n",
    "                # The stem is easy\n",
    "                pts_stem = concat_tensors(\n",
    "                    bbox.right + dx,  bbox.top,\n",
    "                    bbox.right + dx,  bowl_y + dy,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts_stem, pts_bowl_out],\n",
    "                          [None, cpts_bowl])\n",
    "\n",
    "            elif letter == \"K\":\n",
    "                # Shapes:\n",
    "                # stem\n",
    "                # arm\n",
    "                # leg\n",
    "                p_arm_x_offset = P(\"Arm xn offset\")\n",
    "                p_arm_stem_y   = P(\"Stem-arm connection height\")\n",
    "                p_arm_leg_conn = P(\"Arm-leg connection location\")\n",
    "                # First, calculate the arm coordinates\n",
    "                arm_y1 = bbox.bottom - h * p_arm_stem_y\n",
    "                arm_x2 = bbox.right - w * p_arm_x_offset\n",
    "                pts_arm = concat_tensors(\n",
    "                    bbox.left, arm_y1,\n",
    "                    arm_x2,    bbox.top\n",
    "                    )\n",
    "                # The leg connects to the arm at p_arm_leg_conn\n",
    "                leg_p1 = pts_arm[:2] + p_arm_leg_conn * (pts_arm[2:] - pts_arm[:2])\n",
    "                pts_leg = concat_tensors(\n",
    "                    leg_p1,\n",
    "                    bbox.btm_rgt,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                # The stem is trivial\n",
    "                pts_stem = concat_tensors(bbox.top_lft, bbox.btm_lft, flatten=True)\n",
    "                # Add shapes\n",
    "                add_paths([pts_arm, pts_leg, pts_stem])\n",
    "\n",
    "            elif letter == \"L\":\n",
    "                # Shapes:\n",
    "                # L-shape\n",
    "                pts_l = concat_tensors(\n",
    "                    bbox.top_lft,\n",
    "                    bbox.btm_lft,\n",
    "                    bbox.btm_rgt, \n",
    "                    flatten=True\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts_l])\n",
    "\n",
    "            elif letter == \"M\":\n",
    "                # TODO: The top_dx calculation is erroneous as it does not allow for a\n",
    "                #       straight, bold M. See E3 (Arial Bold) for details.\n",
    "                # Shapes:\n",
    "                # M-shape\n",
    "                p_stem_offset = P(\"Stem xp offset from vertical\")\n",
    "                # Calculate the offset to the middle of the top corners\n",
    "                top_dx = torch.min(w / 2, w * p_stem_offset)\n",
    "                btm_x = bbox.left + w / 2\n",
    "                # Start from bottom left\n",
    "                pts_m = concat_tensors(\n",
    "                    bbox.btm_lft,\n",
    "                    bbox.left + top_dx,     bbox.top,\n",
    "                    btm_x,                  bbox.bottom,\n",
    "                    bbox.right - top_dx,    bbox.top,\n",
    "                    bbox.btm_rgt,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts_m])\n",
    "\n",
    "            elif letter == \"N\":\n",
    "                # Shapes:\n",
    "                # N-shape\n",
    "                # Start from bottom left\n",
    "                pts_n = concat_tensors(\n",
    "                    bbox.btm_lft,\n",
    "                    bbox.top_lft,\n",
    "                    bbox.btm_rgt,\n",
    "                    bbox.top_rgt,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts_n])\n",
    "\n",
    "            elif letter in \"OQ\":\n",
    "                # Shapes:\n",
    "                # ellipse\n",
    "                # + tail for Q\n",
    "                pts_o, cpts_o = bowl(\n",
    "                    rad_x=w/2,\n",
    "                    rad_y=h/2,\n",
    "                    x=bbox.left,\n",
    "                    y=bbox.top,\n",
    "                    curvature=p_curvature,\n",
    "                    bowl_type=BowlType.CIRCLE\n",
    "                )\n",
    "                add_paths([pts_o], [cpts_o])\n",
    "                \n",
    "                if letter == \"Q\":\n",
    "                    # Create the tail for Q\n",
    "                    p_tail_angle     = P(\"Tail angle\")\n",
    "                    p_tail_len       = P(\"Tail length\")\n",
    "                    p_tail_bowl_conn = P(\"Tail-bowl connection location\")\n",
    "                    p_tail_inside_f  = P(\"Tail inside fraction\")\n",
    "                    # Calc tail dimensions\n",
    "                    tail_len = h * p_tail_len\n",
    "                    tail_w = p_tail_angle.cos() * tail_len\n",
    "                    tail_h = p_tail_angle.sin() * tail_len\n",
    "                    # Find connection point on the latter half of the bowls SW segment\n",
    "                    conn_t = .5 + .5 * p_tail_bowl_conn\n",
    "                    conn_pt = Bezier(pts_o[6:14]).at(conn_t)\n",
    "                    # Find the tail's position by intersecting it at the connection point\n",
    "                    tail_x = conn_pt[0] - p_tail_inside_f * tail_w\n",
    "                    tail_y = conn_pt[1] - p_tail_inside_f * tail_h\n",
    "                    # Build the tensor\n",
    "                    pts_tail = concat_tensors(\n",
    "                        tail_x,             tail_y,\n",
    "                        tail_x + tail_w,    tail_y + tail_h\n",
    "                        )\n",
    "                    add_paths([pts_tail])\n",
    "\n",
    "            elif letter in \"PR\":\n",
    "                # Shapes: \n",
    "                # vertical stem\n",
    "                # upper bowl with straight horisontal parts\n",
    "                # + leg for R\n",
    "                p_bowl_ratio        = P(\"Bowl aspect ratio\")\n",
    "                p_bowl_distortion   = P(\"Bowl distortion\")\n",
    "                p_crossbar_offset   = P(\"Crossbar y offset\")\n",
    "                # Bowl y and x radius\n",
    "                bar_y = midline_offset(p_crossbar_offset)\n",
    "                rad_y = (bar_y - bbox.top) / 2 \n",
    "                rad_x = torch.min(w, rad_y * p_bowl_ratio)\n",
    "                # Bowl straight part length\n",
    "                line_x = w - rad_x\n",
    "                # Upper bowl\n",
    "                pts_crv, cpts_crv = bowl(\n",
    "                    rad_x=rad_x,\n",
    "                    rad_y=rad_y,\n",
    "                    x=bbox.left + line_x,\n",
    "                    y=bbox.top,\n",
    "                    curvature=p_curvature,\n",
    "                    bowl_type=BowlType.SEMICIRCLE_RIGHT,\n",
    "                    distort=dict(btm_rgt_x = -1 * p_bowl_distortion)\n",
    "                    )\n",
    "                # Add straight parts\n",
    "                pts_bowl = concat_tensors(\n",
    "                    bbox.left, bbox.top,             # Origin\n",
    "                    pts_crv,                         # Curve\n",
    "                    bbox.left, bbox.top + 2 * rad_y, # End of line to stem\n",
    "                    flatten=True\n",
    "                    )\n",
    "                cpts_bowl = [0] + cpts_crv + [0]\n",
    "                # Stem\n",
    "                pts_stem = concat_tensors(bbox.top_lft, bbox.btm_lft, flatten=True)\n",
    "                # Add shapes\n",
    "                add_paths([pts_stem, pts_bowl],\n",
    "                          [None, cpts_bowl])\n",
    "                \n",
    "                if letter == \"R\":\n",
    "                    # Create leg for R\n",
    "                    leg_x_offset   = P(\"Leg xp offset\")\n",
    "                    leg_bowl_conn  = P(\"Leg-bowl connection location\")\n",
    "                    leg_distortion = P(\"Leg distortion\")\n",
    "                    # First find the coords for a straight leg\n",
    "                    str_x1 = bbox.left + line_x * leg_bowl_conn\n",
    "                    str_x2 = torch.clamp(bbox.right + w * leg_x_offset, max=1.)\n",
    "                    str_y1 = bar_y\n",
    "                    str_y2 = bbox.bottom\n",
    "                    str_w  = str_x2 - str_x1\n",
    "                    str_h  = str_y2 - str_y1\n",
    "                    # Then apply the distortion by creating a curve at the start of \n",
    "                    # the leg:\n",
    "                    # - the curve's origin is to the left of str_x1\n",
    "                    # - the curve's end is leg_distortion along the leg\n",
    "                    # – the curve's control points are interpolated at circle\n",
    "                    #   curvature between the ends and str_x1\n",
    "                    crv_x1 = torch.max(bbox.left, str_x1 - str_w * leg_distortion)\n",
    "                    crv_x4 = str_x1 + str_w * leg_distortion\n",
    "                    crv_y4 = str_y1 + str_h * leg_distortion\n",
    "                    crv_x2 = crv_x1 +      CIRCLE_CURVATURE  * (str_x1 - crv_x1)\n",
    "                    crv_x3 = str_x1 + (1 - CIRCLE_CURVATURE) * (crv_x4 - str_x1)\n",
    "                    crv_y3 = str_y1 + (1 - CIRCLE_CURVATURE) * (crv_y4 - str_y1)\n",
    "                    # Create tensor for the whole leg\n",
    "                    pts_leg = concat_tensors(\n",
    "                        crv_x1,     str_y1,\n",
    "                        crv_x2,     str_y1,  # Control point 1\n",
    "                        crv_x3,     crv_y3,  # Control point 2\n",
    "                        crv_x4,     crv_y4,\n",
    "                        str_x2,     str_y2\n",
    "                        )\n",
    "                    cpts_leg = [2, 0]\n",
    "                    add_paths([pts_leg], [cpts_leg])\n",
    "\n",
    "            elif letter == \"S\":\n",
    "                # Shapes:\n",
    "                # truncated semicircles: top-right, bottom-left\n",
    "                # demicircles: top-left, bottom-right\n",
    "                # spine consisting of two connected arcs\n",
    "                # Local params\n",
    "                p_aperture          = P(\"Aperture\")\n",
    "                p_bowl_ratio        = P(\"Upper bowl ratio to lower\")\n",
    "                p_upper_x_offset    = P(\"Upper bowl xp offset\")\n",
    "                # First, calculate the sizes of the bowls and their locations\n",
    "                # The bowls are parametrised by four values:\n",
    "                # (a) the ratio of the upper to the lower bowl (<= 1)\n",
    "                # (b) the “lean”, i.e., the displacement to the right of the upper bowl from\n",
    "                #     central alignment\n",
    "                # (c) width, which is used for the width of the lower bowl\n",
    "                # (d) aperture, which controls the cut-off point of the semicircle \n",
    "                #     segments at the extremes; thus, if aperture = 0, the result is an 8-shape\n",
    "                # We start with the lower one, whose width is the letter width and height is the\n",
    "                # letter height divided by the bowl ratio\n",
    "                lb_rad_x = w / 2\n",
    "                lb_rad_y = h / 2 / (1 + p_bowl_ratio)\n",
    "                ub_rad_x = lb_rad_x * p_bowl_ratio\n",
    "                ub_rad_y = lb_rad_y * p_bowl_ratio\n",
    "                ub_dx    = w * p_upper_x_offset + lb_rad_x - ub_rad_x\n",
    "                lb_dy    = 2 * ub_rad_y\n",
    "                bowl_cut = 1 - p_aperture\n",
    "                # Create the semicircles needed for the top-right (usc) and bottom-left (lsc) \n",
    "                # bowl parts and truncate them\n",
    "                pts_usc, cpts_usc = bowl(\n",
    "                    rad_x=ub_rad_x,\n",
    "                    rad_y=ub_rad_y,\n",
    "                    x=bbox.left + ub_dx + ub_rad_x,\n",
    "                    y=bbox.top,\n",
    "                    curvature=p_curvature,\n",
    "                    bowl_type=BowlType.SEMICIRCLE_RIGHT\n",
    "                    )\n",
    "                pts_usc = cut_semicircle(pts_usc, bowl_cut)\n",
    "                pts_lsc, cpts_lsc = bowl(\n",
    "                    rad_x=lb_rad_x,\n",
    "                    rad_y=lb_rad_y,\n",
    "                    x=bbox.left,\n",
    "                    y=bbox.top + lb_dy,\n",
    "                    curvature=p_curvature,\n",
    "                    bowl_type=BowlType.SEMICIRCLE_LEFT\n",
    "                    )\n",
    "                pts_lsc = cut_semicircle(pts_lsc, bowl_cut)\n",
    "                # Create the top-left and bottom-right demicircles\n",
    "                pts_udc, cpts_udc = bowl(\n",
    "                    rad_x=ub_rad_x,\n",
    "                    rad_y=ub_rad_y,\n",
    "                    x=bbox.left + ub_dx,\n",
    "                    y=bbox.top,\n",
    "                    curvature=p_curvature,\n",
    "                    bowl_type=BowlType.DEMICIRCLE_TOP_LEFT\n",
    "                    )\n",
    "                pts_ldc, cpts_ldc = bowl(\n",
    "                    rad_x=lb_rad_x,\n",
    "                    rad_y=lb_rad_y,\n",
    "                    x=bbox.left + lb_rad_x,\n",
    "                    y=bbox.bottom - lb_rad_y,\n",
    "                    curvature=p_curvature,\n",
    "                    bowl_type=BowlType.DEMICIRCLE_BOTTOM_RIGHT\n",
    "                    )\n",
    "                # Finally, create the spine.\n",
    "                # The spine's middle vertex’ handles are oriented on a line connecting the \n",
    "                # handles of the other end points. The middle segment is thus parametrised \n",
    "                # by curvature with it's endpoints dictated by the demicircles' end points.\n",
    "                # The spine consists of 7 points, of which the 1st, 4th and 7th are the\n",
    "                # vertices, and we start from the top-left. The middle vertex is just the \n",
    "                # average of the endpoints.\n",
    "                sp_p1 = pts_udc[:2]\n",
    "                sp_p7 = pts_ldc[:2]\n",
    "                sp_p4 = sp_p1 + .5 * (sp_p7 - sp_p1)\n",
    "                # Now extend the control points 2 and 6 vertically from the ends\n",
    "                p26_dy = (sp_p7[1] - sp_p1[1]) / 2 * p_curvature\n",
    "                sp_p2 = sp_p1 + pt(0., p26_dy)\n",
    "                sp_p6 = sp_p7 - pt(0., p26_dy)\n",
    "                # The middle vertex' handles (control points 3 and 5) lie on the line\n",
    "                # connecting the other control points and are at a distance defined by\n",
    "                # the curvature\n",
    "                p35_d = (sp_p6 - sp_p2) / 2 * p_curvature\n",
    "                sp_p3 = sp_p4 - p35_d\n",
    "                sp_p5 = sp_p4 + p35_d\n",
    "                # Create the tensor\n",
    "                pts_sp = concat_tensors(sp_p1, sp_p2, sp_p3, sp_p4, sp_p5, sp_p6, sp_p7, flatten=True)\n",
    "                cpts_sp = [2, 2]\n",
    "                # Add shapes\n",
    "                add_paths([ pts_usc,  pts_udc,  pts_sp,  pts_ldc,  pts_lsc], \n",
    "                          [cpts_usc, cpts_udc, cpts_sp, cpts_ldc, cpts_lsc])\n",
    "\n",
    "            elif letter == \"T\":\n",
    "                # Shapes:\n",
    "                # stem\n",
    "                # bar\n",
    "                ctr_x = bbox.left + w / 2\n",
    "                pts_stem = concat_tensors(\n",
    "                    ctr_x,  bbox.bottom,\n",
    "                    ctr_x,  bbox.top,\n",
    "                    )\n",
    "                pts_bar = concat_tensors(\n",
    "                    bbox.top_lft,\n",
    "                    bbox.top_rgt,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts_stem, pts_bar])\n",
    "\n",
    "            elif letter == \"U\":\n",
    "                # Shapes: \n",
    "                # bowl joined to straight vertical stems\n",
    "                p_bowl_ratio = P(\"Bowl aspect ratio\")\n",
    "                # Calc dims\n",
    "                rad_x = w / 2\n",
    "                rad_y = torch.min(h, rad_x / p_bowl_ratio)\n",
    "                # Bowl\n",
    "                crv, crv_cpts = bowl(\n",
    "                    rad_x=rad_x,\n",
    "                    rad_y=rad_y,\n",
    "                    x=bbox.left,\n",
    "                    y=bbox.bottom - rad_y,\n",
    "                    curvature=p_curvature,\n",
    "                    bowl_type=BowlType.SEMICIRCLE_BOTTOM\n",
    "                    )\n",
    "                # Add stems\n",
    "                pts = concat_tensors(\n",
    "                    bbox.top_rgt,\n",
    "                    crv,\n",
    "                    bbox.top_lft\n",
    "                    )\n",
    "                cpts = [0] + crv_cpts + [0]\n",
    "                # Add shapes\n",
    "                add_paths([pts], [cpts])\n",
    "\n",
    "            elif letter == \"V\":\n",
    "                # Shapes: \n",
    "                # V-shape\n",
    "                pts = concat_tensors(\n",
    "                    bbox.top_rgt,\n",
    "                    bbox.left + w / 2,      bbox.bottom,\n",
    "                    bbox.top_lft,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts])\n",
    "\n",
    "            elif letter == \"W\":\n",
    "                # Shapes: \n",
    "                # two connected V-shapes\n",
    "                pts = concat_tensors(\n",
    "                    bbox.top_rgt,\n",
    "                    bbox.right - w / 4,     bbox.bottom,\n",
    "                    bbox.right - w / 2,     bbox.top,\n",
    "                    bbox.left + w / 4,      bbox.bottom,\n",
    "                    bbox.top_lft,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts])\n",
    "\n",
    "            elif letter == \"X\":\n",
    "                # Shapes: \n",
    "                # rising stroke\n",
    "                # falling stroke\n",
    "                # Local parameters\n",
    "                p_asymmetry_offset  = P(\"Offset x from symmetry\")\n",
    "                p_upper_w_diff      = P(\"Upper width n difference\")\n",
    "                # Calculate upper vertices\n",
    "                top_w   = w * (1 - p_upper_w_diff)\n",
    "                top_ctr_x = bbox.left + w / 2 * (1 + p_asymmetry_offset)\n",
    "                top_lft_x = top_ctr_x - top_w / 2\n",
    "                top_rgt_x = top_ctr_x + top_w / 2\n",
    "                # Create tensors\n",
    "                pts_rs = concat_tensors(\n",
    "                    top_rgt_x,             bbox.top,\n",
    "                    bbox.btm_lft,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                pts_fs = concat_tensors(\n",
    "                    bbox.btm_rgt,\n",
    "                    top_lft_x,             bbox.top,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts_rs, pts_fs])\n",
    "\n",
    "            elif letter == \"Y\":\n",
    "                # Shapes:\n",
    "                # V-shape\n",
    "                # stem\n",
    "                # Local params\n",
    "                p_crotch_offset = P(\"Crotch y offset\")\n",
    "                # Calc crotch bottom\n",
    "                crotch_y = midline_offset(p_crotch_offset)\n",
    "                ctr_x = bbox.left + w / 2\n",
    "                pts_v = concat_tensors(\n",
    "                    bbox.top_rgt,\n",
    "                    ctr_x,          crotch_y,\n",
    "                    bbox.top_lft,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                pts_stem = concat_tensors(\n",
    "                    ctr_x,          crotch_y,\n",
    "                    ctr_x,          bbox.bottom\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts_v, pts_stem])\n",
    "\n",
    "            elif letter == \"Z\":\n",
    "                # Shapes:\n",
    "                # Z-shape\n",
    "                # Local params\n",
    "                p_asymmetry_offset = P(\"Offset x from symmetry\")\n",
    "                p_upper_w_diff     = P(\"Upper width n difference\")\n",
    "                # Calculate upper vertices\n",
    "                top_w   = w * (1 - p_upper_w_diff)\n",
    "                top_ctr_x = bbox.left + w / 2 * (1 + p_asymmetry_offset)\n",
    "                top_lft_x = top_ctr_x - top_w / 2\n",
    "                top_rgt_x = top_ctr_x + top_w / 2\n",
    "                # Create tensor\n",
    "                pts = concat_tensors(\n",
    "                    top_lft_x,      bbox.top,\n",
    "                    top_rgt_x,      bbox.top,\n",
    "                    bbox.btm_lft,\n",
    "                    bbox.btm_rgt,\n",
    "                    flatten=True\n",
    "                    )\n",
    "                # Add shapes\n",
    "                add_paths([pts])\n",
    "\n",
    "            else: raise NotImplementedError(f\"Letter '{letter}' not implemented.\")\n",
    "\n",
    "            if self.debug:\n",
    "                print(bbox)\n",
    "\n",
    "            # Crop from above and/or below and apply possible masks defined above\n",
    "            crop_boxes = []\n",
    "            if letter in LETTERS_CROP_BOTH or letter in LETTERS_CROP_TOP_ONLY:\n",
    "                crop_boxes.append(self.crop_box(p2=tensor(1., cap_height_y)))\n",
    "            if letter in LETTERS_CROP_BOTH:\n",
    "                crop_boxes.append(self.crop_box(p1=tensor(0., baseline_y)))\n",
    "            shapes_and_types += [(x, True) for x in crop_boxes]\n",
    "\n",
    "            # We need to add bg color to get rid of artefacts at the edges of the crop boxes\n",
    "            self.scenes[self.i] = self.create_scene_from_shapes(shapes_and_types, bg_color=COLOR_WHITE, fill_color=COLOR_WHITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def inverse_residual_entropy_loss(input: Tensor,\n",
    "    target: Tensor,\n",
    "    softmax = False,\n",
    "    invert = True,\n",
    "    factor = 1/3\n",
    "    ) -> Tensor:\n",
    "    \"\"\"NB! Not used yet anywhere!\n",
    "       Calculate the entropy of the incorrect activations. `input` should \n",
    "       be softmaxed or `softmax` set to True. `factor` is used to \n",
    "       approximately normalise the value. Note that we `invert` the value\n",
    "       by default to suit our optimisation goal of maximum residual \n",
    "       entropy. Also note that the residual entropy is already inversely \n",
    "       correlated with cross entropy loss because of softmax.\"\"\"\n",
    "    if softmax: input = F.softmax(input)\n",
    "    test_close(target.sum(), 1.) # Expect one-hot tensor\n",
    "    input = (1 - target) * input\n",
    "    ent = Categorical(probs=input).entropy() * factor\n",
    "    return 1 / (ent + EPS) if invert else ent\n",
    "\n",
    "def param_loss(x: Tensor, \n",
    "    loss_start = 4., \n",
    "    loss_factor = 1.\n",
    "    ) -> Tensor:\n",
    "    \"\"\"Calculate a linear loss for abs values above `loss_start` multiplied\n",
    "       by `loss_factor`.\"\"\"\n",
    "    return loss_factor * torch.clamp(x.abs() - loss_start, min=0.).sum()\n",
    "\n",
    "class ParamLoss(Module):\n",
    "    \"\"\"Calculate a loss based on extreme parameter values.\"\"\"\n",
    "    def __init__(self, \n",
    "        vector_model: VectorRenderLayerBase, \n",
    "        loss_start = 4., \n",
    "        loss_factor = 1., \n",
    "        **kwargs\n",
    "        ):\n",
    "        assert vector_model is not None\n",
    "        super(ParamLoss, self).__init__(**kwargs)\n",
    "        store_attr(\"vector_model,loss_start,loss_factor\")\n",
    "\n",
    "    def forward(self, *args):\n",
    "        return concat_tensors([param_loss(p, self.loss_start, self.loss_factor) for p in self.vector_model.params]).sum()\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class OCRLoss(CrossEntropyLossFlat):\n",
    "    \"\"\"Softmaxed CrossEntropyLossFlat between one or more `ocr_model`s' prediction\n",
    "       and target category with optional `worst_weight` weighting the worst of the \n",
    "       ensemble's predictions; or `inverse_residual_entropy_loss` weighted by \n",
    "       `residual_entropy_weight`. If `per_item_tfms` is true, transformations are\n",
    "       applied individually to each item instead of the batch. \n",
    "       If `per_category_avg` is true, losses are first averaged for each category \n",
    "       before calculating the mean -- that is, if the batch size is such that \n",
    "       multiple examples of each category are produced. This is useful because \n",
    "       random augmentations and stochastic rendering create a lot of noise in the \n",
    "       losses. Pass an `image_saver` to save images after `tfms`. Use after \n",
    "       `VectorRenderLayerBase`.\"\"\"\n",
    "    def __init__(self, \n",
    "        ocr_model: Union[Module, Sequence[Module]], \n",
    "        tfms: list[DisplayedTransform] = None, \n",
    "        per_item_tfms = True,\n",
    "        per_category_avg = True,\n",
    "        residual_entropy_weight = 0., \n",
    "        worst_model_weight = 0.,\n",
    "        image_saver: ImageSaver = None,\n",
    "        debug = False, \n",
    "        **kwargs\n",
    "    ):\n",
    "        assert ocr_model is not None\n",
    "        if is_listy(ocr_model):\n",
    "            if len(ocr_model) == 1: ocr_model = ocr_model[0]\n",
    "            else: \n",
    "                assert not per_category_avg\n",
    "                assert \"reduction\" not in kwargs; kwargs[\"reduction\"] = 'none'\n",
    "        if per_category_avg: \n",
    "            assert \"reduction\" not in kwargs; kwargs[\"reduction\"] = 'none'\n",
    "            if not per_item_tfms: warn(\"if per_item_tfms is False per_category_avg will not have full impact.\")\n",
    "        if tfms is None: tfms = []\n",
    "        super(OCRLoss, self).__init__(**kwargs)\n",
    "        self.batch_i = -1\n",
    "        self.stored = []\n",
    "        ocr_model.eval()\n",
    "        store_attr()\n",
    "\n",
    "    def __call__(self, \n",
    "        inp: Tensor, \n",
    "        target: Tensor, \n",
    "        return_pred = False,\n",
    "        return_per_category = False,\n",
    "    ) -> Union[Tensor, dict[int, Tensor], tuple[Tensor, Tensor]]:\n",
    "        \"Implements different methods for calculating the loss\"\n",
    "        assert not (return_pred and return_per_category)\n",
    "        assert not (return_pred and is_listy(self.ocr_model))\n",
    "        assert not return_per_category or self.per_category_avg\n",
    "        self.batch_i += 1\n",
    "        if self.debug: orig_inp = inp\n",
    "        inp = self.apply_tfms(inp)\n",
    "        if self.image_saver: \n",
    "            for i in range(inp.shape[0]): self.image_saver(inp[i], batch_i=self.batch_i, item_i=i, scene=None)\n",
    "        if is_listy(self.ocr_model):\n",
    "            losses = torch.cat([super(OCRLoss, self).__call__(o(inp), target).reshape(-1,1) for o in self.ocr_model], dim=1)\n",
    "            w = self.worst_model_weight\n",
    "            loss = (w * losses.max(dim=1).values.mean() + (1 - w) * losses.mean()) if w else losses.mean()\n",
    "        else:\n",
    "            pred = self.ocr_model(inp)\n",
    "            loss = super(OCRLoss, self).__call__(pred, target)\n",
    "            if self.per_category_avg:\n",
    "                # mm = [] # Calculate spread between category losses and print out the maximum of these\n",
    "                # for o in target.unique():\n",
    "                #     z = loss.gather(0, (target == o).nonzero().flatten())\n",
    "                #     mm.append((z.max() - z.min()).item())\n",
    "                # print(max(mm))\n",
    "                cats = target.unique()\n",
    "                losses = [loss.gather(0, (target == o).nonzero().flatten()).quantile(q=0.5).unsqueeze(0) \\\n",
    "                          for o in cats] # We take the median using quantile instead of mean\n",
    "                loss = torch.concat(losses).mean()\n",
    "        if self.residual_entropy_weight: \n",
    "            loss = (1 - self.residual_entropy_weight) * loss + \\\n",
    "                   self.residual_entropy_weight * inverse_residual_entropy_loss(pred, target)\n",
    "        if self.debug:\n",
    "            is_multi = is_listy(self.ocr_model)\n",
    "            self.stored.append(dict(inp=inp.detach(),\n",
    "                                    orig_inp=orig_inp.detach(),\n",
    "                                    loss=loss.item(),\n",
    "                                    pred=None if is_multi else pred.detach(),\n",
    "                                    losses=losses if is_multi or self.per_category_avg else None))\n",
    "        if return_pred:         return (loss, pred)\n",
    "        if return_per_category: return {k:v for k,v in zip([o.item() for o in cats], losses)}\n",
    "        return loss \n",
    "\n",
    "    def apply_tfms(self,\n",
    "        inp: Tensor\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Apply `self.tfms` to `inp` if any.\"\"\"\n",
    "        for tfm in self.tfms:\n",
    "            if self.per_item_tfms:\n",
    "                assert inp.ndim == 4\n",
    "                inp = torch.concat([tfm(o, split_idx=0).unsqueeze(0) for o in inp])\n",
    "            else: inp = tfm(inp, split_idx=0)\n",
    "        return inp\n",
    "\n",
    "class OCRAndParamLoss(Module):\n",
    "    \"\"\"Combined OCR and param loss.\"\"\"\n",
    "    stored = []\n",
    "    @delegates(OCRLoss)\n",
    "    def __init__(self, \n",
    "        ocr_model, \n",
    "        vector_model: VectorRenderLayerBase, \n",
    "        loss_start = 4., \n",
    "        loss_factor = 1., \n",
    "        **kwargs\n",
    "        ):\n",
    "        super(OCRAndParamLoss, self).__init__()\n",
    "        self.ocr_loss = OCRLoss(ocr_model=ocr_model, **kwargs)\n",
    "        self.param_loss = ParamLoss(vector_model=vector_model, loss_start=loss_start, loss_factor=loss_factor)\n",
    "        self.debug = debug\n",
    "\n",
    "    def forward(self, inp, target):\n",
    "        ocr_loss, pred = self.ocr_loss(inp, target, return_pred=True)\n",
    "        loss = ocr_loss + self.param_loss(inp, target)\n",
    "        if self.debug: self.stored.append((loss.item(), pred[0].argmax().item(), pred[0].max().item(), pred[0].detach()))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match Font Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class MatchFontLoss(Module):\n",
    "    \"\"\"L2 loss to match the specified font. Note that the default param specs limit\n",
    "       height to 0.8, so `font_size` should not be too large. Loss is calculated as\n",
    "       a sum of losses from multiple resolution renderings as in Reddy et al., 2021 \n",
    "       (arXiv:2102.02798).\"\"\"\n",
    "    def __init__(self,\n",
    "        vector_model: VectorRenderLayerBase,\n",
    "        font_path: Union[str, Path],\n",
    "        font_size: float = None,\n",
    "        font_y: float = None,\n",
    "        multires_levels: int = 4,\n",
    "        **kwargs\n",
    "        ):\n",
    "        if font_size is None: font_size = .7\n",
    "        if hasattr(vector_model, \"param_specs\"):\n",
    "            ps = vector_model.param_specs\n",
    "            if \"Height\" in ps and ps[\"Height\"].max.item() - font_size < .05:\n",
    "                warn(f\"Model param specs have a max height of {ps['Height'].max.item()} but font_size to match is {font_size}!\")\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self._font_path: str\n",
    "        self.target_letters: list[Tensor]\n",
    "        store_attr(\"vector_model,font_size,font_y,multires_levels\")\n",
    "        self.font_path = font_path # We need the store_attrs for the setter\n",
    "    \n",
    "    @property\n",
    "    def font_path(self) -> str:\n",
    "        \"\"\"Get the path to the target font.\"\"\"\n",
    "        return self._font_path\n",
    "\n",
    "    @property\n",
    "    def multires_factors(self) -> list[int]:\n",
    "        \"\"\"Get the divisors for multiresolution loss.\"\"\"\n",
    "        if not self.multires_levels: return [1]\n",
    "        m = self.vector_model\n",
    "        min_dim = min(m.canvas_width,m.canvas_height)\n",
    "        ff = [2**o for o in range(self.multires_levels)]\n",
    "        return [o for o in ff if min_dim // o > 1]\n",
    "\n",
    "    @font_path.setter\n",
    "    def font_path(self, value: Union[str, Path]):\n",
    "        \"\"\"Set the path to the target font and init the font.\"\"\"\n",
    "        self._font_path = str(value)\n",
    "        self.init_font()\n",
    "    \n",
    "    def init_font(self) -> None:\n",
    "        \"\"\"Pre-render the necessary images for L2 loss. Note that we store these\n",
    "           as a list of `Tensor`s of different resolutions.\"\"\"\n",
    "        m = self.vector_model\n",
    "        w,h = m.canvas_width,m.canvas_height\n",
    "        size = round(self.font_size * h)\n",
    "        y    = round(self.font_y * size)\n",
    "        orig_imgs = [render_text(self.font_path, text=l, text_size=size, y=y,\n",
    "                                image_width=w, image_height=h, as_normalised_array=False) \\\n",
    "                     for l in m.vocab]\n",
    "        imgs = []\n",
    "        for f in self.multires_factors:\n",
    "            wf,hf = w//f,h//f\n",
    "            imgs.append([img_to_normalised_array(o.resize((hf,wf), resample=Image.BICUBIC)) for o in orig_imgs])\n",
    "        self.target_letters = [concat_tensors(o).reshape(-1, 1, *o[0].shape[-2:]) for o in imgs]\n",
    "\n",
    "    def check_init_font(self) -> bool:\n",
    "        \"\"\"Check if prerendered target letters match canvas dimensions.\"\"\"\n",
    "        if not self.target_letters: return False\n",
    "        m = self.vector_model\n",
    "        w,h = m.canvas_width,m.canvas_height\n",
    "        sz = self.target_letters.shape\n",
    "        return sz[-2] == h and sz[-1] == w\n",
    "\n",
    "    def forward(self, inp, target):\n",
    "        \"\"\"Calculate the multi-resolution loss.\"\"\"\n",
    "        if not self.check_init_font: self.init_font()\n",
    "        losses = []\n",
    "        for i,f in enumerate(self.multires_factors):\n",
    "            inp_rsz = inp if f == 1 else \\\n",
    "                      F.interpolate(inp, scale_factor=1/f, mode='bicubic', align_corners=False, recompute_scale_factor=False)\n",
    "            target_rsz = torch.cat([self.target_letters[i][o] for o in target]).reshape(inp_rsz.shape)\n",
    "            losses.append(self.mse_loss(inp_rsz, target_rsz))\n",
    "        return concat_tensors(losses).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plot_param_losses(df: DataFrame, p_name = \"\", plot_width = 6, zoom_range = .3) -> None:\n",
    "    \"\"\"Plot param values and losses from `VectorLearner.calculate_losses`\n",
    "       in width `plot_width` and restrict y-axis to min loss plus `zoom_range`.\"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(2 * plot_width, plot_width))\n",
    "    fig.suptitle(f\"Loss for param {p_name}\")\n",
    "    if zoom_range is not None:\n",
    "        y_min = df.loss.min()\n",
    "        for ax in axs: ax.set_ylim([y_min - zoom_range / 20, y_min + zoom_range])\n",
    "    df = df.sort_values(by=\"value\")\n",
    "    axs[0].plot(df.value, df.loss)\n",
    "    axs[0].set_xlabel(\"Raw value\")\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "    df = df.sort_values(by=\"interpolated_value\")\n",
    "    axs[1].plot(df.interpolated_value, df.loss)\n",
    "    axs[1].set_xlabel(\"Interpolated value\")\n",
    "\n",
    "class VectorLearner(Learner):\n",
    "    \"\"\"A simple extension to Learner offering some utility methods.\"\"\"\n",
    "    def __init__(self, image_saver=None, **kwargs):\n",
    "        super(VectorLearner, self).__init__(**kwargs)\n",
    "        store_attr(\"image_saver\")\n",
    "\n",
    "    @property\n",
    "    def params(self) -> List[Parameter]:\n",
    "        return self.model.params\n",
    "\n",
    "    @property\n",
    "    def param_names(self) -> List[str]:\n",
    "        return self.model.param_names\n",
    "\n",
    "    @property\n",
    "    def vocab(self) -> List[str]:\n",
    "        return self.dls.vocab\n",
    "\n",
    "    def reset_parameters(self, *args, **kwargs) -> VectorLearner:\n",
    "        \"\"\"Shortcut for `self.model.reset_parameters`.\"\"\"\n",
    "        self.model.reset_parameters(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def get_param_dict(self, *args, **kwargs) -> ParamDict:\n",
    "        \"\"\"Shortcut for `self.model.get_param_dict`.\"\"\"\n",
    "        return self.model.get_param_dict(*args, **kwargs)\n",
    "\n",
    "    def load_param_dict(self, *args, **kwargs) -> VectorLearner:\n",
    "        \"\"\"Shortcut for `self.model.load_param_dict`.\"\"\"\n",
    "        self.model.load_param_dict(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def set_param(self, *args, **kwargs) -> VectorLearner:\n",
    "        \"\"\"Shortcut for `self.model.set_param`.\"\"\"\n",
    "        self.model.set_param(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def get_param_groups(self) -> OrderedDict:\n",
    "        \"\"\"Shortcut for `self.model.get_param_groups`.\"\"\"\n",
    "        return self.model.get_param_groups()\n",
    "\n",
    "    def get_effective_params(self, *args, **kwargs) -> list[str]:\n",
    "        \"\"\"Shortcut for `self.model.get_effective_params`.\"\"\"\n",
    "        return self.model.get_effective_params(*args, **kwargs)\n",
    "\n",
    "    def freeze_params(self, *args, **kwargs) -> VectorLearner:\n",
    "        \"\"\"Shortcut for `self.model.freeze_params`.\"\"\"\n",
    "        self.model.freeze_params(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def unfreeze_params(self, *args, **kwargs) -> VectorLearner:\n",
    "        \"\"\"Shortcut for `self.model.unfreeze_params`.\"\"\"\n",
    "        self.model.unfreeze_params(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def create_variations(self, iters = 20, epochs = [10, 20, 20], lrs = [1e-1, 5e-2, 1e-2], \n",
    "        initial_params: list[dict] = None, render_letters: Union[str, None] = \"all\", \n",
    "        img_scale = 3.) -> list[dict]:\n",
    "        \"\"\"Create `iters` optimised iterations by reinitialising parameters either randomly\n",
    "           or from `initial_params` list and training for `epochs` with `lrs`.\"\"\"\n",
    "        assert len(epochs) == len(lrs)\n",
    "        assert initial_params is None or len(initial_params) == iters\n",
    "        def noop(*args): pass\n",
    "        logger = self.recorder.logger\n",
    "        self.recorder.logger = noop\n",
    "        self.unfreeze_params()\n",
    "        results = []\n",
    "        for i in range(iters):\n",
    "            print(f\"Starting iter {i + 1}/{iters}\")\n",
    "            if initial_params is None: self.reset_parameters()\n",
    "            else: self.load_param_dict(initial_params[i])\n",
    "            init_pars = self.get_param_dict()\n",
    "            for e_n, e_lr in zip(epochs, lrs): self.fit(e_n, e_lr)\n",
    "            res = {\n",
    "                  \"initial_params\": init_pars,\n",
    "                  \"param_values\":   self.get_param_dict(),\n",
    "                  \"loss_at_end\":    self.recorder.losses[-1].item()\n",
    "                  }\n",
    "            if render_letters is not None:\n",
    "                res[\"img\"] = self.render_letters(None if render_letters == \"all\" else render_letters, scale=img_scale)\n",
    "            results.append(res)\n",
    "        self.recorder.logger = logger\n",
    "        return results\n",
    "\n",
    "    def fit_letters(self,\n",
    "        letters: Iterable[str] = None,\n",
    "        **kwargs\n",
    "        ) -> None:\n",
    "        \"\"\"Fit only the specific parameters affecting `letters` or all if `None`.\"\"\"\n",
    "        orig_letters = self.dls.train.letters\n",
    "        if letters not in (None, ''):\n",
    "            self.freeze_params()\n",
    "            params = get_effective_params(self.param_names, letters)\n",
    "            if len(params) == 0:\n",
    "                warn(f\"No applicable params found for letters '{letters}'.\")\n",
    "                return\n",
    "            self.unfreeze_params(params)\n",
    "            self.dls.train.letters = letters\n",
    "        self.fit(**kwargs)\n",
    "        self.dls.train.letters = orig_letters\n",
    "        self.unfreeze_params()\n",
    "        \n",
    "    def fit_naively(self, iters = 10, epochs = 10, steps = 25, exclude = []) -> Tuple[float, DataFrame]:\n",
    "        \"\"\"\"Naïvely try the whole range of eacn paramater value and see if loss can be improved.\n",
    "            Complete `iters` iterations for `epochs` traversing the parameters in a random order.\n",
    "            Bypass params in `exclude`. Returns a tuple of improvement in loss (can be negative)\n",
    "            and the final results of each iteration.\"\"\"\n",
    "        param_names = [x for x in self.model.param_names if not exclude or x not in exclude]\n",
    "        n_pars = len(param_names)\n",
    "        init_loss = self.get_current_loss()\n",
    "        init_params = self.get_param_dict()\n",
    "        res = []\n",
    "        for i in range(iters):\n",
    "            self.load_param_dict(init_params)\n",
    "            for e in range(epochs):\n",
    "                best_loss = self.get_current_loss()\n",
    "                random.shuffle(param_names)\n",
    "                for j, p in enumerate(param_names):\n",
    "                    report(f\"Fitting\", prog = (i * epochs) + (e * n_pars) + j / (iters * epochs * n_pars))\n",
    "                    df = self.calculate_losses(p, plot=False, smooth_loss_dist=None, steps=steps)\n",
    "                    if df.loss.min() < best_loss: self.set_param(p, get_argmin(df))\n",
    "            res.append(dict(loss=self.get_current_loss(), \n",
    "                            params=self.get_param_dict()))\n",
    "        res = DataFrame(res)\n",
    "        improvement = init_loss - res.loss.min()\n",
    "        if improvement > 0: self.load_param_dict(get_argmin(res, return_col=\"params\"))\n",
    "        return improvement, res\n",
    "\n",
    "    def render_tensor(self,\n",
    "        x: Tensor,\n",
    "        scale: float = None, \n",
    "        as_image = True,\n",
    "        apply_tfms = False,\n",
    "        cols: int = None, \n",
    "        rows: int = None\n",
    "        ) -> Union[PIL.Image, Tensor]:\n",
    "        \"\"\"Render input `x`. If input is 4-dimensional, it's rendered as multiple images\n",
    "           using `image_grid` to which `cols`, `rows` and `grid_scale` are passed.\"\"\"\n",
    "        m = self.model\n",
    "        with eval_model(m):\n",
    "            with torch.no_grad(): t = m(x)\n",
    "        if apply_tfms and hasattr(self.loss_func, \"ocr_loss\"):\n",
    "            t = self.loss_func.ocr_loss.apply_tfms(t)\n",
    "        if not as_image: return t\n",
    "        return image_grid(t, cols=cols, rows=rows, scale=scale) if t.ndim == 4 and t.shape[0] > 1 else \\\n",
    "               img_from_tensor(t, scale=scale)\n",
    "\n",
    "    @delegates(render_tensor)\n",
    "    def show_batch(self,\n",
    "        **kwargs\n",
    "        ) -> PIL.Image:\n",
    "        \"\"\"Show one batch applying possible loss transformations.\"\"\"\n",
    "        x,_ = list(self.dls.train)[0]\n",
    "        return self.render_tensor(x, **{\"apply_tfms\": True, **kwargs})\n",
    "\n",
    "    @delegates(render_tensor)\n",
    "    def render_letter(self, \n",
    "        letter: str = \"A\", \n",
    "        **kwargs\n",
    "        ) -> PIL.Image:\n",
    "        \"\"\"Render one or more `letter`s.\"\"\"\n",
    "        x = tensor([self.vocab.index(o) for o in letter])\n",
    "        return self.render_tensor(x, **kwargs)\n",
    "\n",
    "    @delegates(render_letter)\n",
    "    def render_letters(self, \n",
    "        letters: Union[str, list[str]] = None, \n",
    "        **kwargs\n",
    "        ) -> PIL.Image:\n",
    "        \"\"\"An alias for `render_letter`.\"\"\"\n",
    "        if letters is None: letters = self.vocab # self.dls[0].letters\n",
    "        return self.render_letter(letters, **kwargs)\n",
    "\n",
    "    @delegates(render_letter)\n",
    "    def render_letters_as_df(self,\n",
    "        vocab: list[str] = None,\n",
    "        **kwargs\n",
    "    ) -> DataFrame:\n",
    "        \"\"\"Create `DataFrame` suitable for OCR learners by rendering the font.\"\"\"\n",
    "        assert all([o not in kwargs for o in (\"letter\", \"as_image\")])\n",
    "        if vocab is None: vocab = self.vocab\n",
    "        data = []\n",
    "        for i,l in enumerate(vocab):\n",
    "            t = self.render_letter(letter=l, as_image=False, **kwargs)\n",
    "            data.append([i] + [round(x.item()) for x in 255 * (1. - t.flatten())])\n",
    "        df = pd.DataFrame(data).astype(\"uint8\")\n",
    "        df.columns = [\"Letter_idx\"] + [f\"{i}_{j}\" for i in range(self.canvas_height) for j in range(self.canvas_width)]\n",
    "        return df\n",
    "        \n",
    "    def render_result_video(self, **kwargs):\n",
    "        \"\"\"Shortcut for `self.image_saver.render_result_video`\"\"\"\n",
    "        assert self.image_saver is not None\n",
    "        self.image_saver.render_result_video(**kwargs)\n",
    "\n",
    "    def save_svg(self, *args, **kwargs) -> None:\n",
    "        \"\"\"Shortcut for `self.model.save_svg`\"\"\"\n",
    "        self.model.save_svg(*args, **kwargs)\n",
    "\n",
    "    def calculate_losses(self, param: Union[str, int, Parameter], min = -4., max = 4., steps = 80, \n",
    "                         smooth_loss_dist = 3, plot = False, zoom_range = .3, plot_width = 6) -> pd.DataFrame:\n",
    "        \"\"\"Output loss statistics and predictions for the `param` by name or index\n",
    "           for `steps` between `min` and `max`. `smooth_loss_dist` is used to smooth\n",
    "           the loss values, see `smooth`. Optionally `plot` the results\n",
    "           in width `plot_width` and restrict y-axis to min loss plus `zoom_range`.\"\"\"\n",
    "        assert steps > 1\n",
    "        lf = self.loss_func\n",
    "        with debug(lf):\n",
    "            model = self.model\n",
    "            x,y = list(self.dls.train)[0]\n",
    "            stats = []\n",
    "            for i in range(steps):\n",
    "                v = min + (max - min) * i / (steps - 1)\n",
    "                model.set_param(param, v)\n",
    "                l = self.get_current_loss()\n",
    "                d = {\n",
    "                    \"value\": model.get_param(param).item(), # There's a discrepancy between v and this\n",
    "                    \"interpolated_value\": model.get_param_value(param).item(),\n",
    "                    \"loss\": l,\n",
    "                    \"pred\": self.vocab[lf.stored[-1][1]] if hasattr(lf, \"stored\") else None,\n",
    "                    \"pred_correct\": (lf.stored[-1][1] == y[0]).item() if hasattr(lf, \"stored\") else None,\n",
    "                    \"pred_activation\": lf.stored[-1][2] if hasattr(lf, \"stored\") else None,\n",
    "                    }\n",
    "                stats.append(d)\n",
    "        df = DataFrame(stats).sort_values(by=\"value\") # See value discrepancy above\n",
    "        if smooth_loss_dist is not None:\n",
    "            if float(smooth_loss_dist) / steps > .1: \n",
    "                warn(f\"Using smooth_loss_dist of {smooth_loss_dist} with {steps} steps yields poor resolution!\")\n",
    "            df[\"raw_loss\"] = df.loss\n",
    "            df.loss = smooth(df.loss, dist=smooth_loss_dist)\n",
    "        if plot: plot_param_losses(df, p_name=model.get_param_name(param), plot_width=plot_width, zoom_range=zoom_range)\n",
    "        return df\n",
    "\n",
    "    def get_current_loss(self, \n",
    "        iters = 1, \n",
    "        reduction: Union[str, None] = \"mean\",\n",
    "        per_category = False,\n",
    "    ) -> Union[float, list[float], dict[int, float]]:\n",
    "        \"\"\"Calculate the current loss, possibly as an average of `iters` or a list\n",
    "           and possible `per_category` when mean is always returned.\"\"\"\n",
    "        assert reduction in (\"mean\", \"none\", None) \n",
    "        assert not per_category or (hasattr(self.loss_func, \"ocr_loss\") and self.loss_func.ocr_loss.per_category_avg)\n",
    "        m = self.model\n",
    "        with eval_model(m):\n",
    "            x, y = list(self.dls.train)[0]\n",
    "            if per_category:\n",
    "                losses = {}\n",
    "                for i in range(iters): \n",
    "                    for k,v in self.loss_func.ocr_loss(m(x), y, return_per_category=True).items():\n",
    "                        if k not in losses: losses[k] = []\n",
    "                        losses[k].append(v.item())\n",
    "            else:\n",
    "                losses = []\n",
    "                for i in range(iters): losses.append(self.loss_func(m(x), y).item())\n",
    "        if iters == 1 and not per_category: return losses[0]\n",
    "        if per_category:         return {self.vocab[k]:mean(v) for k,v in losses.items()}\n",
    "        if reduction ==  \"mean\": return mean(losses)\n",
    "        return losses\n",
    "\n",
    "    @contextmanager\n",
    "    def no_progress(self):\n",
    "        \"\"\"Context manager that disables any reporting of progress when fitting.\"\"\"\n",
    "        has_rec = hasattr(self, \"recorder\")\n",
    "        if has_rec:\n",
    "            logger = self.recorder.logger = noop\n",
    "            self.recorder.logger = noop\n",
    "        prog_cbs = [o for o in self.cbs if isinstance(o, ProgressCallback)]\n",
    "        self.remove_cbs(prog_cbs)\n",
    "        try: yield self\n",
    "        finally: \n",
    "            if has_rec: self.recorder.logger = logger\n",
    "            self.add_cbs(prog_cbs)\n",
    "\n",
    "    def show_renders_and_target(self,\n",
    "        scale = .5\n",
    "    ) -> None:\n",
    "        \"\"\"Show rendered letters and target letters when using `MatchFontLoss`.\"\"\"\n",
    "        assert hasattr(self.loss_func, \"target_letters\")\n",
    "        pred = self.render_letters(scale=scale)\n",
    "        targ = image_grid([img_from_tensor(o) for o in self.loss_func.target_letters[0]], scale=scale).convert('L')\n",
    "        size = targ.size\n",
    "        targ2 = Image.new('RGB', size=size, color=\"white\")\n",
    "        targ2.paste((255,0,0), mask=invert(targ))\n",
    "        mask = Image.new('L', size=size, color=128)\n",
    "        comp = Image.composite(pred, targ2, mask)\n",
    "        grid_size = (3 * size[0], size[1])\n",
    "        grid = Image.new('RGB', size=grid_size, color=\"white\")\n",
    "        for i,img in enumerate([comp, pred, targ]): grid.paste(img, box=(i * size[0], 0))\n",
    "        print(f\"Loss: {self.get_current_loss()}\")\n",
    "        display(grid)\n",
    "\n",
    "add_docs(VectorLearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factory Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class LossType(Enum):\n",
    "    OCR = auto()\n",
    "    MATCH_FONT = auto()\n",
    "\n",
    "def create_font_learner(loss_type = LossType.OCR,\n",
    "    ocr_model = None, \n",
    "    ocr_learner = None, \n",
    "    ocr_tfms = None,\n",
    "    match_font_path = None,\n",
    "    match_font_size = None,\n",
    "    match_font_y: float = None,\n",
    "    vocab = VOCAB_UC,\n",
    "    letters = None,\n",
    "    folder = None, \n",
    "    save_ocr_imgs = False,\n",
    "    save_svg = False,\n",
    "    normalise = False, \n",
    "    epoch_len = 1,\n",
    "    vector_class = SansSerifFontRL, \n",
    "    input_shape = None, \n",
    "    n_colors_out = 1, \n",
    "    eps = None, \n",
    "    optim = None,\n",
    "    lr = 1e-2, \n",
    "    debug = False, \n",
    "    cbs = None, \n",
    "    seed = None, \n",
    "    init_range = 2.,\n",
    "    samples = None,\n",
    "    bs = None,\n",
    "    mom = None,\n",
    "    sqr_mom = None,\n",
    "    param_specs = None,\n",
    ") -> VectorLearner:\n",
    "    \"\"\"A factory function for creating a `VectorLearner` for full font optimisation.\"\"\"\n",
    "    if eps is not None: warn(f\"Using eps {eps}\")\n",
    "    if loss_type == LossType.OCR:\n",
    "        assert ocr_model is not None or ocr_learner is not None\n",
    "        if ocr_model is None: ocr_model = ocr_learner.model\n",
    "        if input_shape is None and ocr_learner is not None:\n",
    "            ocr_img = ocr_learner.dls.train_ds[0][0]\n",
    "            canvas_width = ocr_img.width\n",
    "            canvas_height = ocr_img.height\n",
    "    if vocab is None: vocab = get_vocab(ocr_learner)\n",
    "    raster_norm = ocr_learner.dls.train.after_batch[1] if normalise else None\n",
    "    if input_shape is None:\n",
    "        input_shape = (128,128) if loss_type == LossType.MATCH_FONT else (28,28)\n",
    "        warn(f\"Using default input_shape: {input_shape}\")\n",
    "    canvas_width, canvas_height = input_shape\n",
    "    def get_dl(): return LetterDL.from_vocab(vocab, epoch_len=epoch_len, bs=bs) if letters is None else \\\n",
    "                         LetterDL(vocab=vocab, letters=letters, epoch_len=epoch_len, bs=bs)\n",
    "    empty_dl = DataLoader(n=0)\n",
    "    dls = DataLoaders(get_dl(), empty_dl) # No valid dataset, get_dl())\n",
    "    image_saver = ImageSaver(folder=folder, save_svg=save_svg) if folder is not None else None\n",
    "    v_args = dict(vocab=vocab,\n",
    "                  raster_norm=raster_norm, \n",
    "                  rendered_callback=image_saver,\n",
    "                  canvas_width=canvas_width, \n",
    "                  canvas_height=canvas_height,\n",
    "                  n_colors_out=n_colors_out,\n",
    "                  seed=seed,\n",
    "                  eps=eps,\n",
    "                  init_range=init_range,\n",
    "                  samples=samples)\n",
    "    if param_specs is not None:            v_args[\"param_specs\"] = param_specs\n",
    "    elif loss_type == LossType.MATCH_FONT: v_args[\"param_specs\"] = FONT_MATCHING_PARAM_SPECS\n",
    "    render_layer = vector_class(**v_args)\n",
    "    if debug: render_layer.debug = debug\n",
    "    # Params will be added by Learner\n",
    "    if mom is None: mom = .5\n",
    "    if sqr_mom is None: sqr_mom = .9\n",
    "    get_optim = partial(Adam,  lr=lr, mom=mom, sqr_mom=sqr_mom, wd=0.) if optim is None else \\\n",
    "                partial(optim, lr=lr)\n",
    "    if loss_type == LossType.OCR:\n",
    "        loss_image_saver = ImageSaver(folder=folder, iter_name=\"augmented\", save_svg=save_svg) if save_ocr_imgs else None\n",
    "        loss = OCRAndParamLoss(ocr_model=ocr_model,\n",
    "                               tfms=ocr_tfms,\n",
    "                               vector_model=render_layer,\n",
    "                               image_saver=loss_image_saver,\n",
    "                               debug=debug)\n",
    "    elif loss_type == LossType.MATCH_FONT:\n",
    "        loss = MatchFontLoss(vector_model=render_layer,\n",
    "                             font_path=match_font_path,\n",
    "                             font_size=match_font_size,\n",
    "                             font_y=match_font_y)\n",
    "    else: raise ValueError(f\"Unknown loss type {loss_type}\")\n",
    "    vector_learner = VectorLearner(dls=dls,\n",
    "                                   model=render_layer,\n",
    "                                   loss_func=loss,\n",
    "                                   opt_func=get_optim,\n",
    "                                   cbs=cbs,\n",
    "                                   image_saver=image_saver)\n",
    "    return vector_learner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary Tests\n",
    "\n",
    "> These can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.206069</td>\n",
       "      <td>None</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from aifont.ocrlearner import *\n",
    "import gc\n",
    "\n",
    "DUMP_FOLDER = Path(\"results/nb17_experiment_3_rerun\"); ensure_path(DUMP_FOLDER)\n",
    "FINETUNED_OCR_MODEL_FN = \"e2_cornet_z_v4_finetuned_final.pth\"\n",
    "FINETUNED_OCR_MODEL_ALT_FN = \"e2_cornet_z_v1_finetuned_final.pth\"\n",
    "ACC_50_TFMS = {'use_affine_tfms': False,\n",
    "               'use_xtra_tfms': True,\n",
    "               'tfms_p': 1.0,\n",
    "               'blur_size': None,\n",
    "               'blur_sigma': None,\n",
    "               'noise_f': 1.365625,\n",
    "               'noise_type': NoiseType.GAUSSIAN,\n",
    "               'noise_method': BlendingMethod.ADD,\n",
    "               'size': 48,\n",
    "               'normalize': True,\n",
    "               'translate_and_pad': 0.0\n",
    "              }\n",
    "BASE_FN = \"e3_with_e2_v4_finetuned\"\n",
    "BEST_PARAMS_PATH = DUMP_FOLDER/f\"{BASE_FN}_best_params.pkl\"\n",
    "ARIAL_BOLD_PARAMS_PATH = DUMP_FOLDER/f\"{BASE_FN}_arial_bold_params.pkl\"\n",
    "BASE_TFMS = dict(size=48,\n",
    "                 normalize=True, \n",
    "                 tfms_p=1., # Edit\n",
    "                 use_affine_tfms=True,\n",
    "                 use_xtra_tfms=True,\n",
    "                 blur_size=None, #(3, 9),\n",
    "                 blur_sigma=None, #(1., 3.), \n",
    "                 noise_f=(.15, 2.),\n",
    "                 noise_method=BlendingMethod.ADD,\n",
    "                 noise_type=NoiseType.GAUSSIAN,\n",
    "                 translate_and_pad=0.,\n",
    "                 override_max_rotate=5.,\n",
    "                 override_max_warp=0.1\n",
    "                 )\n",
    "\n",
    "def get_learner(\n",
    "    ocr_fn = FINETUNED_OCR_MODEL_FN,\n",
    "    ocr_arch = cornet_for_ocr,\n",
    "    n_out = 26,\n",
    "    seed = None,\n",
    "    bs = None,\n",
    "    tfms = ACC_50_TFMS,\n",
    "    init_range = 0.,\n",
    "    **kwargs\n",
    ") -> VectorLearner:\n",
    "    gc.collect()\n",
    "    ocr_model = load_ocr_model(file=ocr_fn, arch=ocr_arch, n_out=n_out)\n",
    "    # These must match ACC_50_TFMS\n",
    "    aug_tfms = get_tfms(orig_sz=28, **BASE_TFMS)\n",
    "    warp = aug_tfms[0][-1]\n",
    "    ocr_tfms = [\n",
    "        Pad((tfms[\"size\"] - 28) // 2, fill=1.),\n",
    "        Noise(p=tfms[\"tfms_p\"], f=tfms[\"noise_f\"], method=tfms[\"noise_method\"], noise_type=tfms[\"noise_type\"]),\n",
    "        ToRGB(),\n",
    "        # DebugTfm(\"After Pad\"),\n",
    "        get_imagenet_norm(),\n",
    "        warp\n",
    "        # TranslateAndPad(p=tfms_p, max_x=translate_and_pad, max_y=translate_and_pad),\n",
    "        # GaussianBlur(p=1., sigma=blur_sigma, kernel_size=(blur_size,)*2)\n",
    "        ]\n",
    "    # ocr_tfms += [Noise(p=tfms_p, f=(0., noise))]\n",
    "    learner = create_font_learner(ocr_tfms=ocr_tfms if len(ocr_tfms) else None,\n",
    "                                  letters=None,\n",
    "                                  ocr_model=ocr_model,\n",
    "                                  n_colors_out=1,\n",
    "                                  lr=1e-1, \n",
    "                                  init_range=init_range,\n",
    "                                  seed=seed,\n",
    "                                  bs=bs,\n",
    "                                  **kwargs\n",
    "                                  )\n",
    "    assert len(learner.loss_func.ocr_loss.tfms) == len(ocr_tfms)\n",
    "    return learner\n",
    "\n",
    "ocr_fn = FINETUNED_OCR_MODEL_ALT_FN\n",
    "learner_args = dict(\n",
    "    ocr_fn=ocr_fn,\n",
    "    bs=26*3,\n",
    "    param_specs=FONT_MATCHING_PARAM_SPECS, # Add translation parameters\n",
    ")\n",
    "\n",
    "learn = get_learner(**learner_args)\n",
    "learn.loss_func.ocr_loss.debug = True\n",
    "learn.fit_one_cycle(1, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7325) 3.2060723304748535\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=48x48 at 0x13C0C2850>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = learn.loss_func.ocr_loss.stored[0][\"inp\"][0]\n",
    "print(img.mean(), learn.loss_func.ocr_loss.stored[0][\"loss\"])\n",
    "img_from_tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7785964385754301\n"
     ]
    }
   ],
   "source": [
    "font_path = SYS_FONT_PATH/\"Arial Bold.ttf\"\n",
    "img_arial = render_text(font_path, \"A\", text_size=28, y=24, image_width=28, as_normalised_array=True)\n",
    "print(img_arial.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_arial = tensor(img_arial).unsqueeze(0).unsqueeze(0)\n",
    "t_arial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase(3.2868, grad_fn=<AliasBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = learn.loss_func.ocr_loss(t_arial, tensor([0]))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=48x48 at 0x13C0C2700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorCategory([4.1389], grad_fn=<AliasBackward0>)\n",
      "tensor(0.0643)\n",
      "tensor(0.0299)\n",
      "H\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=48x48 at 0x13C0C2280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase([3.2868], grad_fn=<AliasBackward0>)\n",
      "tensor(0.0844)\n",
      "tensor(0.0374)\n",
      "G\n"
     ]
    }
   ],
   "source": [
    "for o in learn.loss_func.ocr_loss.stored:\n",
    "    display(img_from_tensor(o[\"inp\"][0]))\n",
    "    print(o[\"losses\"][0])\n",
    "    print(F.softmax(o[\"pred\"][0], dim=-1).max())\n",
    "    print(F.softmax(o[\"pred\"][0], dim=-1)[learn.vocab.index(\"A\")])\n",
    "    print(learn.vocab[F.softmax(o[\"pred\"][0], dim=-1).argmax()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.43494897959184"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arial = get_font_df([font_path], font_size=1., font_y=24/28, vocab=\"A\")\n",
    "df_arial.drop(columns=[\"Letter_idx\"]).iloc[0].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_ocr_model_training_1.ipynb.\n",
      "Converted 01_fontlearnertests.ipynb.\n",
      "Converted 02_first_letter_and_optim_tests.ipynb.\n",
      "Converted 03_vector_models.ipynb.\n",
      "Converted 04_font_statistics.ipynb.\n",
      "Converted 05_full_aphabet_optimisation.ipynb.\n",
      "Converted 06_data_augmentation.ipynb.\n",
      "Converted 07_optimising_with_augmentation.ipynb.\n",
      "Converted 08_comparing_existing_fonts.ipynb.\n",
      "Converted 09_experiment_1_optimise_to_match_font.ipynb.\n",
      "Converted 10_optimising_with_aug_run_2.ipynb.\n",
      "Converted 11_optimise_to_match_font_multires.ipynb.\n",
      "Converted 12_optimising_with_aug_with_multiple_ocr_models.ipynb.\n",
      "Converted 13_analysing_ocr_models.ipynb.\n",
      "Converted 14_experiment_2_ocrlearner_training_with_emp_data.ipynb.\n",
      "Converted 15_experiment_3_optimise_with_emp_model.ipynb.\n",
      "Converted 16_experiment_2_rerun.ipynb.\n",
      "Converted 17_experiment_3_rerun.ipynb.\n",
      "Converted aifont_core.ipynb.\n",
      "Converted aifont_fontlearner.ipynb.\n",
      "Converted aifont_fontsampler.ipynb.\n",
      "Converted aifont_ocrlearner.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5710b12fb88680bf60c169aecc91e9487b0350ee3a6536206b6750ffeed12b61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ai-font-p3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
