# AUTOGENERATED! DO NOT EDIT! File to edit: 00_ocr_model_training_1.ipynb (unless otherwise specified).

__all__ = ['list_params', 'load_ocr_model', 'get_learner_filename', 'get_ocr_learner_2', 'get_ocr_learner_3',
           'create_nist_learner', 'create_ocr_model', 'get_ocr_model']

# Cell

from .core import *
from .ocrlearner import *
import cornet
from fastai.data.all import *
from fastai.vision.all import *
from enum import Enum, auto
import gc
import hashlib
from itertools import product
from nbdev.showdoc import *
import matplotlib.pyplot as plt
import os
import pandas as pd
from pandas import DataFrame
import PIL
import random
import re
import scipy.io
import string
import torchvision.transforms.functional as VF
import torchvision.transforms as VT
from typing import Callable, List, Sequence, Tuple

# Cell

def list_params(learn: Learner) -> None:
    """Quickly list param groups and params to see which ones are frozen."""
    for i,g in enumerate(learn.opt.param_groups):
        for j,p in enumerate(g["params"]):
            print(f"Group {i} â€¢ Param {j}: {p.shape}, {'grad' if p.requires_grad else 'no grad'}")

def load_ocr_model(
    file: str = None,
    arch: Callable = None,
    df: Callable = None,
    vocab: List[str] = VOCAB_UC,
    version: str = None,
    model_dir: str = MODELS_PATH,
    n_out: int = None,
    **kwargs
    ) -> Module:
    """Load a trained OCR model for use with `OCRLoss`. Pass either `file` and `arch` or
       `arch`, `df`, `version` and `vocab` to construct the filename automatically."""
    assert None not in (file, arch) or None not in (arch, df, vocab)
    if file is None: file = get_learner_filename(arch, df, vocab, version=version, incl_suffix=True)
    if n_out is None: n_out = len(vocab)
    file = os.path.join(model_dir, file)
    report(f"Loading OCR model: {file}")
    # This is awful, sry!
    model = arch(n_out=n_out, **kwargs)
    model = model[0] if type(model) is tuple else model
    load_model(file, model, opt=False, device=None)
    return model

def get_learner_filename(arch: Callable, df: Callable,
    vocab: List[str] = None,
    version: str = None,
    incl_suffix = False) -> str:
    """Create a filaneme for the model for use with saving and loading."""
    sfx = ".pth" if incl_suffix else ""
    vcb = f"__vocab_{hashlib.md5(''.join(vocab).encode('utf-8')).hexdigest()}" if vocab else ""
    ver = "" if version in (None, "") else f"_{version}"
    return f"{arch.__name__}__{df.__name__}{vcb}{ver}{sfx}"

def get_ocr_learner_2(
    arch=kaggle_cnn_a,
    n_out=None,
    bs=128,
    df=get_a_z_handw_images,
    vocab=VOCAB_UC,
    version=None,
    normalize=False,
    load_saved=True,
    size=28,
    loss_func=CrossEntropyLossFlat(),
    opt_func=Adam,
    init=nn.init.kaiming_normal_,
    lr=defaults.lr,
    splitter=None,
    use_xtra_tfms=False,
    cbs=None,
    metrics=accuracy,
    path=None,
    model_dir=MODELS_PATH,
    wd=None,
    wd_bn_bias=False,
    train_bn=True,
    moms=(0.95,0.85,0.95),
    **kwargs) -> Learner:
    """Create a new OCR learner based on architecture `arch` and dataset `df`.
       If `pretrained`, the model will be initialised if a suitable save is found."""
    if use_xtra_tfms:
        max_rotate = 15.0
        max_warp = .25
        blur = GaussianBlur(p=.5, random_size=5)
        noise = Noise(p=.5, f=(0., .6))
        item_tfms = [blur, noise]
    else:
        max_rotate = 5.0
        max_warp = .1
        item_tfms = None
    tfms = aug_transforms(mult=1.0, do_flip=False, flip_vert=False, max_rotate=max_rotate,
                          min_zoom=0.85, max_zoom=1.15, max_warp=max_warp, p_affine=.5,
                          p_lighting=0., xtra_tfms=None, size=size, mode='bilinear',
                          pad_mode='reflection', align_corners=True, batch=False,
                          min_scale=1.0)
    del(tfms[1]) # Remove lighting tfm
    warn("Need to add custom normalisation scheme and check this doesn't expand channels!")
    # See: Normalize.from_stats(mean,std) https://docs.fast.ai/data.transforms.html#Normalize
    dls = ImageDataLoadersDF.from_df(df(), vocab=vocab,
                                     width=size, height=size,
                                     num_workers=0, # Needed for Mac
                                     valid_pct=0.2,
                                     batch_tfms=tfms,
                                     item_tfms=item_tfms,
                                     seed=42, bs=bs)

    if n_out is None: n_out = get_c(dls)
    # This is a crappy, but we can specify the splitter in arch
    model_and_splitter = arch(n_out, input_shape=(size, size))
    if type(model_and_splitter) is tuple:
        model, splitter = model_and_splitter
    else:
        model = model_and_splitter
        splitter = lambda m: L(m[0], m[1:]).map(params)
    learn = Learner(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr,
                    splitter=splitter, cbs=cbs,  metrics=metrics, path=path, model_dir=model_dir,
                    wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn, moms=moms)
    if load_saved: learn.load(get_learner_filename(arch=arch, df=df, vocab=vocab, version=version))
    store_attr('arch,normalize,n_out', self=learn, **kwargs)
    return learn

def get_ocr_learner_3(
    arch=kaggle_cnn_a,
    n_out=None,
    bs=128,
    df=get_combined_az_and_tmnist_df,
    start_col=1,
    vocab=VOCAB_UC,
    version=None,
    normalize=False,
    load_saved=True,
    size=28,
    loss_func=CrossEntropyLossFlat(),
    opt_func=Adam,
    init=nn.init.kaiming_normal_,
    lr=defaults.lr,
    splitter=None,
    use_xtra_tfms=False,
    tfms_p=.5,
    blur_size: Tuple[int, Sequence[int]]=5,
    blur_sigma: Tuple[int, Sequence[int]]=(.1, 5.),
    cbs=None,
    metrics=accuracy,
    path=None,
    model_dir=MODELS_PATH,
    wd=None,
    wd_bn_bias=False,
    train_bn=True,
    moms=(0.95,0.85,0.95),
    seed=None,
    **kwargs) -> Learner:
    """Create a new OCR learner based on architecture `arch` and dataset `df`.
       If `pretrained`, the model will be initialised if a suitable save is found."""
    tfms = []
    item_tfms = []
    # Check if we need to pad
    data = df()
    orig_sz = math.isqrt(data.shape[1] - start_col)
    if orig_sz < size:
        pad = (size - orig_sz) // 2
        assert orig_sz + 2 * pad == size
        item_tfms += [Pad(pad, fill=255)]
    if normalize: tfms += [get_imagenet_norm()] # ToRGB(),
    if use_xtra_tfms:
        max_rotate = 15.0
        max_warp = .25
        blur = GaussianBlur(p=tfms_p, random_size=blur_size, sigma=blur_sigma)
        noise = Noise(p=tfms_p, f=(0., .6))
        item_tfms += [blur, noise]
    else:
        max_rotate = 5.0
        max_warp = .1
    aug_tfms = aug_transforms(mult=1.0, do_flip=False, flip_vert=False, max_rotate=max_rotate,
                          min_zoom=0.85, max_zoom=1.15, max_warp=max_warp, p_affine=tfms_p,
                          p_lighting=0., xtra_tfms=None, size=size, mode='bilinear',
                          pad_mode='reflection', align_corners=True, batch=False,
                          min_scale=1.0)
    del(aug_tfms[1]) # Remove lighting tfm

    tfms += aug_tfms
    dls = ImageDataLoadersDF.from_df(data, vocab=vocab,
                                     width=orig_sz, height=orig_sz,
                                     num_workers=0, # Needed for Mac
                                     valid_pct=0.2,
                                     batch_tfms=tfms,
                                     item_tfms=item_tfms,
                                     color=normalize,
                                     seed=seed, bs=bs)
    if n_out is None: n_out = get_c(dls)
    # This is a crappy, but we can specify the splitter in arch
    model_and_splitter = arch(n_out, input_shape=(size, size))
    if type(model_and_splitter) is tuple:
        model,splitter = model_and_splitter
    else:
        model = model_and_splitter
        splitter = lambda m: L(m[0], m[1:]).map(params)
    learn = Learner(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr,
                    splitter=splitter, cbs=cbs,  metrics=metrics, path=path, model_dir=model_dir,
                    wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn, moms=moms)
    if load_saved: learn.load(get_learner_filename(arch=arch, df=df, vocab=vocab, version=version))
    store_attr('arch,normalize,n_out', self=learn, **kwargs)
    return learn

# Cell

def create_nist_learner(path = NIST_PATH, model_path = MODELS_PATH, vocab = None,
                        cut = 5, size = 128) -> Learner:

    enable_global_greyscale()

    fnames = get_nist_images(vocab=vocab,
                             path=path,
                             show_stats=False)
    tfms = aug_transforms(mult=1.0, do_flip=False, flip_vert=False, max_rotate=5.0,
                          min_zoom=0.85, max_zoom=1.15, max_warp=0.1, p_affine=.5,
                          p_lighting=0., xtra_tfms=None, size=size, mode='bilinear',
                          pad_mode='reflection', align_corners=True, batch=False,
                          min_scale=1.0)
    del(tfms[1]) # Remove lighting tfm
    print("WARN! Need to add custom normalisation scheme and check this doesn't expand channels!")
    # Normalize.from_stats(mean,std)
    # https://docs.fast.ai/data.transforms.html#Normalize
    # X_train_mean = X_train.mean().astype(np.float32)
    # X_train_std = X_train.std().astype(np.float32)
    # X_test_mean = X_test.mean().astype(np.float32)
    # X_test_std = X_test.std().astype(np.float32)

    # X_train = (X_train - X_train_mean)/X_train_std
    # X_test = (X_test - X_test_mean)/X_test_std
    dls = ImageDataLoaders.from_name_func(path, fnames, nist_from_name_func,
                                          num_workers=0,   # Needed for Mac
                                          valid_pct=0.2,
                                          batch_tfms=tfms, # This raises if used as item_tfms
                                          seed=42)



    learn = cnn_learner(dls, resnet18,
                        n_in=1,
                        normalize=False, # ImageNet norm makes image 3-channel
                        path=".",
                        model_dir=model_path,
                        loss_func=CrossEntropyLossFlat(),
                        metrics=accuracy,
                        cut=cut)
    return learn

# Cell

def create_ocr_model(epochs=1, save_as = "OCR_resnet18_wip",
                     load_from: str = None, cut: int = None,
                     resize: int = None) -> Learner:
    """Create a simple resnet18-based OCR model cut at `cut` with images
       optionally resized to `resize` and fine-tuning for `epochs`,
       or load one from `load_from`."""
    path = GOOGLE_FONT_PATH
    model_path = "models"
    fnames = get_image_files(path)
    pat = r"^([^_]+)_.+$"
    for f in fnames: assert re.search(pat, str(f)) is not None

    dls = ImageDataLoaders.from_name_re(path, fnames, pat,
                                        num_workers=0, # NEEDED FOR MAC!
                                        valid_pct=0.2,
                                        item_tfms=Resize(resize, method=ResizeMethod.Squish) if resize is not None else None,
                                        seed=42)
    learn = cnn_learner(dls, resnet18,
                        path=".",
                        model_dir=model_path,
                        loss_func=F.cross_entropy,
                        metrics=accuracy,
                        cut=cut)

    if load_from is not None:
        learn.load(load_from)
    elif epochs is not None:
        learn.fine_tune(epochs)
        learn.save(save_as)

    return learn

def get_ocr_model(cut: int = None, img_size: int = None) -> Learner:
    """Get a basic pretrained ocr model cut at `cut` and with input
       at `img_size`."""
    file = "OCR_resnet18"
    if cut is not None: file += f"_cut{cut}"
    if img_size is not None: file += f"_imgsize{img_size}"
    return create_ocr_model(load_from=file, cut=cut, resize=img_size)