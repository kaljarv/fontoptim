# AUTOGENERATED! DO NOT EDIT! File to edit: 02_lettervectors.ipynb (unless otherwise specified).

__all__ = ['SansSerifFontRL', 'DEFAULT_FONT_PARAM_SPECS', 'LETTERS_CROP_BOTH', 'LETTERS_CROP_TOP_ONLY',
           'LETTERS_PAD_LEFT', 'LETTERS_PAD_RIGHT', 'LETTERS_PAD_TOP', 'LETTERS_PAD_BOTTOM', 'LETTERS_OVERSHOOT_TOP',
           'LETTERS_OVERSHOOT_BOTTOM', 'create_vector_learner', 'fit_pvals_naively', 'reset_params_and_optimise',
           'plot_param_values', 'filter_imgs', 'filter_results', 'get_imgs', 'get_losses_and_activations',
           'residual_entropy', 'plot_activations', 'plot_residual_entropy']

# Cell
from .core import *
from .fontlearner import *
from .ocrlearner import *
from collections import OrderedDict
from fastai.data.all import *
from fastai.vision.all import *
import gc
from nbdev.showdoc import *
from pandas import DataFrame
import pydiffvg
import torch
from typing import Callable, List, Protocol, Tuple, Union

# Cell

DEFAULT_FONT_PARAM_SPECS = OrderedDict({
    "Height":       PRANGE_NONZERO,
    "Slant":        PRANGE_BIDIR,
    "Midline":      PRANGE_DEFAULT,
    "Width, AV":    PRANGE_NONZERO,
    "Offset xp from symmetry, AXZ": PRANGE_BIDIR_S,
    "Overshoot, AMNVW": PRANGE_ASYM_S, # An option is to allow negative values for this
    "Crossbar y offset, A": PRANGE_BIDIR_H,
    "Stroke width": PRANGE_STROKE,
    })

# Letter groups
# Crop the ends of strokes going beyond cap height or baseline
LETTERS_CROP_BOTH        = "AB DE FHI KLMN P R T VWXYZ"
LETTERS_CROP_TOP_ONLY    = "         J          U     "
# Pad vertex points by half stroke width
LETTERS_PAD_LEFT         = "ABCDEFGHIJKLMNOPQRS UVWXYZ"
LETTERS_PAD_RIGHT        = "ABCD  GHIJK MNOPQRS UVWXY "
LETTERS_PAD_TOP          = " BCDEFG       OPQRST     Z"
LETTERS_PAD_BOTTOM       = " BCDE G  J L  O Q S U    Z"
# The directions to apply overshoot to
LETTERS_OVERSHOOT_TOP    = "A C   G       O Q S       "
LETTERS_OVERSHOOT_BOTTOM = "  C   G  J    O Q S UVW   "

class SansSerifFontRL(VectorRenderLayerBase):
    """A model for rendering a whole sans serif font. Init takes `vocab`
       to define which letters are allowed. `param_specs` defines the
       value ranges for the parameters (see source)."""

    def __init__(self, param_specs: OrderedDict = DEFAULT_FONT_PARAM_SPECS, max_distance=1.0, **kwargs):
        assert param_specs is not None
        assert max_distance == 1.0, "Do not use max_distance with SansSerifFontRL"
        # Note that we allow the full range for stroke_width as it's restrictions are
        # done in param_specs
        super(SansSerifFontRL, self).__init__(param_specs=param_specs, max_distance=max_distance,
                                              stroke_width = (0., 1.), **kwargs)

    def crop_box(self, p1=tensor(0., 0.), p2=tensor(1., 1.), expand_distance=True) -> pydiffvg.Rect:
        """Create a cropping box with corner points `p1` and `p2`."""
        return pydiffvg.Rect(self.expand_distance(p1) if expand_distance else p1,
                             self.expand_distance(p2) if expand_distance else p2,
                             stroke_width=tensor(0.))

    def create_scenes(self) -> None:
        """Create scenes for rendering for the whole batch contained in `self.x`."""
        for i in range(self.bs):
            self.i = i
            letter = self.get_letter()

            # General params
            p_height   = self.get_param_value("Height")
            # p_slant  = self.get_param_value("Slant") # NOT USED
            p_midline  = self.get_param_value("Midline")
            p_stroke_w = self.get_param_value("Stroke width")

            # Precalculated properties
            top_y = (1 - p_height) / 2
            baseline_y = top_y + p_height
            expanded_stroke_w = self.expand_stroke_width(p_stroke_w)

            shapes = None

            def get_bbox(p_width, p_overshoot = tensor(0.)) -> Tensor:
                """Calculate the coordinates for the bounding box of vertices.
                    NB. Needs access to global params."""
                w = p_height * p_width
                x1 = (1 - w) / 2
                x2 = x1 + w
                y1 = (1 - p_height) / 2
                y2 = y1 + p_height
                dw = p_stroke_w / 2
                if letter in LETTERS_PAD_LEFT:         x1 += dw
                if letter in LETTERS_PAD_RIGHT:        x2 -= dw
                if letter in LETTERS_PAD_TOP:          y1 += dw
                if letter in LETTERS_PAD_BOTTOM:       y2 -= dw
                if letter in LETTERS_OVERSHOOT_TOP:    y1 -= p_overshoot
                if letter in LETTERS_OVERSHOOT_BOTTOM: y2 += p_overshoot
                return concat_tensors(x1, y1, x2, y2, x2 - x1, y2 - y1).reshape(3, 2)

            if letter == "A":
                # Consists of an inverted V shape and the crossbar
                # The angles of the V can be asymmetrically slanted

                # Local params
                p_width            = self.get_param_value("Width, AV")
                p_asymmetry_offset = self.get_param_value("Offset xp from symmetry, AXZ")
                p_overshoot        = self.get_param_value("Overshoot, AMNVW")
                p_crossbar_offset  = self.get_param_value("Crossbar y offset, A")

                # Get vertex bounding box [[xmin, ymin], [xmax, ymax], [width, height]]
                bbox = get_bbox(p_width, p_overshoot)
                w, h = bbox[2][0], bbox[2][1]

                # Get iV relative center
                center_dx = bbox[2][0] / 2 + p_asymmetry_offset

                # Calc iV x/y ratios bc we need to extend the strokes beyond the baseline
                # so that the rounded ends aren't shown. We extend them so that their
                # y coordinates are half stroke_w below the baseline.
                ratio_l = center_dx / h
                ratio_r = (w - center_dx) / h
                iv_dy   = p_stroke_w / 2
                iv_dx_l = iv_dy * ratio_l * -1
                iv_dx_r = iv_dy * ratio_r

                # Calc crossbar coordinates as offsets from the bottom corners
                bar_dy   = (1 - p_midline + p_crossbar_offset) * h * -1
                bar_dx_l = bar_dy * ratio_l * -1
                bar_dx_r = bar_dy * ratio_r

                # Create points tensors
                pts_iv = concat_tensors(
                    bbox[0][0] + iv_dx_l,   bbox[1][1] + iv_dy,
                    bbox[0][0] + center_dx, bbox[0][1],
                    bbox[1][0] + iv_dx_r,   bbox[1][1] + iv_dy,
                    ).reshape(3, 2)
                pts_bar = concat_tensors(
                    bbox[0][0] + bar_dx_l,  bbox[1][1] + bar_dy,
                    bbox[1][0] + bar_dx_r,  bbox[1][1] + bar_dy
                    ).reshape(2, 2)

                # Add shapes
                shapes = self.points_to_polygons(pts_iv, pts_bar,
                                                 stroke_width=expanded_stroke_w, expand_distance=True)

                if self.debug:
                    print(f"iv_dy: {iv_dy.item()} • iv_dx_l: {iv_dx_l.item()} • iv_dx_r: {iv_dx_r.item()}")
                    print("Bbox:", bbox)
                    for i, s in enumerate(shapes): print(f"Shape {i}", {s.points})

            else: raise NotImplementedError(f"Letter '{letter}' not implemented.")

            crop_boxes = []

            # Crop from above and/or below
            if letter in LETTERS_CROP_BOTH or letter in LETTERS_CROP_TOP_ONLY:
                crop_boxes.append(self.crop_box(p2=tensor(1., top_y)))
            if letter in LETTERS_CROP_BOTH:
                crop_boxes.append(self.crop_box(p1=tensor(0., baseline_y)))

            # We need to add bg color to get rid of artefacts at the edges of the crop boxes
            self.scenes[self.i] = self.create_mixed_scene(line_shapes=shapes, fill_shapes=crop_boxes,
                                                          bg_color=COLOR_WHITE, fill_color=COLOR_WHITE)
            # self.scenes[self.i] = self.create_mixed_scene(line_shapes=[], fill_shapes=crop_boxes, fill_color=COLOR_WHITE)

# Cell

def create_vector_learner(bs = 1, epoch_len = 10, cut = 5, img_size = None, ocr_learner = None,
                          folder = "results/test_3c_ATI", normalise = True, vector_class = SansSerifFontRL,
                          n_colors_out = 1, eps = None, lr = 1e-2, debug = False, cbs = None, seed = None,
                          init_range = 2.):

    if eps is not None: warn(f"Using eps {eps}")

    if ocr_learner is None:
        ocr_learner = get_ocr_model(cut=cut,
                                    img_size=img_size)
    ocr_model = ocr_learner.model
    vocab = get_vocab(ocr_learner)
    raster_norm = ocr_learner.dls.train.after_batch[1] if normalise else None
    ocr_img = ocr_learner.dls.train_ds[0][0]
    canvas_width = ocr_img.width
    canvas_height = ocr_img.height

    def get_dl():
        return LetterDL(vocab=vocab,
                        letters=("A",),
                        epoch_len=epoch_len,
                        bs=bs)
    dls = DataLoaders(get_dl(), get_dl())

    image_saver = ImageSaver(folder=folder)
    render_layer = vector_class(vocab=vocab,
                                raster_norm=raster_norm,
                                rendered_callback=image_saver,
                                canvas_width=canvas_width,
                                canvas_height=canvas_height,
                                n_colors_out=n_colors_out,
                                seed=seed,
                                # max_distance=max_distance,
                                eps=eps,
                                init_range=init_range)
    if debug: render_layer.debug = debug
    font_model = render_layer # torch.nn.Sequential(render_layer, Debugger())

    # Params will be added by Learner
    get_optim = partial(Adam, lr=lr,
                              mom=.5,
                              sqr_mom=.9,
                              wd=0.) # NB. Eps can be also modified

    loss = OCRAndParamLoss(ocr_model=ocr_model,
                           vector_model=render_layer,
                           debug=debug)

    vector_learner = VectorLearner(dls=dls,
                                   model=font_model,
                                   loss_func=loss,
                                   opt_func=get_optim,
                                   cbs=cbs,
                                   image_saver=image_saver)

    return vector_learner, image_saver

# Cell
def fit_pvals_naively(
    learner,
    epochs = 10,
    smooth_loss_dist = 6,
    apply_pval_immediately = True,
    exclude = ["Slant"]
    ) -> DataFrame:
    """"Iteratively calculate losses for different param values and apply them."""
    param_names = [x for x in learner.model.param_names if x not in exclude]
    res = []
    for e in range(epochs):
        p_losses = {}
        p_vals = {}
        random.shuffle(param_names)
        for p in param_names:
            df = learner.calculate_losses(p, plot=False, smooth_loss_dist=smooth_loss_dist)
            opt_val = get_argmin(df)
            loss = df.loss.min()
            p_losses[p] = loss
            p_vals[p] = opt_val
            if apply_pval_immediately: learner.set_param(p, opt_val)
        img = learner.render_letter("A", scale=5)
        res.append({
            "values": p_vals,
            "losses": p_losses,
            "order": list(param_names),
            "loss_at_end": loss,
            "img": img,
            "info": f"Epoch {e} • Loss {loss} (values applied {'immediately' if apply_pval_immediately else 'at end of epoch'})"
            })
        if not apply_pval_immediately:
            for p in param_names: learner.set_param(p, p_vals[p])
    return res

def reset_params_and_optimise(
    learner,
    n_iters = 10,
    epochs = 5,
    vocal = True,
    ) -> Tuple[list, list[PILImage]]:
    """Reset learner parameters and naively optimise `n_iters` times.
       Return results and initial renderings before optimisation."""
    all_res = []
    init_imgs = []
    for i in range(n_iters):
        learner.reset_parameters()
        init_img = learner.render_letter("A", scale=5)
        init_imgs.append(init_img)
        res = fit_pvals_naively(learner, epochs=5)
        all_res.append(res)
        if vocal:
            print(f"Iteration {i} • Loss {res[-1]['loss_at_end']}")
            display(init_img)
            display(res[-1]["img"])
    return all_res, init_imgs

import statistics
def plot_param_values(
    learner,
    all_res,
    figsize = (10,10),
    vary_marker_size = True,
    marker_size_factor = 20.,
    marker_size_max_sd = 2.,
    marker_size_min = 1.
    ) -> None:
    """Plot the param values in all_res with size modulated by loss."""
    plt.figure(figsize=figsize)
    losses = [x[-1]["loss_at_end"] for x in all_res]
    loss_sd = statistics.stdev(losses)
    min_loss = min(losses)
    p_names = [x for x in learner.model.param_names if x in all_res[0][0]["values"]]
    for res in all_res:
        vals = [res[-1]["values"][k] for k in p_names]
        loss = res[-1]["loss_at_end"]
        loss_dist = (loss - min_loss) / loss_sd
        size = (marker_size_max_sd - loss_dist) / marker_size_max_sd if vary_marker_size else 1.
        size = size * marker_size_factor if size > 0 else 0
        size += marker_size_min
        plt.scatter(p_names, vals, s=size)

def filter_imgs(
    all_res: list,
    **kwargs
    ) -> List[Image.Image]:
    """Filter all results by loss `sd_dist` standard deviations from minimum
       and results the rendered images for those. Use this with `image_grid`."""
    return get_imgs(filter_results(all_res, **kwargs))

def filter_results(
    all_res: list,
    sd_dist =  1.,
    sort = True
    ) -> list:
    """Filter all results by loss `sd_dist` standard deviations from minimum."""
    losses = [x[-1]["loss_at_end"] for x in all_res]
    loss_sd = statistics.stdev(losses)
    min_loss = min(losses)
    if sort: all_res = sorted(all_res, key = lambda x: x[-1]["loss_at_end"])
    return [x for x in all_res if \
            sd_dist is None or x[-1]["loss_at_end"] - min_loss <= sd_dist * loss_sd]

def get_imgs(all_res: list) -> List[Image.Image]:
    """Extract final images from all results."""
    return [x[-1]["img"] for x in all_res]

def get_losses_and_activations(
    res_file = "results/test_6_letter_A_all_params/all_res_2.pkl",
    sd_dist = .05,
    letter = "A",
    re_loss_weight = 0.
    ) -> list[dict]:
    """Load pickled esults returned by, e.g., `reset_params_and_optimise`,
       filter by loss SD of max `sd_dist` from min and return a list of
       dicts containing the loss, activations tensor and rendered image
       for each."""
    naive_results = pickle.load(open(res_file, "rb"))
    letter_i = learner.vocab.index(letter)
    losses_and_activations = []
    inp = tensor([0] * len(learner.vocab))
    inp[letter_i] = tensor(1)
    # inp.unsqueeze_(0)
    m = learner.model
    m_inp = tensor([letter_i])
    with eval_model(m):
        with torch.no_grad():
            with debug(learner.loss_func.ocr_loss):
                for r in filter_results(naive_results, sd_dist=sd_dist):
                    for p, v in r[-1]["values"].items(): learner.set_param(p, v)
                    img_tensor = m(m_inp)
                    learner.loss_func.ocr_loss(img_tensor, m_inp)
                    s = learner.loss_func.ocr_loss.stored[-1]
                    xe = s[0]
                    act = s[3]
                    re = residual_entropy(act, inp, softmax=True)
                    losses_and_activations.append({
                        "loss": (1 - re_loss_weight) * xe + re_loss_weight * re,
                        "xe_loss": xe,
                        "re_loss": re,
                        "activations": act,
                        "img": learner.render_letter(letter, scale=5)
                        })
    return losses_and_activations

from torch.distributions import Categorical
def residual_entropy(
    input: Tensor,
    target: Tensor = None,
    softmax = False,
    factor = 1/3,
    invert = True
    ) -> Tensor:
    """Calculate the entropy of the incorrect activations or others except the
       highest one if `target` is not supplied. `input` should be softmaxed
       or `softmax` set to True. `factor` is used to approximately normalise
       the value. Note that we `invert` the value to suit our goals."""
    if softmax: input = F.softmax(input)
    if target is not None:
        test_close(target.sum(), 1.) # Expect one-hot tensor
        input = (1 - target) * input
    else: input = input.sort(descending=True)[0][1:]
    ent = Categorical(probs=input).entropy() * factor
    return 1 / (ent + 1e-10) if invert else ent

def plot_activations(
    learner,
    losses_and_activations,
    softmax = False,
    exclude: str = None,
    figsize = (6, 6)
    ) -> None:
    """Plot the activations."""
    plt.figure(figsize=figsize)
    names = list(learner.vocab)
    if exclude is not None:
        excl_i = names.index(exclude)
        names.remove(exclude)
    for res in losses_and_activations:
        acts = res["activations"]
        if softmax: acts = F.softmax(acts, dim=0)
        if exclude is not None: acts = [x for i, x in enumerate(acts.numpy()) if i != excl_i]
        plt.plot(names, acts)

def plot_residual_entropy(
    losses_and_activations,
    target = None,
    figsize = (6, 6)
    ) -> Tuple[list, list]:
    """Plot the residual entropies exluding the highest activation against loss."""
    plt.figure(figsize=figsize)
    losses = [x["loss"] for x in losses_and_activations]
    entrs =  [residual_entropy(x["activations"], target=target) for x in losses_and_activations]
    plt.scatter(losses, entrs)
    return losses, entrs