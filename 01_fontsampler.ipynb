{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# default_exp core\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aifont.fontsampler\n",
    "\n",
    "> Utilities to create images from Google Fonts. Code mostly by https://erraticgenerator.com/blog/use-google-fonts-for-machine-learning-part1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Font Metadata\n",
    "\n",
    "> Get font metadata from the Google Fonts API. Needed only once. You need an API key for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "def create_google_font_metadata(data_path: str = None, api_key: str = None, \n",
    "    save_path = \"google-fonts-annotation.csv\") -> pd.DataFrame:\n",
    "    \"\"\"Get Google Fonts metadata either from the API using `api_key` or from\n",
    "       a local file at `data_path` and save the data as csv in `save_path`.\n",
    "       Also returns the data frame.\"\"\"\n",
    "\n",
    "    assert api_key is not None or data_path is not None\n",
    "\n",
    "    if data_path is not None:\n",
    "        # Use JSON already downloaded\n",
    "        df = pd.read_json(data_path)\n",
    "    else:\n",
    "        # Download json data once\n",
    "        url = f\"https://www.googleapis.com/webfonts/v1/webfonts?key={api_key}\"\n",
    "        df = pd.read_json(url, orient='')\n",
    "\n",
    "    # flatten the JSON hierarchy (easier to handle this way)\n",
    "    df = pd.json_normalize(df['items'])\n",
    "\n",
    "    # select only the columns we need\n",
    "    cols = ['family', 'variants', 'subsets', 'category']\n",
    "    df = df[cols]\n",
    "    # df.head(5)\n",
    "\n",
    "    # Remove any space from family string so that it matchs with file name convention.\n",
    "    df.family = [name.replace(' ', '') for name in df.family]\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "\n",
    "    # one-hot encoding + prefix\n",
    "    df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('variants')),\n",
    "                            columns=[x for x in mlb.classes_],\n",
    "                            index=df.index))\n",
    "    df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('subsets')),\n",
    "                            columns=['subsets_' + x for x in mlb.classes_],\n",
    "                            index=df.index))\n",
    "    df = df.join(pd.get_dummies(df['category'], prefix=\"category\")).drop(['category'], axis=1)\n",
    "\n",
    "    col_names = {\n",
    "        \"100\": \"thin\",\n",
    "        \"100italic\": \"thinitalic\",\n",
    "        \"200\": \"extralight\",\n",
    "        \"200italic\": \"extralightitalic\",\n",
    "        \"300\": \"light\",\n",
    "        \"300italic\": \"lightitalic\",\n",
    "        \"400\": \"regular\",\n",
    "        \"regular\": \"regular\",\n",
    "        \"400italic\": \"italic\",\n",
    "        \"italic\": \"italic\",\n",
    "        \"500\": \"medium\",\n",
    "        \"500italic\": \"mediumitalic\",\n",
    "        \"600\": \"semibold\",\n",
    "        \"600italic\": \"semibolditalic\",\n",
    "        \"700\": \"bold\",\n",
    "        \"700italic\": \"bolditalic\",\n",
    "        \"800\": \"extrabold\",\n",
    "        \"800italic\": \"extrabolditalic\",\n",
    "        \"900\": \"black\",\n",
    "        \"900italic\": \"blackitalic\"\n",
    "    }\n",
    "    col_names = {k:f'variants_{v}' for k, v in col_names.items()}\n",
    "\n",
    "    df = df.rename(col_names, axis='columns')\n",
    "\n",
    "    # Export csv\n",
    "    if not save_path.endswith(\".csv\"):\n",
    "        save_path += \".csv\"\n",
    "    df.to_csv(save_path, index=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_fontsampler.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
