{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fontsampler\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Font Sampler\n",
    "\n",
    "> Utilities to create images from Google Fonts. Code mostly by [@erraticgener8or](https://erraticgenerator.com/blog/use-google-fonts-for-machine-learning-part1/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from aifont.core import *\n",
    "import glob\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from os.path import basename, join, splitext\n",
    "from PIL import Image\n",
    "import random\n",
    "import re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from typing import Union"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering Font Images\n",
    "\n",
    "> Selecting Google Fonts and rendering font images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "GOOGLE_FONT_ROOT_PATH = \"data/google_fonts\"\n",
    "\n",
    "class FontSampler:\n",
    "    \"\"\"Sample Google Fonts and render as images. `df` or `df_path` should point to font annotations\n",
    "       (see `create_font_annotations`), `font_path` to the root folder of the ofl fonts. Control\n",
    "       font selection with `variants`, `subsets` and `category`, which can be either strings or \n",
    "       regexs. Note that the search is performed on an AND basis meaning that if you define, e.g.,\n",
    "       `variants=['regular', 'medium']`, you will only find font faces where the family itself\n",
    "       contains both. Use `add_fonts` with another variant if you want to perform an OR-type\n",
    "       search.\"\"\"\n",
    "    def __init__(self, \n",
    "        df: DataFrame = None, \n",
    "        df_path: str = f\"{GOOGLE_FONT_ROOT_PATH}/google-fonts-annotation.csv\", \n",
    "        font_path: str = \"data/fonts\", \n",
    "        variants: list[str] = None, \n",
    "        subsets: list[str] = [\"latin\"], \n",
    "        category: str = None, \n",
    "        image_width: int = 256, \n",
    "        image_height: int = 256\n",
    "    ):\n",
    "        self.df = pd.read_csv(df_path) if df is None else df\n",
    "        self.font_path = font_path\n",
    "        self.variants = variants\n",
    "        self.subsets = subsets\n",
    "        self.category = category\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.font_index = -1\n",
    "        self.paths = []\n",
    "        self.set_fonts(self.filter_fonts_get_paths())\n",
    "\n",
    "    @property\n",
    "    def num_fonts(self):\n",
    "        \"\"\"Get the number of fonts found.\"\"\"\n",
    "        return len(self.paths)\n",
    "\n",
    "    def set_fonts(self, paths: list[str]) -> None:\n",
    "        \"\"\"Set paths and shuffle them.\"\"\"\n",
    "        self.paths = list(paths)\n",
    "        random.shuffle(self.paths)\n",
    "        # Reset index\n",
    "        self.font_index = -1\n",
    "\n",
    "    def add_fonts(self, variants: list[str] = None, subsets: list[str] = None, \n",
    "        category: str = None) -> None:\n",
    "        \"\"\"Add fonts to `self.paths` using the criteria.\"\"\"\n",
    "        paths = self.filter_fonts_get_paths(variants=variants, subsets=subsets, category=category)\n",
    "        paths = list(set(paths + self.paths))\n",
    "        self.set_fonts(paths)\n",
    "\n",
    "    def remove_fonts(self, variants: list[str] = None, subsets: list[str] = None, \n",
    "        category: str = None) -> None:\n",
    "        \"\"\"Remove fonts from `self.paths` using the criteria.\"\"\"\n",
    "        remove = self.filter_fonts_get_paths(variants=variants, subsets=subsets, category=category)\n",
    "        paths = list(self.paths)\n",
    "        for p in remove:\n",
    "            if p in paths: paths.remove(p)\n",
    "        self.set_fonts(paths)\n",
    "\n",
    "    def filter_fonts_get_paths(self, variants: list[str] = None, subsets: list[str] = None, \n",
    "        category: str = None) -> list[str]:\n",
    "        \"\"\"Filter the fonts list by the criteria and return a list of file paths.\"\"\"\n",
    "        df = self.df\n",
    "        font_path = self.font_path\n",
    "        if variants is None: variants = self.variants\n",
    "        if subsets is None: subsets = self.subsets\n",
    "        if category is None: category = self.category\n",
    "        # exceptions\n",
    "        if variants is None or variants == [''] or variants == '': variants = ['_']\n",
    "        if subsets is None or subsets == [''] or subsets == '': subsets = ['_']\n",
    "        if category is None: category = ''\n",
    "        # apply filters\n",
    "        regex_filters = variants + subsets + ['_' + category]\n",
    "        df_new = pd.concat([df.filter(regex=re.compile(regex, re.IGNORECASE), axis=1).sum(axis=1).astype(bool) \n",
    "                            for regex in regex_filters], axis=1)\n",
    "        mask = df_new.all(axis=1)\n",
    "        filtered_fontnames = list(df.loc[mask].family)\n",
    "        # construct file paths\n",
    "        paths = []\n",
    "        for fontname in filtered_fontnames:\n",
    "            if variants == ['_']: # select all variants\n",
    "                sel = glob.glob(f'{font_path}/{fontname.lower()}/**/*.ttf', recursive=True)\n",
    "                paths.extend(sel)\n",
    "            else:\n",
    "                for variant in variants:\n",
    "                    sel = glob.glob(f'{font_path}/{fontname.lower()}/**/{fontname}-{variant}.ttf', recursive=True) \n",
    "                    for path in sel: paths.append(path)\n",
    "        if len(paths) == 0: raise Exception(\"No matching fonts found!\")\n",
    "        # print(f'Found {len(paths)} font files.')\n",
    "        return paths\n",
    "\n",
    "    def render_text(self, text: str, text_size: int = None, x: int = None, y: int = None, \n",
    "        font_index: int = None, image_width: int = None, image_height: int = None, \n",
    "        as_normalised_array = False, include_font = False) -> Union[\n",
    "            tuple[np.ndarray, str], tuple[Image.Image, str], tuple[None, None],\n",
    "            np.ndarray, Image.Image, None\n",
    "            ]:\n",
    "        \"\"\"Render the given text as black on white and return either as a normalised \n",
    "           numpy array of (alpha) values, a PIL Image or a tuple with one of these and the\n",
    "           font filename if `include_font` is True. If called without font_index, will \n",
    "           iterate over all paths and return None once the end is reached.\"\"\"\n",
    "        paths = self.paths\n",
    "        if font_index is None:\n",
    "            if self.font_index >= len(paths):\n",
    "                self.font_index = -1\n",
    "                return (None, None) if include_font else None\n",
    "            self.font_index += 1\n",
    "            font_index = self.font_index\n",
    "        if image_width is None:  image_width = self.image_width\n",
    "        if image_height is None: image_height = self.image_height\n",
    "        font_path = paths[font_index % len(paths)]\n",
    "        img = render_text(font_path=font_path, text=text, text_size=text_size, x=x, y=y, \n",
    "                          image_width=image_width, image_height=image_height, as_normalised_array=as_normalised_array)\n",
    "        # Include  font name if needed\n",
    "        if include_font: return (img, basename(font_path))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FontSampler.num_fonts\" class=\"doc_header\"><code>FontSampler.num_fonts</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Get the number of fonts found."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FontSampler.render_text\" class=\"doc_header\"><code>FontSampler.render_text</code><a href=\"__main__.py#L109\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FontSampler.render_text</code>(**`text`**:`str`, **`text_size`**:`int`=*`None`*, **`x`**:`int`=*`None`*, **`y`**:`int`=*`None`*, **`font_index`**:`int`=*`None`*, **`image_width`**:`int`=*`None`*, **`image_height`**:`int`=*`None`*, **`as_normalised_array`**=*`False`*, **`include_font`**=*`False`*)\n",
       "\n",
       "Render the given text as black on white and return either as a normalised \n",
       "numpy array of (alpha) values, a PIL Image or a tuple with one of these and the\n",
       "font filename if `include_font` is True. If called without font_index, will \n",
       "iterate over all paths and return None once the end is reached."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FontSampler.num_fonts)\n",
    "show_doc(FontSampler.render_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render a letter as a grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x1271E4820>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = FontSampler(category=\"sans-serif\")\n",
    "img = fs.render_text('A'); img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or as a numpy matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_img = fs.render_text('A', as_normalised_array=True, font_index=0)\n",
    "np_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use it with `diffvg`, use the values as the A-band of the RGBA tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 256]), torch.Size([256, 256, 1]), torch.Size([256, 256, 4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "wd_ht = torch.tensor(np_img, dtype=torch.float32)\n",
    "wd_ht_a = torch.reshape(wd_ht, wd_ht.shape + tuple([1]))\n",
    "wd_ht_rgba = F.pad(input=wd_ht_a, pad=(3, 0, 0, 0, 0, 0), mode='constant', value=0)\n",
    "wd_ht.shape, wd_ht_a.shape, wd_ht_rgba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FontSampler.add_fonts\" class=\"doc_header\"><code>FontSampler.add_fonts</code><a href=\"__main__.py#L70\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FontSampler.add_fonts</code>(**`variants`**:`list`\\[`str`\\]=*`None`*, **`subsets`**:`list`\\[`str`\\]=*`None`*, **`category`**:`str`=*`None`*)\n",
       "\n",
       "Add fonts to `self.paths` using the criteria."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FontSampler.add_fonts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Font Samples\n",
    "\n",
    "> Using FontSampler to create a set of font images for use in learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_font_images(texts = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"), \n",
    "    variants = [\"regular\", \"medium\", \"light\"], file_extension = \".png\",\n",
    "    image_width = 256, image_height = 256, out_path = f\"{GOOGLE_FONT_ROOT_PATH}/font_images\") -> None:\n",
    "    \"\"\"Create font images and save them. Find matching font `variants` and\n",
    "       renders grayscale `image_width` x `image_height` images for each\n",
    "       of the `texts` using `FontSampler.render_text`.\"\"\"\n",
    "\n",
    "    fs = FontSampler(category=\"sans-serif\", \n",
    "                     subsets=[\"latin\"],\n",
    "                     variants=[variants[0]] if len(variants) > 0 else None,\n",
    "                     image_width=image_width,\n",
    "                     image_height=image_height)\n",
    "\n",
    "    if len(variants) > 1:\n",
    "        for v in variants[1:]:\n",
    "            fs.add_fonts(category=\"sans-serif\",\n",
    "                         subsets=[\"latin\"],\n",
    "                         variants=[v])\n",
    "\n",
    "    print(f\"{fs.num_fonts} fonts found.\")\n",
    "\n",
    "    for i in range(fs.num_fonts):\n",
    "        if i % 20 == 0: print(f\"Font {i}/{fs.num_fonts}\")\n",
    "        for t in texts:\n",
    "            img, font = fs.render_text(t, \n",
    "                                       font_index=i,\n",
    "                                       include_font=True)\n",
    "            font = splitext(font)[0]\n",
    "            filename = join(out_path, f\"{t}_{font}{file_extension}\")\n",
    "            try:\n",
    "                img.save(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {font} / {t}: {e}\")\n",
    "    \n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Font Metadata\n",
    "\n",
    "> Get font metadata from the Google Fonts API. Needed only once. You need an API key for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def create_font_annotations(data_path: str = os.path.join(GOOGLE_FONT_ROOT_PATH, \"webfonts.json\"), api_key: str = None, \n",
    "    save_path = \"data/google-fonts-annotation.csv\") -> DataFrame:\n",
    "    \"\"\"Get Google Fonts metadata either from the API using `api_key` or from\n",
    "       a local file at `data_path` and save the data as csv in `save_path`.\n",
    "       Also returns the data frame.\"\"\"\n",
    "\n",
    "    assert api_key is not None or data_path is not None\n",
    "\n",
    "    if data_path is not None:\n",
    "        # Use JSON already downloaded\n",
    "        df = pd.read_json(data_path)\n",
    "    else:\n",
    "        # Download json data once\n",
    "        url = f\"https://www.googleapis.com/webfonts/v1/webfonts?key={api_key}\"\n",
    "        df = pd.read_json(url, orient='')\n",
    "\n",
    "    # flatten the JSON hierarchy (easier to handle this way)\n",
    "    df = pd.json_normalize(df['items'])\n",
    "\n",
    "    # select only the columns we need\n",
    "    cols = ['family', 'variants', 'subsets', 'category']\n",
    "    df = df[cols]\n",
    "    # df.head(5)\n",
    "\n",
    "    # Remove any space from family string so that it matchs with file name convention.\n",
    "    df.family = [name.replace(' ', '') for name in df.family]\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "\n",
    "    # one-hot encoding + prefix\n",
    "    df = df.join(DataFrame(mlb.fit_transform(df.pop('variants')),\n",
    "                           columns=[x for x in mlb.classes_],\n",
    "                           index=df.index))\n",
    "    df = df.join(DataFrame(mlb.fit_transform(df.pop('subsets')),\n",
    "                           columns=['subsets_' + x for x in mlb.classes_],\n",
    "                           index=df.index))\n",
    "    df = df.join(pd.get_dummies(df['category'], prefix=\"category\")).drop(['category'], axis=1)\n",
    "\n",
    "    col_names = {\n",
    "        \"100\": \"thin\",\n",
    "        \"100italic\": \"thinitalic\",\n",
    "        \"200\": \"extralight\",\n",
    "        \"200italic\": \"extralightitalic\",\n",
    "        \"300\": \"light\",\n",
    "        \"300italic\": \"lightitalic\",\n",
    "        \"400\": \"regular\",\n",
    "        \"regular\": \"regular\",\n",
    "        \"400italic\": \"italic\",\n",
    "        \"italic\": \"italic\",\n",
    "        \"500\": \"medium\",\n",
    "        \"500italic\": \"mediumitalic\",\n",
    "        \"600\": \"semibold\",\n",
    "        \"600italic\": \"semibolditalic\",\n",
    "        \"700\": \"bold\",\n",
    "        \"700italic\": \"bolditalic\",\n",
    "        \"800\": \"extrabold\",\n",
    "        \"800italic\": \"extrabolditalic\",\n",
    "        \"900\": \"black\",\n",
    "        \"900italic\": \"blackitalic\"\n",
    "    }\n",
    "    col_names = {k:f'variants_{v}' for k, v in col_names.items()}\n",
    "\n",
    "    df = df.rename(col_names, axis='columns')\n",
    "\n",
    "    # Export csv\n",
    "    if not save_path.endswith(\".csv\"):\n",
    "        save_path += \".csv\"\n",
    "    df.to_csv(save_path, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of fonts and variants in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, 1364 fonts with 4790 total variants\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(GOOGLE_FONT_ROOT_PATH, \"webfonts.json\"))\n",
    "tot = sum([len(r['items']['variants']) for _,r in df.iterrows()])\n",
    "print(f'In total, {len(df)} fonts with {tot} total variants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_ocr_model_training_1.ipynb.\n",
      "Converted 01_fontlearnertests.ipynb.\n",
      "Converted 02_first_letter_and_optim_tests.ipynb.\n",
      "Converted 03_vector_models.ipynb.\n",
      "Converted 04_font_statistics.ipynb.\n",
      "Converted 05_full_aphabet_optimisation.ipynb.\n",
      "Converted 06_data_augmentation.ipynb.\n",
      "Converted 07_optimising_with_augmentation.ipynb.\n",
      "Converted 08_comparing_existing_fonts.ipynb.\n",
      "Converted 09_optimise_to_match_font.ipynb.\n",
      "Converted 10_optimising_with_aug_run_2.ipynb.\n",
      "Converted 11_optimise_to_match_font_multires.ipynb.\n",
      "Converted 12_optimising_with_aug_with_multiple_ocr_models.ipynb.\n",
      "Converted 13_analysing_ocr_models.ipynb.\n",
      "Converted 14_ocrlearner_training_2_match_empirical_data.ipynb.\n",
      "Converted aifont_core.ipynb.\n",
      "Converted aifont_fontlearner.ipynb.\n",
      "Converted aifont_fontsampler.ipynb.\n",
      "Converted aifont_ocrlearner.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5710b12fb88680bf60c169aecc91e9487b0350ee3a6536206b6750ffeed12b61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ai-font-p3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
