{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# default_exp fontlearner\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Font Learner\n",
    "\n",
    "> Diffvg-based learner for font optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections.abc import Callable\n",
    "import glob\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import os\n",
    "import pydiffvg\n",
    "import subprocess\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Union\n",
    "\n",
    "class Scene:\n",
    "    \"\"\"Just a utility to hold the different scene arguments together.\n",
    "       The folder argument is optional.\"\"\"\n",
    "    def __init__(self, shapes: list[any], shape_groups: list[pydiffvg.ShapeGroup], \n",
    "        canvas_width = 256, canvas_height = 256, iter_name = \"iter_\", folder: str = None):\n",
    "\n",
    "        assert shapes is not None and len(shapes) != 0\n",
    "        assert shape_groups is not None and len(shape_groups) != 0\n",
    "\n",
    "        self.shapes = shapes\n",
    "        self.shape_groups = shape_groups\n",
    "        self.canvas_width = canvas_width\n",
    "        self.canvas_height = canvas_height\n",
    "        self.iter_name = iter_name\n",
    "        self.folder = folder\n",
    "        self.grad_pattern = \"grad_\"\n",
    "        self._iteration = -1\n",
    "        self._seed = -1\n",
    "\n",
    "    def get_folder(self, folder: str = None) -> str:\n",
    "        \"\"\"A shorthand for parsing the folder argument.\"\"\"\n",
    "        folder = self.folder if folder is None else folder\n",
    "        assert folder is not None\n",
    "        return folder[:-1] if folder.endswith(\"/\") else folder\n",
    "\n",
    "    def get_scene_args(self) -> list:\n",
    "        return pydiffvg.RenderFunction.serialize_scene(self.canvas_width, \n",
    "                                                       self.canvas_height, \n",
    "                                                       self.shapes, \n",
    "                                                       self.shape_groups)\n",
    "    \n",
    "    def new_seed(self) -> int:\n",
    "        \"\"\"For use with render\"\"\"\n",
    "        self._seed += 1\n",
    "        return self._seed\n",
    "\n",
    "    def next_i(self) -> int:\n",
    "        \"\"\"For use with render\"\"\"\n",
    "        self._iteration += 1\n",
    "        return self._iteration\n",
    "\n",
    "    def normalise(self, values: Union[list, float]) -> Tensor:\n",
    "        \"\"\"Create a normalised, grad Tensor from the possible multidim array of points\"\"\"\n",
    "        return torch.tensor(np.array(values) / self.canvas_width, \n",
    "                            dtype=torch.float32, \n",
    "                            requires_grad=True)\n",
    "\n",
    "    def denormalise(self, normalised: Tensor) -> Tensor:\n",
    "        \"\"\"Expand a normalised Tensor\"\"\"\n",
    "        return normalised * self.canvas_width\n",
    "\n",
    "    def render(self, name: str = None, folder: str = None, render_grad = False) -> Tensor:\n",
    "        \"\"\"Render the scene, save as an image and return the image Tensor.\"\"\"\n",
    "\n",
    "        i = self.next_i()\n",
    "        name = f\"{self.iter_name}{i}\" if name is None else name\n",
    "        assert name is not None\n",
    "\n",
    "        folder = self.get_folder(folder)\n",
    "        scene_args = self.get_scene_args()\n",
    "        w = self.canvas_width\n",
    "        h = self.canvas_height\n",
    "        s = self.new_seed()\n",
    "\n",
    "        img = pydiffvg.RenderFunction.apply(w, h, 2, 2, s, None, *scene_args)\n",
    "        # The output image is in linear RGB space. Do Gamma correction before saving the image.\n",
    "        pydiffvg.imwrite(img.cpu(), f\"{folder}/{name}.png\", gamma=2.2)\n",
    "\n",
    "        if render_grad:\n",
    "            grad = pydiffvg.RenderFunction.render_grad(torch.ones(w, h, 4, device=pydiffvg.get_device()),\n",
    "                                                    w, h, 2, 2, s, None, *scene_args)\n",
    "            pydiffvg.imwrite(grad[:,:,0].cpu(), f\"{folder}/{self.grad_pattern}{i}.png\", gamma=2.2)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def render_result_video(self, folder: str = None, iter_pattern: str = None, \n",
    "        out_file=\"0_out\", render_grad = False, delete_imgs = False) -> None:\n",
    "        \"\"\"Render intermediate images and optionally grad as a video.\"\"\"\n",
    "        \n",
    "        folder = self.get_folder(folder)\n",
    "        if iter_pattern is None:\n",
    "            iter_pattern = self.iter_name\n",
    "\n",
    "        def _run(pat = iter_pattern, out = out_file): \n",
    "            subprocess.run([\"ffmpeg\", \n",
    "                            \"-f\", \"lavfi\", \n",
    "                            \"-i\", f\"color=c=white:s={self.canvas_width}x{self.canvas_height}:r=24\",\n",
    "                            \"-framerate\", \"24\", \n",
    "                            \"-i\", f\"{folder}/{pat}%d.png\", \n",
    "                            \"-filter_complex\", \"[0:v][1:v]overlay=shortest=1,format=yuv420p[out]\",\n",
    "                            \"-y\",\n",
    "                            \"-map\", \"[out]\",\n",
    "                            f\"{folder}/{out}.mp4\"],\n",
    "                            capture_output=True)\n",
    "\n",
    "        def _rm(pat = iter_pattern):\n",
    "            # Can't use subprocess with globs\n",
    "            files = glob.glob(f\"{folder}/{pat}*.png\")\n",
    "            for f in files:\n",
    "                os.remove(f)\n",
    "\n",
    "        _run()\n",
    "        if render_grad: \n",
    "            _run(self.grad_pattern, f\"{self.grad_pattern}out\")\n",
    "\n",
    "        if delete_imgs:\n",
    "            _rm()\n",
    "            if render_grad: \n",
    "                _rm(self.grad_pattern)\n",
    "\n",
    "        print(\"Rendering video done!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Scene.normalise)\n",
    "show_doc(Scene.denormalise)\n",
    "show_doc(Scene.render)\n",
    "show_doc(Scene.render_result_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class VectorLearner:\n",
    "    \"\"\"Handle optimisation and iterations.\n",
    "       TODO: Convert to a subclass of Learner.\"\"\"\n",
    "    def __init__(self, parameters: list[Tensor], forward: Callable[..., Tensor], \n",
    "        target: Tensor = None, loss: Callable[..., Tensor] = None, \n",
    "        lr = 1e-2):\n",
    "        self._lr = lr\n",
    "        self.parameters = parameters\n",
    "        self.optimizer = torch.optim.Adam(self.parameters, lr=self._lr)\n",
    "        self.forward = forward\n",
    "        self.loss = self.loss_l2 if loss is None else loss\n",
    "        self.target = target\n",
    "        self.debug = False\n",
    "        self.iterations = -1\n",
    "        self._iteration = -1\n",
    "\n",
    "    @property\n",
    "    def lr(self) -> float:\n",
    "        return self._lr\n",
    "\n",
    "    @lr.setter\n",
    "    def lr(self, val: float):\n",
    "        self._lr = self.optimizer.lr = val\n",
    "\n",
    "    def loss_l2(self, img: Tensor, target: Tensor, **kwargs) -> Tensor:\n",
    "        \"\"\"L2 loss function\"\"\"\n",
    "        return (img - target).pow(2).sum() # mean()\n",
    "\n",
    "    def next_i(self) -> int:\n",
    "        \"\"\"For use with step\"\"\"\n",
    "        self._iteration += 1\n",
    "        return self._iteration\n",
    "\n",
    "    def reset_i(self) -> None:\n",
    "        self._iteration = -1\n",
    "\n",
    "    def run(self, iterations=100, **kwargs) -> None:\n",
    "        \"\"\"Perform iterations number of steps. Kwargs are passed to step and hence to forward.\"\"\"\n",
    "        self.reset_i()\n",
    "        self.iterations = iterations\n",
    "        for _ in range(iterations):\n",
    "            self.step(**kwargs)\n",
    "\n",
    "    def step(self, target: Tensor = None, **kwargs) -> None:\n",
    "        \"\"\"Perform one optimisation step. Kwargs are passed to forward.\"\"\"\n",
    "\n",
    "        if target is None: target = self.target\n",
    "        assert target is not None\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        # Forward pass: render the image.\n",
    "        img = self.forward(**kwargs)\n",
    "        loss = self.loss(img=img, target=target, parameters=self.parameters)\n",
    "        # Backpropagate the gradients.\n",
    "        loss.backward()\n",
    "        if self.debug: \n",
    "            for p in self.parameters: print(p.grad)\n",
    "        # Take a gradient descent step.\n",
    "        self.optimizer.step()\n",
    "\n",
    "        print(f\"Iteration {self.next_i()}/{self.iterations} â€¢ Loss: {loss.item():8.0f}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_fontsampler.ipynb.\n",
      "Converted 02_ocrlearner.ipynb.\n",
      "Converted 03_fontlearner.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5710b12fb88680bf60c169aecc91e9487b0350ee3a6536206b6750ffeed12b61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ai-font-p3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
