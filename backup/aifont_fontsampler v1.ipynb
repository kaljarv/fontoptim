{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# default_exp fontsampler\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Font Sampler\n",
    "\n",
    "> Utilities to create images from Google Fonts. Code mostly by [@erraticgener8or](https://erraticgenerator.com/blog/use-google-fonts-for-machine-learning-part1/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from aifont.core import *\n",
    "import glob\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from os.path import basename, join, splitext\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "import re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering Font Images\n",
    "\n",
    "> Selecting Google Fonts and rendering font images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "GOOGLE_FONT_ROOT_PATH = \"data/google_fonts\"\n",
    "\n",
    "def render_text(font_path: str,\n",
    "    text: str, \n",
    "    text_size: int = None, \n",
    "    x: int = None, \n",
    "    y: int = None, \n",
    "    image_width: int = 256, \n",
    "    image_height: int = None, \n",
    "    as_normalised_array = False\n",
    "    ) -> Union[\n",
    "        tuple[np.ndarray, str], tuple[Image.Image, str], tuple[None, None],\n",
    "        np.ndarray, Image.Image, None\n",
    "        ]:\n",
    "    \"\"\"Render `text` with `font_path` as black on white and return either \n",
    "       as a normalised numpy array of (alpha) values or a PIL Image.\"\"\"\n",
    "    assert image_width is not None\n",
    "    if image_height is None: image_height = image_width\n",
    "    if text_size is None: text_size = round(image_height * .8)\n",
    "    if x is None: x = image_width * .5\n",
    "    if y is None:\n",
    "        # Try to find a nice y location for the text keeping in mind that descenders\n",
    "        # will reach below this point and might thus fall off canvas\n",
    "        y = text_size + max(0, (image_height - text_size * 1.5) / 2)\n",
    "    font = ImageFont.truetype(font_path, text_size)\n",
    "    # get text info (not being used but may be useful)\n",
    "    # text_width, text_height = font.getsize(text)\n",
    "    # left, top, right, bottom = font.getbbox(text)\n",
    "    # create a blank canvas\n",
    "    canvas = Image.new('L', (image_width, image_height), 'white')\n",
    "    # draw the text onto the text canvas\n",
    "    draw = ImageDraw.Draw(canvas)\n",
    "    draw.text((x, y), text, 'black', font, anchor='ms')\n",
    "    # Convert to normalised list if needed\n",
    "    return np.reshape([(255 - x) / 255. for x in list(canvas.getdata())], (image_height, image_width)) \\\n",
    "           if as_normalised_array else canvas\n",
    "\n",
    "class FontSampler:\n",
    "    \"\"\"Sample Google Fonts and render as images. `df` or `df_path` should point to font annotations\n",
    "       (see `create_font_annotations`), `font_path` to the root folder of the ofl fonts. Control\n",
    "       font selection with `variants`, `subsets` and `category`, which can be either strings or \n",
    "       regexs. Note that the search is performed on an AND basis meaning that if you define, e.g.,\n",
    "       `variants=['regular', 'medium']`, you will only find font faces where the family itself\n",
    "       contains both. Use `add_fonts` with another variant if you want to perform an OR-type\n",
    "       search.\"\"\"\n",
    "    def __init__(self, df: DataFrame = None, df_path: str = f\"{GOOGLE_FONT_ROOT_PATH}/google-fonts-annotation.csv\", \n",
    "        font_path: str = \"data/fonts\", variants: list[str] = None, subsets: list[str] = None, \n",
    "        category: str = None, image_width: int = 256, image_height: int = 256):\n",
    "        self.df = pd.read_csv(df_path) if df is None else df\n",
    "        self.font_path = font_path\n",
    "        self.variants = variants\n",
    "        self.subsets = subsets\n",
    "        self.category = category\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.font_index = -1\n",
    "        self.paths = []\n",
    "        self.set_fonts(self.filter_fonts_get_paths())\n",
    "\n",
    "    @property\n",
    "    def num_fonts(self):\n",
    "        \"\"\"Get the number of fonts found.\"\"\"\n",
    "        return len(self.paths)\n",
    "\n",
    "    def set_fonts(self, paths: list[str]) -> None:\n",
    "        \"\"\"Set paths and shuffle them.\"\"\"\n",
    "        self.paths = list(paths)\n",
    "        random.shuffle(self.paths)\n",
    "        # Reset index\n",
    "        self.font_index = -1\n",
    "\n",
    "    def add_fonts(self, variants: list[str] = None, subsets: list[str] = None, \n",
    "        category: str = None) -> None:\n",
    "        \"\"\"Add fonts to `self.paths` using the criteria.\"\"\"\n",
    "        paths = self.filter_fonts_get_paths(variants=variants, subsets=subsets, category=category)\n",
    "        paths = list(set(paths + self.paths))\n",
    "        self.set_fonts(paths)\n",
    "\n",
    "    def filter_fonts_get_paths(self, variants: list[str] = None, subsets: list[str] = None, \n",
    "        category: str = None) -> list[str]:\n",
    "        \"\"\"Filter the fonts list by the criteria and return a list of file paths.\"\"\"\n",
    "        df = self.df\n",
    "        font_path = self.font_path\n",
    "        if variants is None:\n",
    "            variants = self.variants\n",
    "        if subsets is None:\n",
    "            subsets = self.subsets\n",
    "        if category is None:\n",
    "            category = self.category\n",
    "        # exceptions\n",
    "        if variants is None or variants == [''] or variants == '': \n",
    "            variants = ['_']\n",
    "        if subsets is None or subsets == [''] or subsets == '': \n",
    "            subsets = ['_']\n",
    "        if category is None:\n",
    "            category = ''\n",
    "        # apply filters\n",
    "        regex_filters = variants + subsets + ['_' + category]\n",
    "        df_new = pd.concat([df.filter(regex=re.compile(regex, re.IGNORECASE), axis=1).sum(axis=1).astype(bool) for regex in regex_filters], axis=1)\n",
    "        mask = df_new.all(axis=1)\n",
    "        filtered_fontnames = list(df.loc[mask].family)\n",
    "        # construct file paths\n",
    "        paths = []\n",
    "        for fontname in filtered_fontnames:\n",
    "            if variants == ['_']: # select all variants\n",
    "                sel = glob.glob(f'{font_path}/{fontname.lower()}/**/*.ttf', recursive=True)\n",
    "                paths.extend(sel)\n",
    "            else:\n",
    "                for variant in variants:\n",
    "                    sel = glob.glob(f'{font_path}/{fontname.lower()}/**/{fontname}-{variant}.ttf', recursive=True) \n",
    "                    for path in sel:\n",
    "                        paths.append(path)\n",
    "        if len(paths) == 0:\n",
    "            raise Exception(\"No matching fonts found!\")\n",
    "        # print(f'Found {len(paths)} font files.')\n",
    "        return paths\n",
    "\n",
    "    def render_text(self, text: str, text_size: int = None, x: int = None, y: int = None, \n",
    "        font_index: int = None, image_width: int = None, image_height: int = None, \n",
    "        as_normalised_array = False, include_font = False) -> Union[\n",
    "            tuple[np.ndarray, str], tuple[Image.Image, str], tuple[None, None],\n",
    "            np.ndarray, Image.Image, None\n",
    "            ]:\n",
    "        \"\"\"Render the given text as black on white and return either as a normalised \n",
    "           numpy array of (alpha) values, a PIL Image or a tuple with one of these and the\n",
    "           font filename if `include_font` is True. If called without font_index, will \n",
    "           iterate over all paths and return None once the end is reached.\"\"\"\n",
    "        paths = self.paths\n",
    "        if font_index is None:\n",
    "            if self.font_index >= len(paths):\n",
    "                self.font_index = -1\n",
    "                return (None, None) if include_font else None\n",
    "            self.font_index += 1\n",
    "            font_index = self.font_index\n",
    "        if text_size is None:    text_size = round(self.image_height * .8)\n",
    "        if image_width is None:  image_width = self.image_width\n",
    "        if image_height is None: image_height = self.image_height\n",
    "        if x is None: x = image_width * .5\n",
    "        if y is None:\n",
    "            # Try to find a nice y location for the text keeping in mind that descenders\n",
    "            # will reach below this point and might thus fall off canvas\n",
    "            y = text_size + max(0, (image_height - text_size * 1.5) / 2)\n",
    "        font_path = paths[font_index % len(paths)]\n",
    "        font = ImageFont.truetype(font_path, text_size)\n",
    "        # get text info (not being used but may be useful)\n",
    "        # text_width, text_height = font.getsize(text)\n",
    "        # left, top, right, bottom = font.getbbox(text)\n",
    "        # print(left, top, right, bottom)\n",
    "        # create a blank canvas\n",
    "        canvas = Image.new('L', (image_width, image_height), 'white')\n",
    "        # draw the text onto the text canvas\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "        draw.text((x, y), text, 'black', font, anchor='ms')\n",
    "        # Convert to normalised list if needed\n",
    "        img = np.reshape([(255 - x) / 255. for x in list(canvas.getdata())],\n",
    "                         (image_height, image_width)) if as_normalised_array else canvas\n",
    "        # Include  font name if needed\n",
    "        if include_font: return (img, basename(font_path))\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FontSampler.num_fonts\" class=\"doc_header\"><code>FontSampler.num_fonts</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Get the number of fonts found."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FontSampler.render_text\" class=\"doc_header\"><code>FontSampler.render_text</code><a href=\"__main__.py#L90\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FontSampler.render_text</code>(**`text`**:`str`, **`text_size`**:`int`=*`None`*, **`x`**:`int`=*`None`*, **`y`**:`int`=*`None`*, **`font_index`**:`int`=*`None`*, **`image_width`**:`int`=*`None`*, **`image_height`**:`int`=*`None`*, **`as_normalised_array`**=*`False`*, **`include_font`**=*`False`*)\n",
       "\n",
       "Render the given text as black on white and return either as a normalised \n",
       "numpy array of (alpha) values, a PIL Image or a tuple with one of these and the\n",
       "font filename if `include_font` is True. If called without font_index, will \n",
       "iterate over all paths and return None once the end is reached."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FontSampler.num_fonts)\n",
    "show_doc(FontSampler.render_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render a letter as a grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x11B262280>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = FontSampler(category=\"sans-serif\")\n",
    "img = fs.render_text('A'); img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or as a numpy matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_img = fs.render_text('A', as_normalised_array=True, font_index=0)\n",
    "np_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use it with `diffvg`, use the values as the A-band of the RGBA tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 256]), torch.Size([256, 256, 1]), torch.Size([256, 256, 4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "wd_ht = torch.tensor(np_img, dtype=torch.float32)\n",
    "wd_ht_a = torch.reshape(wd_ht, wd_ht.shape + tuple([1]))\n",
    "wd_ht_rgba = F.pad(input=wd_ht_a, pad=(3, 0, 0, 0, 0, 0), mode='constant', value=0)\n",
    "wd_ht.shape, wd_ht_a.shape, wd_ht_rgba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FontSampler.add_fonts\" class=\"doc_header\"><code>FontSampler.add_fonts</code><a href=\"__main__.py#L38\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FontSampler.add_fonts</code>(**`variants`**:`list`\\[`str`\\]=*`None`*, **`subsets`**:`list`\\[`str`\\]=*`None`*, **`category`**:`str`=*`None`*)\n",
       "\n",
       "Add fonts to `self.paths` using the criteria."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FontSampler.add_fonts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Font Samples\n",
    "\n",
    "> Using FontSampler to create a set of font images for use in learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_font_images(texts = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"), \n",
    "    variants = [\"regular\", \"medium\", \"light\"], file_extension = \".png\",\n",
    "    image_width = 256, image_height = 256, out_path = f\"{GOOGLE_FONT_ROOT_PATH}/font_images\") -> None:\n",
    "    \"\"\"Create font images and save them. Find matching font `variants` and\n",
    "       renders grayscale `image_width` x `image_height` images for each\n",
    "       of the `texts` using `FontSampler.render_text`.\"\"\"\n",
    "\n",
    "    fs = FontSampler(category=\"sans-serif\", \n",
    "                    subsets=[\"latin\"],\n",
    "                    variants=[variants[0]] if len(variants) > 0 else None,\n",
    "                    image_width=image_width,\n",
    "                    image_height=image_height)\n",
    "\n",
    "    if len(variants) > 1:\n",
    "        for v in variants[1:]:\n",
    "            fs.add_fonts(category=\"sans-serif\",\n",
    "                        subsets=[\"latin\"],\n",
    "                        variants=[v])\n",
    "\n",
    "    print(f\"{fs.num_fonts} fonts found.\")\n",
    "\n",
    "    for i in range(fs.num_fonts):\n",
    "        if i % 20 == 0: print(f\"Font {i}/{fs.num_fonts}\")\n",
    "        for t in texts:\n",
    "            img, font = fs.render_text(t, \n",
    "                                       font_index=i,\n",
    "                                       include_font=True)\n",
    "            font = splitext(font)[0]\n",
    "            filename = join(out_path, f\"{t}_{font}{file_extension}\")\n",
    "            try:\n",
    "                img.save(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {font} / {t}: {e}\")\n",
    "    \n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Font Metadata\n",
    "\n",
    "> Get font metadata from the Google Fonts API. Needed only once. You need an API key for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def create_font_annotations(data_path: str = os.path.join(GOOGLE_FONT_ROOT_PATH, \"webfonts.json\"), api_key: str = None, \n",
    "    save_path = \"data/google-fonts-annotation.csv\") -> DataFrame:\n",
    "    \"\"\"Get Google Fonts metadata either from the API using `api_key` or from\n",
    "       a local file at `data_path` and save the data as csv in `save_path`.\n",
    "       Also returns the data frame.\"\"\"\n",
    "\n",
    "    assert api_key is not None or data_path is not None\n",
    "\n",
    "    if data_path is not None:\n",
    "        # Use JSON already downloaded\n",
    "        df = pd.read_json(data_path)\n",
    "    else:\n",
    "        # Download json data once\n",
    "        url = f\"https://www.googleapis.com/webfonts/v1/webfonts?key={api_key}\"\n",
    "        df = pd.read_json(url, orient='')\n",
    "\n",
    "    # flatten the JSON hierarchy (easier to handle this way)\n",
    "    df = pd.json_normalize(df['items'])\n",
    "\n",
    "    # select only the columns we need\n",
    "    cols = ['family', 'variants', 'subsets', 'category']\n",
    "    df = df[cols]\n",
    "    # df.head(5)\n",
    "\n",
    "    # Remove any space from family string so that it matchs with file name convention.\n",
    "    df.family = [name.replace(' ', '') for name in df.family]\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "\n",
    "    # one-hot encoding + prefix\n",
    "    df = df.join(DataFrame(mlb.fit_transform(df.pop('variants')),\n",
    "                           columns=[x for x in mlb.classes_],\n",
    "                           index=df.index))\n",
    "    df = df.join(DataFrame(mlb.fit_transform(df.pop('subsets')),\n",
    "                           columns=['subsets_' + x for x in mlb.classes_],\n",
    "                           index=df.index))\n",
    "    df = df.join(pd.get_dummies(df['category'], prefix=\"category\")).drop(['category'], axis=1)\n",
    "\n",
    "    col_names = {\n",
    "        \"100\": \"thin\",\n",
    "        \"100italic\": \"thinitalic\",\n",
    "        \"200\": \"extralight\",\n",
    "        \"200italic\": \"extralightitalic\",\n",
    "        \"300\": \"light\",\n",
    "        \"300italic\": \"lightitalic\",\n",
    "        \"400\": \"regular\",\n",
    "        \"regular\": \"regular\",\n",
    "        \"400italic\": \"italic\",\n",
    "        \"italic\": \"italic\",\n",
    "        \"500\": \"medium\",\n",
    "        \"500italic\": \"mediumitalic\",\n",
    "        \"600\": \"semibold\",\n",
    "        \"600italic\": \"semibolditalic\",\n",
    "        \"700\": \"bold\",\n",
    "        \"700italic\": \"bolditalic\",\n",
    "        \"800\": \"extrabold\",\n",
    "        \"800italic\": \"extrabolditalic\",\n",
    "        \"900\": \"black\",\n",
    "        \"900italic\": \"blackitalic\"\n",
    "    }\n",
    "    col_names = {k:f'variants_{v}' for k, v in col_names.items()}\n",
    "\n",
    "    df = df.rename(col_names, axis='columns')\n",
    "\n",
    "    # Export csv\n",
    "    if not save_path.endswith(\".csv\"):\n",
    "        save_path += \".csv\"\n",
    "    df.to_csv(save_path, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_fontlearnertests.ipynb.\n",
      "Converted 02_first_letter_and_optim_tests.ipynb.\n",
      "Converted 03_vector_models.ipynb.\n",
      "Converted 04_font_statistics.ipynb.\n",
      "Converted 05_full_aphabet_optimisation.ipynb.\n",
      "Converted 06_data_augmentation.ipynb.\n",
      "Converted 07_optimising_with_augmentation.ipynb.\n",
      "Converted aifont_core.ipynb.\n",
      "Converted aifont_fontlearner.ipynb.\n",
      "Converted aifont_fontsampler.ipynb.\n",
      "Converted aifont_ocrlearner.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5710b12fb88680bf60c169aecc91e9487b0350ee3a6536206b6750ffeed12b61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ai-font-p3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
