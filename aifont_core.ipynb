{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aifont Core\n",
    "\n",
    "> Core functions and constants for Aifont. These are imported by the other Aifont modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.data.all import *\n",
    "from fastai.vision.all import *\n",
    "from functools import cmp_to_key\n",
    "from IPython.display import clear_output\n",
    "import itertools\n",
    "from math import sqrt, ceil\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import PIL.ImageOps\n",
    "import skimage.io\n",
    "import subprocess\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Any, Callable, List, Protocol, Tuple, Union\n",
    "from warnings import warn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "SYS_FONT_PATH = Path(\"data/system_fonts\")\n",
    "VOCAB_UC = list(string.ascii_uppercase)\n",
    "VOCAB_UC_NUM = VOCAB_UC + list(string.digits)\n",
    "\n",
    "ImageTypes         = (PILImage, PILImageBW, Image.Image)\n",
    "TensorImageOrImage = (TensorImage, *ImageTypes)\n",
    "TensorOrImage      = (Tensor, *ImageTypes)\n",
    "\n",
    "# terminal output colours\n",
    "RED = '\\033[91m'\n",
    "GRN = '\\033[92m'\n",
    "YEL = '\\033[93m'\n",
    "BLU = '\\033[94m'\n",
    "PNK = '\\033[95m'\n",
    "TEL = '\\033[96m'\n",
    "GRY = '\\033[97m'\n",
    "END = '\\x1b[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is \u001b[92mgreen\u001b[0m text\n"
     ]
    }
   ],
   "source": [
    "print(f\"This is {GRN}green{END} text\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def clear() -> None:\n",
    "    \"\"\"Clear output\"\"\"\n",
    "    clear_output(wait=True)\n",
    "\n",
    "def report(\n",
    "    msg: str = \"\", \n",
    "    prog: float = None, \n",
    "    line_len = 120\n",
    ") -> None:\n",
    "    \"\"\"Report a one line message with optional progress [0, 1].\"\"\"\n",
    "    if prog is not None: msg = f\"{prog:6.2%} â€¢ {msg}\"\n",
    "    print(f\"{msg:{line_len}s}\", end=\"\\r\")\n",
    "\n",
    "def notify(title = \"\", text = \"\") -> None:\n",
    "    \"\"\"Display an OSX notification.\"\"\"\n",
    "    NOTIFY_CMD = '''\n",
    "    on run argv\n",
    "        display notification (item 2 of argv) with title (item 1 of argv)\n",
    "    end run\n",
    "    '''\n",
    "    subprocess.call(['osascript', '-e', NOTIFY_CMD, title, text])\n",
    "\n",
    "def dump(data: Any, filename: Union[Path, str]) -> None:\n",
    "    \"\"\"Pickle dump `data`.\"\"\"\n",
    "    assert type(filename) is str or isinstance(filename, Path)\n",
    "    filename = str(filename)\n",
    "    if not filename.endswith(\".pkl\"): filename = filename + \".pkl\"\n",
    "    ensure_path(filename)\n",
    "    with open(filename, 'wb') as f: pkl.dump(data, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "def ensure_path(path: Union[Path, str]) -> Union[Path, str]:\n",
    "    \"\"\"Create all folders on `path` if they don't exist. If `path` doesn't have a suffix,\n",
    "       the last item is created as a folder as well.\"\"\"\n",
    "    p = Path(path)\n",
    "    if p.suffix != \"\": p = p.parent\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def load(filename: Union[str, Path]\n",
    ") -> Any:\n",
    "    \"\"\"Pickle load data.\"\"\"\n",
    "    filename = Path(filename)\n",
    "    with open(filename.with_suffix(\".pkl\"), 'rb') as f: return pkl.load(f)\n",
    "\n",
    "def try_load(filename: Union[str, Path]\n",
    ") -> Any:\n",
    "    \"\"\"Pickle load data and return `None` if not successful.\"\"\"\n",
    "    try: res = load(filename)\n",
    "    except: return None\n",
    "    return res\n",
    "\n",
    "def flatten_list(deep_list: list[list[object]]\n",
    ") -> list[object]: \n",
    "    \"\"\"Flatten a list of lists.\"\"\"\n",
    "    flat = list(itertools.chain.from_iterable(deep_list))\n",
    "    return flatten_list(flat) if len(flat) and type(flat[0]) is list else flat\n",
    "\n",
    "def render_text(font_path: Union[Path, str],\n",
    "    text: str, \n",
    "    text_size: int = None, \n",
    "    x: int = None, \n",
    "    y: int = None, \n",
    "    image_width: int = 256, \n",
    "    image_height: int = None, \n",
    "    as_normalised_array = False\n",
    ") -> Union[np.ndarray, Image.Image]:\n",
    "    \"\"\"Render `text` with `font_path` as black on white and return either \n",
    "       as a normalised numpy array of (alpha) values or a PIL Image.\"\"\"\n",
    "    assert image_width is not None\n",
    "    if image_height is None: image_height = image_width\n",
    "    if text_size is None: text_size = round(image_height * .8)\n",
    "    if x is None: x = image_width * .5\n",
    "    if y is None:\n",
    "        # Try to find a nice y location for the text keeping in mind that descenders\n",
    "        # will reach below this point and might thus fall off canvas\n",
    "        y = text_size + max(0, (image_height - text_size * 1.5) / 2)\n",
    "    font = ImageFont.truetype(str(font_path), text_size)\n",
    "    # get text info (not being used but may be useful)\n",
    "    # text_width, text_height = font.getsize(text)\n",
    "    # left, top, right, bottom = font.getbbox(text)\n",
    "    # create a blank canvas\n",
    "    canvas = Image.new('L', (image_width, image_height), 'white')\n",
    "    # draw the text onto the text canvas\n",
    "    draw = ImageDraw.Draw(canvas)\n",
    "    draw.fontmode = \"L\"\n",
    "    draw.text((x, y), text, 'black', font, anchor='ms')\n",
    "    # Convert to normalised list if needed\n",
    "    return img_to_normalised_array(canvas) if as_normalised_array else canvas\n",
    "\n",
    "def is_image(x: Tensor) -> bool: return x.ndim >= 2\n",
    "\n",
    "def is_pil(img) -> bool: return isinstance(img, Image.Image)\n",
    "\n",
    "def tensor_is_bw_image(x: Tensor, allow_batch = False) -> bool:\n",
    "    \"\"\"Check if `x` looks like a black-and-white image. Note that if `allow_batch` is\n",
    "       `True` a single RGB image will look like a batch of bw images.\"\"\"\n",
    "    return (x.ndim == 3 or (x.ndim >  3 and x.shape[-3] == 1)) if allow_batch else \\\n",
    "           (x.ndim == 2 or (x.ndim == 3 and x.shape[-3] == 1))\n",
    "\n",
    "def tensor_is_rgb_image(x: Tensor, allow_batch = False) -> bool:\n",
    "    \"Check if `x` looks like an RGB image.\"\n",
    "    return (x.ndim == 3 or (allow_batch and x.ndim > 3)) and x.shape[-3] == 3\n",
    "\n",
    "def tensor_to_rgb(x: Tensor, div_int_by = 255.) -> Tensor:\n",
    "    \"\"\"Expand `x` to 3 channels and div by `div_int_by` if int. `x` can have 2 to 4 dims.\n",
    "       The channel dim is expected to be -3 with the preceding ones batches.\n",
    "       Flattens rgba to rgb.\"\"\"\n",
    "    assert x.ndim in (2,3,4)\n",
    "    if x.ndim == 2:      x = x.expand((3,-1,-1)) # expand 2 to 3 dims\n",
    "    if x.shape[-1] <= 4: x = x.permute((2,0,1)     if x.ndim == 3 else (0,3,1,2)) # reorder channels first\n",
    "    if x.shape[-3] == 1: x = x.expand((3,-1,-1))   if x.ndim == 3 else x.expand((-1,3,-1,-1)) # expand grayscale to rgb\n",
    "    if x.shape[-3] == 4: x = x[0:3,:,:] * x[3,:,:] if x.ndim == 3 else x[:,0:3,:,:] * x[:,3,:,:] # flatten rgba\n",
    "    assert x.shape[-3] == 3\n",
    "    return x if torch.is_floating_point(x) else x / div_int_by\n",
    "\n",
    "def img_from_tensor(t: Tensor, \n",
    "    scale: float = None\n",
    ") -> Image.Image:\n",
    "    \"\"\"Create an image from a tensor produced by `aifont.fontlearner.VectorRenderLayer`.\"\"\"\n",
    "    pil_img = to_image(tensor_to_rgb(t.clip(0., 1.).squeeze()))\n",
    "    if scale is not None: pil_img = pil_img.resize((round(pil_img.width * scale), round(pil_img.height * scale)), resample=0)\n",
    "    return pil_img\n",
    "\n",
    "def img_to_normalised_array(img: Image.Image) -> np.ndarray:\n",
    "    \"\"\"Convert a rendered image to a normalised array.\"\"\"\n",
    "    return np.reshape([x/255. for x in list(img.getdata())], (img.height, img.width))\n",
    "\n",
    "def image_grid(imgs: Union[List[Image.Image], List[str], Tensor], \n",
    "    rows: int = None, \n",
    "    cols: int = None,\n",
    "    bg_color: any = \"white\",\n",
    "    scale: float = None,\n",
    ") -> Image.Image:\n",
    "    \"\"\"Create a grid from the images or image filenames supplied.\"\"\"\n",
    "    if isinstance(imgs, Tensor):\n",
    "        if   imgs.ndim == 2: imgs = imgs.reshape(( 1,1,*imgs.shape[-2:]))\n",
    "        elif imgs.ndim == 3: imgs = imgs.reshape((-1,*imgs.shape[-3:]))\n",
    "        elif imgs.ndim != 4: raise ValueError(f\"Can't deal with tensor of {imgs.ndim} dimensions.\")\n",
    "        imgs = [img_from_tensor(o.detach()) for o in imgs]\n",
    "    elif type(imgs[0]) is str: imgs = [Image.open(o) for o in imgs]\n",
    "    n = len(imgs)\n",
    "    if rows is None: rows = ceil(sqrt(n)) if cols is None else ceil(n / cols)\n",
    "    if cols is None: cols = ceil(n / rows)\n",
    "    w, h = imgs[0].size\n",
    "    size = (cols * w, rows * h)\n",
    "    grid = Image.new('RGB', size=size, color=bg_color)\n",
    "    for i, img in enumerate(imgs): grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    if scale is not None: grid = grid.resize((round(o * scale) for o in size))\n",
    "    return grid\n",
    "\n",
    "def df_row_to_image(\n",
    "    df_row: pd.Series,\n",
    "    start_col = 1\n",
    ") -> Image:\n",
    "    \"\"\"Convert image data from a DataFrame row to an Image object.\"\"\"\n",
    "    sz = len(df_row) - start_col\n",
    "    wh = int(sz ** .5)\n",
    "    assert sz == wh ** 2\n",
    "    img = df_row[start_col : len(df_row)].values.reshape(wh, wh)\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "@delegates(image_grid)\n",
    "def df_to_image_grid(\n",
    "    df: DataFrame,\n",
    "    start_col = 1,\n",
    "    max_images = 50,\n",
    "    invert = False,\n",
    "    **kwargs,\n",
    ") -> Image:\n",
    "    \"\"\"Convert a DataFrame to an Image grid and optionally `invert`.\"\"\"\n",
    "    imgs = [df_row_to_image(df.iloc[i], start_col=start_col) for i in range(min(len(df), max_images))]\n",
    "    if invert: imgs = [PIL.ImageOps.invert(o) for o in imgs]\n",
    "    return image_grid(imgs, **kwargs)\n",
    "\n",
    "def read_image(fn: str) -> Tensor:\n",
    "    \"\"\"Read an image and return a normalised rgba tensor.\"\"\"\n",
    "    return Tensor(skimage.io.imread(fn) / 255.)\n",
    "\n",
    "def s(x):\n",
    "    if not isinstance(x, Tensor): x = torch.tensor(x)\n",
    "    return 1/(1 + torch.exp(-x))\n",
    "\n",
    "def smooth(y, \n",
    "    dist = 1\n",
    ") -> list:\n",
    "    \"\"\"Smooth values in the list up to `dist` items in both directions.\"\"\"\n",
    "    assert dist > 0\n",
    "    if type(y) is pd.Series: y = y.to_numpy()\n",
    "    window = 2 * dist + 1\n",
    "    y = np.insert(y, 0, [0] + [y[0]] * dist)\n",
    "    y = np.append(y, [y[-1]] * dist)\n",
    "    cs = np.cumsum(y)\n",
    "    return (cs[window:] - cs[:-window]) / window\n",
    "\n",
    "def plot_function(f, \n",
    "    tx=None, ty=None, \n",
    "    title=None, \n",
    "    min=-2, max=2, \n",
    "    figsize=(6,4)\n",
    ") -> None:\n",
    "    \"\"\"From fastbook.utils\"\"\"\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['savefig.dpi']= 200\n",
    "    mpl.rcParams['font.size']=12\n",
    "    x = torch.linspace(min,max,steps=None)\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot(x,f(x))\n",
    "    if tx is not None: ax.set_xlabel(tx)\n",
    "    if ty is not None: ax.set_ylabel(ty)\n",
    "    if title is not None: ax.set_title(title)\n",
    "\n",
    "def concat_tensors(*tensors,\n",
    "    flatten = False\n",
    ") -> Tensor:\n",
    "    \"\"\"Utility to concat tensors or numbers even if they are zero-dimensional.\n",
    "       Optionally `flatten` the concatenated tensor.\"\"\"\n",
    "    if type(tensors[0]) in (list, tuple): \n",
    "        assert len(tensors) == 1\n",
    "        tensors = tensors[0]\n",
    "    tt = [tensor(x) for x in tensors]\n",
    "    res = torch.concat([x.unsqueeze(0) if x.ndim == 0 else x for x in tt])\n",
    "    return res.flatten() if flatten else res\n",
    "\n",
    "def file_cmp(a, b, sep=r\"[\\W_\\-]+\") -> int:\n",
    "    \"Compare to strings by splitting them and comparing each part with numbers compared as such.\"\n",
    "    for a_,b_ in zip(*[re.split(sep, o) for o in (a,b)]):\n",
    "        if a_.isdigit(): a_,b_ = int(a_),int(b_)\n",
    "        if   a_ < b_: return - 1\n",
    "        elif a_ > b_: return 1\n",
    "    return 0\n",
    "\n",
    "def get_file_sorter(sep=None) -> Callable:\n",
    "    \"\"\"Get a `key` function for `sort` to compare to strings by splitting them and \n",
    "       comparing each part with numbers compared as such.\"\"\"\n",
    "    return cmp_to_key(file_cmp if sep is None else partial(file_cmp, sep=sep))\n",
    "\n",
    "def mean(vals: list) -> float:\n",
    "    \"Get the mean of `vals`.\"\n",
    "    return np.array(vals).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_experiment_1_match_font.ipynb.\n",
      "Converted 02_experiment_2_ocr_models.ipynb.\n",
      "Converted 03_experiment_3_optimise_with_ocr.ipynb.\n",
      "Converted 04_font_statistics.ipynb.\n",
      "Converted aifont_core.ipynb.\n",
      "Converted aifont_fontlearner.ipynb.\n",
      "Converted aifont_fontsampler.ipynb.\n",
      "Converted aifont_ocrlearner.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5710b12fb88680bf60c169aecc91e9487b0350ee3a6536206b6750ffeed12b61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ai-font-p3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
